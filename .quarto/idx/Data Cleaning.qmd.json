{"title":"Data Cleaning","markdown":{"yaml":{"title":"Data Cleaning","author":[{"name":"Thomas Pollet and Connor Malcolm","affiliations":[{"name":"Northumbria University"}]}],"date":"2022-01-30","date-modified":"`r format(Sys.time(), '%Y %B, %d')`","title-block-banner":true,"abstract":"Data Cleaning readying for analyses"},"headingText":"| echo: false","containsRefs":false,"markdown":"\n\n```{r}\n#| output: false\nlibrary(tidyverse)\nlibrary(yarrr)\nlibrary(wordcloud)\nlibrary(wordcloud2)\nlibrary(bibliometrix)\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(EGAnet)\nlibrary(papaja)\nlibrary(janitor)\nlibrary(gtools)\nlibrary(data.table)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(HiveR)\nlibrary(RBioFabric) #Installation: install.packages(\"remotes\")\n                    #remotes::install_github(\"wjrl/RBioFabric\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nscopus1000df <- convert2df(file = \"scopus2000alloa.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopusRESTdf <- convert2df(file = \"scopusall30.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopus_all_oa<- merge(scopusRESTdf, scopus1000df, all = TRUE) #Scopus has a 2000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusGreen.bib\"\n\nscopus_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusGREENFINALOA.bib\"\n\nscopus_green_final <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusGREENACCEPTEDOA.bib\"\n\nscopus_green_accepted <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusNOTGREEN.bib\"\n\nscopus_not_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n \nwos1000df <- convert2df(file = \"wosALLOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTdf <- convert2df(file = \"wosALLrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_all_oa<- merge(wosRESTdf, wos1000df, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"wosAllGreen.bib\"\n\nwos_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"wosNOTGREEN.bib\"\n\nwos_not_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"wosFinal.bib\"\n\nwos_green_final <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nwos1000Accepteddf <- convert2df(file = \"wosAcceptedOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTAccepteddf <- convert2df(file = \"wosAcceptedrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_green_accepted<- merge(wosRESTAccepteddf, wos1000Accepteddf, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n```\n\n# Data Cleaning\n\n## Scopus merge with Web of Science\n\nMerging Scopus and Web of Science data.\n\n**All Open Access**\n\n```{r}\ncommon_col_all_oa_names <- intersect(names(scopus_all_oa), names(wos_all_oa)) #Find common column names\nscopus_wos_all_oa <- merge(scopus_all_oa, wos_all_oa, by=common_col_all_oa_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n**Green**\n\n```{r}\ncommon_col_green_names <- intersect(names(scopus_green), names(wos_green)) #Find common column names\nscopus_wos_green <- merge(scopus_green, wos_green, by=common_col_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n**Green Final**\n\n```{r}\ncommon_col_green_final_names <- intersect(names(scopus_green_final), names(wos_green_final)) #Find common column names\nscopus_wos_green_final <- merge(scopus_green_final, wos_green_final, by=common_col_green_final_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n**Green Accepted**\n\n```{r}\ncommon_col_green_accepted_names <- intersect(names(scopus_green_accepted), names(wos_green_accepted)) #Find common column names\nscopus_wos_green_accepted <- merge(scopus_green_accepted, wos_green_accepted, by=common_col_green_accepted_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n**Not Green**\n\n```{r}\ncommon_col_not_green_names <- intersect(names(scopus_not_green), names(wos_not_green)) #Find common column names\nscopus_wos_not_green <- merge(scopus_not_green, wos_not_green, by=common_col_not_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n### Just Corresponding authors\n\nCleaning to just corresponding authors\n\n```{r}\nall_oa_corr <- scopus_wos_all_oa %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nall_oa_single_authors<- all_oa_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_corr <- scopus_wos_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_single_authors<- green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_final_corr <- scopus_wos_green_final %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_final_single_authors<- green_final_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_accepted_corr <- scopus_wos_green_accepted %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_accepted_single_authors<- green_accepted_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\nnot_green_corr <- scopus_wos_not_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nnot_green_single_authors<- not_green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n```\n\n```{r}\nall_oa_single_authors$RP <- sub(';.*', \"\" , as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub(',',\"\", as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub('\\\\.',\"\", as.character(all_oa_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_all_oa <- subset(all_oa_single_authors, AU == RP)\n\ngreen_single_authors$RP <- sub(';.*', \"\" , as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub(',',\"\", as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green <- subset(green_single_authors, AU == RP)\n\ngreen_final_single_authors$RP <- sub(';.*', \"\" , as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub(',',\"\", as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_final_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_final <- subset(green_final_single_authors, AU == RP)\n\ngreen_accepted_single_authors$RP <- sub(';.*', \"\" , as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub(',',\"\", as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_accepted_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_accepted <- subset(green_accepted_single_authors, AU == RP)\n\nnot_green_single_authors$RP <- sub(';.*', \"\" , as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub(',',\"\", as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub('\\\\.',\"\", as.character(not_green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_not_green <- subset(not_green_single_authors, AU == RP)\n```\n\nCheck for duplicates!\n\n```{r}\nduplicates_green_green<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green_accepted, by='DI')\n\nduplicates_not_green_green_final<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green, by='DI')\n\nduplicates_not_green_green_acccepted<-inner_join(scopus_wos_not_green, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nduplicates_green_final_green_acccepted<-inner_join(scopus_green_final, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Data Cleaning.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","theme":"cyborg","title":"Data Cleaning","author":[{"name":"Thomas Pollet and Connor Malcolm","affiliations":[{"name":"Northumbria University"}]}],"date":"2022-01-30","date-modified":"`r format(Sys.time(), '%Y %B, %d')`","title-block-banner":true,"abstract":"Data Cleaning readying for analyses"},"extensions":{"book":{"multiFile":true}}}}}