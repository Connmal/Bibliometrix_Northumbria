{"title":"Word Clouds","markdown":{"yaml":{"title":"Word Clouds","author":[{"name":"Thomas Pollet and Connor Malcolm","affiliations":[{"name":"Northumbria University"}]}],"date":"2022-01-30","date-modified":"`r format(Sys.time(), '%Y %B, %d')`","title-block-banner":true,"abstract":"Making Wordclouds for Authors, Keywords and Publication"},"headingText":"| echo: false","containsRefs":false,"markdown":"\n\n```{r}\n#| output: false\nlibrary(tidyverse)\nlibrary(yarrr)\nlibrary(wordcloud)\nlibrary(wordcloud2)\nlibrary(bibliometrix)\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(EGAnet)\nlibrary(papaja)\nlibrary(janitor)\nlibrary(gtools)\nlibrary(data.table)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(HiveR)\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nscopus1000df <- convert2df(file = \"scopus2000alloa.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopusRESTdf <- convert2df(file = \"scopusall30.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopus_all_oa<- merge(scopusRESTdf, scopus1000df, all = TRUE) #Scopus has a 2000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusGreen.bib\"\n\nscopus_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusGREENFINALOA.bib\"\n\nscopus_green_final <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusGREENACCEPTEDOA.bib\"\n\nscopus_green_accepted <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"scopusNOTGREEN.bib\"\n\nscopus_not_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n \nwos1000df <- convert2df(file = \"wosALLOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTdf <- convert2df(file = \"wosALLrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_all_oa<- merge(wosRESTdf, wos1000df, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"wosAllGreen.bib\"\n\nwos_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"wosNOTGREEN.bib\"\n\nwos_not_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nfile <- \"wosFinal.bib\"\n\nwos_green_final <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n```\n\n```{r}\n#| echo: false\n#| output: false\n\nwos1000Accepteddf <- convert2df(file = \"wosAcceptedOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTAccepteddf <- convert2df(file = \"wosAcceptedrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_green_accepted<- merge(wosRESTAccepteddf, wos1000Accepteddf, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n```\n\n```{r}\n#| echo: false\n#| output: false\ncommon_col_all_oa_names <- intersect(names(scopus_all_oa), names(wos_all_oa)) #Find common column names\nscopus_wos_all_oa <- merge(scopus_all_oa, wos_all_oa, by=common_col_all_oa_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n```{r}\n#| echo: false\n#| output: false\ncommon_col_green_names <- intersect(names(scopus_green), names(wos_green)) #Find common column names\nscopus_wos_green <- merge(scopus_green, wos_green, by=common_col_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n```{r}\n#| echo: false\n#| output: false\ncommon_col_green_final_names <- intersect(names(scopus_green_final), names(wos_green_final)) #Find common column names\nscopus_wos_green_final <- merge(scopus_green_final, wos_green_final, by=common_col_green_final_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n```{r}\n#| echo: false\n#| output: false\ncommon_col_green_accepted_names <- intersect(names(scopus_green_accepted), names(wos_green_accepted)) #Find common column names\nscopus_wos_green_accepted <- merge(scopus_green_accepted, wos_green_accepted, by=common_col_green_accepted_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n```{r}\n#| echo: false\n#| output: false\ncommon_col_not_green_names <- intersect(names(scopus_not_green), names(wos_not_green)) #Find common column names\nscopus_wos_not_green <- merge(scopus_not_green, wos_not_green, by=common_col_not_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n```\n\n```{r}\n#| echo: false\n#| output: false\nall_oa_corr <- scopus_wos_all_oa %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nall_oa_single_authors<- all_oa_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_corr <- scopus_wos_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_single_authors<- green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_final_corr <- scopus_wos_green_final %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_final_single_authors<- green_final_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_accepted_corr <- scopus_wos_green_accepted %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_accepted_single_authors<- green_accepted_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\nnot_green_corr <- scopus_wos_not_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nnot_green_single_authors<- not_green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n```\n\n```{r}\n#| echo: false\n#| output: false\nall_oa_single_authors$RP <- sub(';.*', \"\" , as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub(',',\"\", as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub('\\\\.',\"\", as.character(all_oa_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_all_oa <- subset(all_oa_single_authors, AU == RP)\n\ngreen_single_authors$RP <- sub(';.*', \"\" , as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub(',',\"\", as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green <- subset(green_single_authors, AU == RP)\n\ngreen_final_single_authors$RP <- sub(';.*', \"\" , as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub(',',\"\", as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_final_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_final <- subset(green_final_single_authors, AU == RP)\n\ngreen_accepted_single_authors$RP <- sub(';.*', \"\" , as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub(',',\"\", as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_accepted_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_accepted <- subset(green_accepted_single_authors, AU == RP)\n\nnot_green_single_authors$RP <- sub(';.*', \"\" , as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub(',',\"\", as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub('\\\\.',\"\", as.character(not_green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_not_green <- subset(not_green_single_authors, AU == RP)\n```\n\n```{r}\n#| echo: false\n#| output: false\nduplicates_green_green<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green_accepted, by='DI')\n\nduplicates_not_green_green_final<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green, by='DI')\n\nduplicates_not_green_green_acccepted<-inner_join(scopus_wos_not_green, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nduplicates_green_final_green_acccepted<-inner_join(scopus_green_final, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n```\n\n# Word Clouds\n\nPreparation for Word Clouds\n\n```{r}\ncorr_table_all_oa<-table(rp_single_author_all_oa$AU)\ncorr_table_all_oa_sorted <- corr_table_all_oa%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green<-table(rp_single_author_green$AU)\ncorr_table_green_sorted <- corr_table_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green_final<-table(rp_single_author_green_final$AU)\ncorr_table_green_final_sorted <- corr_table_green_final%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green_accepted<-table(rp_single_author_green_accepted$AU)\ncorr_table_green_accepted_sorted <- corr_table_green_accepted%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_not_green<-table(rp_single_author_not_green$AU)\ncorr_table_not_green_sorted <- corr_table_not_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\n```\n\nSeparate tables for Open Access publications\n\n```{r}\nSO_table_all_oa<-table(scopus_wos_all_oa$SO)\nSO_table_all_oa_sorted <- SO_table_all_oa%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green<-table(scopus_wos_green$SO)\nSO_table_green_sorted <- SO_table_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green_final<-table(scopus_wos_green_final$SO)\nSO_table_green_final_sorted <- SO_table_green_final%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green_accepted<-table(scopus_wos_green_accepted$SO)\nSO_table_green_accepted_sorted <- SO_table_green_accepted%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_not_green<-table(scopus_wos_not_green$SO)\nSO_table_not_green_sorted <- SO_table_not_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n```\n\n## Publications\n\nYarrr package seems to be best for vibrant and differing colours!\n\n### **All Open Access**\n\n```{r}\nset.seed(1404)\n\nDF_SO_table_all_oa_sorted <- as.data.frame(SO_table_all_oa_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_all_oa_sorted$Var1, freq = DF_SO_table_all_oa_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n##To fit long publication names had to make the words pretty small\n```\n\n### **Green**\n\n```{r}\nDF_SO_table_green_sorted <- as.data.frame(SO_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_green_sorted$Var1, freq = DF_SO_table_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n##To fit long publication names had to make the words pretty small\n```\n\n### **Green Final**\n\n```{r}\nDF_SO_table_green_final_sorted <- as.data.frame(SO_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = DF_SO_table_green_final_sorted$Var1, freq = DF_SO_table_green_final_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n##To fit long publication names had to make the words pretty small\n```\n\n### **Green Accepted**\n\n```{r}\nDF_SO_table_green_accepted_sorted <- as.data.frame(SO_table_green_accepted_sorted)\nwourdcloud_green_accepted_publications<- wordcloud(words = DF_SO_table_green_accepted_sorted$Var1, freq = DF_SO_table_green_accepted_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n##To fit long publication names had to make the words pretty small\n```\n\n### **Not Green**\n\n```{r}\nDF_SO_table_not_green_sorted <- as.data.frame(SO_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = DF_SO_table_not_green_sorted$Var1, freq = DF_SO_table_not_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(.25,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n##To fit long publication names had to make the words pretty small\n```\n\n## Corresponding Authors\n\n### **All Open Access**\n\n```{r}\ndf_corr_table_all_oa_sorted <- as.data.frame(corr_table_all_oa_sorted)\nwourdcloud_all_oa_publications<- wordcloud(words = df_corr_table_all_oa_sorted$Var1, freq = df_corr_table_all_oa_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n\n### **Green**\n\n```{r}\ndf_corr_table_green_sorted <- as.data.frame(corr_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_sorted$Var1, freq = df_corr_table_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n```\n\n### **Green Final**\n\n```{r}\ndf_corr_table_green_final_sorted <- as.data.frame(corr_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = df_corr_table_green_final_sorted$Var1, freq = df_corr_table_green_final_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n\n### **Green Accepted**\n\n```{r}\ndf_corr_table_green_accepted_sorted <- as.data.frame(corr_table_green_accepted_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_accepted_sorted$Var1, freq = df_corr_table_green_accepted_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n```\n\n### **Not Green**\n\n```{r}\ndf_corr_table_not_green_sorted <- as.data.frame(corr_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = df_corr_table_not_green_sorted$Var1, freq = df_corr_table_not_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n```\n\n## Keywords\n\n### **All Open Access**\n\n```{r}\nall_oa_keywords<- scopus_wos_all_oa %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nall_oa_keywords<- all_oa_keywords %>% \n  count(DE)\nall_oa_keywords<- na.omit(all_oa_keywords)\ncolnames(all_oa_keywords)[2]<- \"Freq\"\nwourdcloud_just_all_oa_keywords<- wordcloud(words = all_oa_keywords$DE, freq = all_oa_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n\n### **Green**\n\n```{r}\ngreen_keywords<- scopus_wos_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_keywords<- green_keywords %>% \n  count(DE)\ngreen_keywords<- na.omit(green_keywords)\ncolnames(green_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_keywords<- wordcloud(words = green_keywords$DE, freq = green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n\n### **Green Final**\n\n```{r}\ngreen_final_keywords<- scopus_wos_green_final %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_final_keywords<- green_final_keywords %>% \n  count(DE)\ngreen_final_keywords<- na.omit(green_final_keywords)\ncolnames(green_final_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_final_keywords<- wordcloud(words = green_final_keywords$DE, freq = green_final_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n\n### **Green Accepted**\n\n```{r}\ngreen_accepted_keywords<- scopus_wos_green_accepted %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_accepted_keywords<- green_accepted_keywords %>% \n  count(DE)\ngreen_accepted_keywords<- na.omit(green_accepted_keywords)\ncolnames(green_accepted_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_accepted_keywords<- wordcloud(words = green_accepted_keywords$DE, freq = green_accepted_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n\n### **Not Green**\n\n```{r}\nnot_green_keywords<- scopus_wos_not_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nnot_green_keywords<- not_green_keywords %>% \n  count(DE)\nnot_green_keywords<- na.omit(not_green_keywords)\ncolnames(not_green_keywords)[2]<- \"Freq\"\nwourdcloud_just_not_green_keywords<- wordcloud(words = not_green_keywords$DE, freq = not_green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"Word Clouds.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","editor":"visual","theme":"cyborg","title":"Word Clouds","author":[{"name":"Thomas Pollet and Connor Malcolm","affiliations":[{"name":"Northumbria University"}]}],"date":"2022-01-30","date-modified":"`r format(Sys.time(), '%Y %B, %d')`","title-block-banner":true,"abstract":"Making Wordclouds for Authors, Keywords and Publication"},"extensions":{"book":{"multiFile":true}}}}}