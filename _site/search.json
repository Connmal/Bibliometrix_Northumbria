[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Open Science Northumbria",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A R based document looking at bibliography data from Scopus and Web of Science based on cross department researchers in Northumbria University, who publish open access articles.\nAll Data is publicly available and all search terms used on the bibliographic databases are available as a part of the document.\nThe publications were split into types of open access.\nGreen : Free to read at repository. Published or Accepted. (Combination of Final and Accepted)\nGreen Final : Published article that is free to read at repository.\nGreen Accepted : Accepted for publication that is free to read at repository but not yet published.\nAll Open Access : Any kind of open access.\nNot Green : A combination of Bronze, Gold and Hybrid Gold\nBronze : Published or accepted where author chose to provide permanent or temporary open access. Bronze is applied if there is a license other than a creative common license. Or no licence at all.\nGold : Published with a creative common license and in an only open access journal, available on publisher platform.\nHybrid Gold : Published wit ha creative common license. Published in a journal that allows for the choice of publishing open access."
  },
  {
    "objectID": "Quatro_Bilbio.html",
    "href": "Quatro_Bilbio.html",
    "title": "Bibliometrix_Northumbria",
    "section": "",
    "text": "title: “Bibliometrix_Northumbria” author: - name: “Thomas Pollet and Connor Malcolm” affiliations: - name: “Northumbria University” date: “2022-01-30” date-modified: “2023 April, 20” title-block-banner: true abstract: “Bilbiometric data analysis of northumbrian author open access publications” format: html: embed-resources: true toc: true toc_float: true theme: cyborg editor: visual"
  },
  {
    "objectID": "Quatro_Bilbio.html#libraries",
    "href": "Quatro_Bilbio.html#libraries",
    "title": "Bibliometrix_Northumbria",
    "section": "Libraries",
    "text": "Libraries\n\nlibrary(openalexR)\nlibrary(tidyverse)\nlibrary(yarrr)\nlibrary(wordcloud)\nlibrary(wordcloud2)\nlibrary(bibliometrix)\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(EGAnet)\nlibrary(papaja)\nlibrary(janitor)\nlibrary(gtools)\nlibrary(data.table)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(HiveR)\nlibrary(RBioFabric) #Installation: install.packages(\"remotes\")\n                    #remotes::install_github(\"wjrl/RBioFabric\")"
  },
  {
    "objectID": "Quatro_Bilbio.html#scopus",
    "href": "Quatro_Bilbio.html#scopus",
    "title": "Bibliometrix_Northumbria",
    "section": "Scopus",
    "text": "Scopus\n2000 max BibTex for export\n\nAll Open Access\nSearch terms for all open access, scopus:\nAFFIL(northumbria AND university) AND (OA (all)) AND (LIMIT-TO(PUBYEAR, 2023) OR LIMIT-TO(PUBYEAR,2022))\n\nscopus1000df <- convert2df(file = \"scopus2000alloa.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopusRESTdf <- convert2df(file = \"scopusall30.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopus_all_oa<- merge(scopusRESTdf, scopus1000df, all = TRUE) #Scopus has a 2000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n\nGreen Open Access\nSearch terms for all green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repository) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusGreen.bib\"\n\nscopus_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nGreen Final Open Access\nSearch terms for final green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repositoryvor) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusGREENFINALOA.bib\"\n\nscopus_green_final <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nGreen Accepted Open Access\nSearch terms for accepted green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repositoryam) AND NOT OA(repositoryvor) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusGREENACCEPTEDOA.bib\"\n\nscopus_green_accepted <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nNot Green Open Access\nSearch terms for all other types of open access (gold, hybrid gold and bronze), scopus:\nAFFIL(northumbria AND university) AND NOT OA(repository) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusNOTGREEN.bib\"\n\nscopus_not_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")"
  },
  {
    "objectID": "Quatro_Bilbio.html#web-of-science",
    "href": "Quatro_Bilbio.html#web-of-science",
    "title": "Bibliometrix_Northumbria",
    "section": "Web of Science",
    "text": "Web of Science\n1000 max BibTex for export\n\nAll Open Access\nLink to query for all open access:\nhttps://www.webofscience.com/wos/woscc/summary/76daec0d-afe7-4d19-9b33-afbcaf4ac927-797e5bf7/relevance/1\n\nwos1000df <- convert2df(file = \"wosALLOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTdf <- convert2df(file = \"wosALLrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_all_oa<- merge(wosRESTdf, wos1000df, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n\nAll Green Open Access\nLink to query for all open access:\nhttps://www.webofscience.com/wos/woscc/summary/c535d015-7a95-4b5b-9dca-0309ca62c4f2-797fe8f3/relevance/1\n\nfile <- \"wosAllGreen.bib\"\n\nwos_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nNot Green Open Access\nLink to query for not green open access:\nhttps://www.webofscience.com/wos/woscc/summary/3a3b1916-43f6-48a3-a03e-fc9e4041374b-7980065f/relevance/1\n\nfile <- \"wosNOTGREEN.bib\"\n\nwos_not_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nGreen Final Open Access\nLink to query for final open access:\nhttps://www.webofscience.com/wos/woscc/summary/26c9a11c-54fa-4bed-80d9-7c1592eb28c7-798058d2/relevance/1\n\nfile <- \"wosFinal.bib\"\n\nwos_green_final <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nGreen Accepted Open Access\nLink to query for accepted open access:\nhttps://www.webofscience.com/wos/woscc/summary/ff65467a-69e4-480c-8e34-bd8788e4fb56-79807445/relevance/1\n\nwos1000Accepteddf <- convert2df(file = \"wosAcceptedOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTAccepteddf <- convert2df(file = \"wosAcceptedrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_green_accepted<- merge(wosRESTAccepteddf, wos1000Accepteddf, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one"
  },
  {
    "objectID": "Quatro_Bilbio.html#open-alex",
    "href": "Quatro_Bilbio.html#open-alex",
    "title": "Bibliometrix_Northumbria",
    "section": "Open Alex",
    "text": "Open Alex\nAPI access.\nPolite Pool\nFaster access! Doesn’t need to be ran.\n\noptions(openalexR.mailto = \"c.malcolm@northumbria.ac.uk\") #Put email in \"\" if accessing the polite pool\n\n\nAll Open Access\n\nopen_alex_not_green <- oa_fetch(\n  entity = \"works\",\n  authorships.institutions.id = \"I32394136\",\n  oa_status = c(\"green\", \"bronze\", \"gold\", \"hybrid\"),\n  from_publication_date = \"2021-01-01\",\n  to_publication_date = \"2023-03-16\",)\n\n\n\nAll Green Open Access\n\nopen_alex_green <- oa_fetch(\n  entity = \"works\",\n  authorships.institutions.id = \"I32394136\",\n  oa_status = \"green\",\n  from_publication_date = \"2021-01-01\",\n  to_publication_date = \"2023-03-16\",)\n\n\n\nGreen Accepted and Final Open Access\n\nopen_alex_accepted <- oa_fetch(\n  entity = \"works\",\n  authorships.institutions.id = \"I32394136\",\n  has_oa_accepted_or_published_version = TRUE,\n  from_publication_date = \"2021-01-01\",\n  to_publication_date = \"2023-03-16\",)\n\n\n\nNot Green Open Access\n\nopen_alex_not_green <- oa_fetch(\n  entity = \"works\",\n  authorships.institutions.id = \"I32394136\",\n  oa_status = c(\"bronze\", \"gold\", \"hybrid\"),\n  from_publication_date = \"2021-01-01\",\n  to_publication_date = \"2023-03-08\",)"
  },
  {
    "objectID": "Quatro_Bilbio.html#scopus-merge-with-web-of-science",
    "href": "Quatro_Bilbio.html#scopus-merge-with-web-of-science",
    "title": "Bibliometrix_Northumbria",
    "section": "Scopus merge with Web of Science",
    "text": "Scopus merge with Web of Science\nOpenAlex does not have bilbiometrix compatible data.\nAll Open Access\n\ncommon_col_all_oa_names <- intersect(names(scopus_all_oa), names(wos_all_oa)) #Find common column names\nscopus_wos_all_oa <- merge(scopus_all_oa, wos_all_oa, by=common_col_all_oa_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen\n\ncommon_col_green_names <- intersect(names(scopus_green), names(wos_green)) #Find common column names\nscopus_wos_green <- merge(scopus_green, wos_green, by=common_col_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen Final\n\ncommon_col_green_final_names <- intersect(names(scopus_green_final), names(wos_green_final)) #Find common column names\nscopus_wos_green_final <- merge(scopus_green_final, wos_green_final, by=common_col_green_final_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen Accepted\n\ncommon_col_green_accepted_names <- intersect(names(scopus_green_accepted), names(wos_green_accepted)) #Find common column names\nscopus_wos_green_accepted <- merge(scopus_green_accepted, wos_green_accepted, by=common_col_green_accepted_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nNot Green\n\ncommon_col_not_green_names <- intersect(names(scopus_not_green), names(wos_not_green)) #Find common column names\nscopus_wos_not_green <- merge(scopus_not_green, wos_not_green, by=common_col_not_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\n\nJust Corresponding authors\nCleaning to just corresponding authors\n\nall_oa_corr <- scopus_wos_all_oa %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nall_oa_single_authors<- all_oa_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_corr <- scopus_wos_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_single_authors<- green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_final_corr <- scopus_wos_green_final %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_final_single_authors<- green_final_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_accepted_corr <- scopus_wos_green_accepted %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_accepted_single_authors<- green_accepted_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\nnot_green_corr <- scopus_wos_not_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nnot_green_single_authors<- not_green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\n\nall_oa_single_authors$RP <- sub(';.*', \"\" , as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub(',',\"\", as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub('\\\\.',\"\", as.character(all_oa_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_all_oa <- subset(all_oa_single_authors, AU == RP)\n\ngreen_single_authors$RP <- sub(';.*', \"\" , as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub(',',\"\", as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green <- subset(green_single_authors, AU == RP)\n\ngreen_final_single_authors$RP <- sub(';.*', \"\" , as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub(',',\"\", as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_final_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_final <- subset(green_final_single_authors, AU == RP)\n\ngreen_accepted_single_authors$RP <- sub(';.*', \"\" , as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub(',',\"\", as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_accepted_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_accepted <- subset(green_accepted_single_authors, AU == RP)\n\nnot_green_single_authors$RP <- sub(';.*', \"\" , as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub(',',\"\", as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub('\\\\.',\"\", as.character(not_green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_not_green <- subset(not_green_single_authors, AU == RP)\n\nCheck for duplicates!\n\nduplicates_green_green<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green_accepted, by='DI')\n\nduplicates_not_green_green_final<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green, by='DI')\n\nduplicates_not_green_green_acccepted<-inner_join(scopus_wos_not_green, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nduplicates_green_final_green_acccepted<-inner_join(scopus_green_final, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nSeparating corresponding authors into separate tables.\nPrep for wordclouds\n\ncorr_table_all_oa<-table(rp_single_author_all_oa$AU)\ncorr_table_all_oa_sorted <- corr_table_all_oa%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green<-table(rp_single_author_green$AU)\ncorr_table_green_sorted <- corr_table_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green_final<-table(rp_single_author_green_final$AU)\ncorr_table_green_final_sorted <- corr_table_green_final%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green_accepted<-table(rp_single_author_green_accepted$AU)\ncorr_table_green_accepted_sorted <- corr_table_green_accepted%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_not_green<-table(rp_single_author_not_green$AU)\ncorr_table_not_green_sorted <- corr_table_not_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSeparate tables for Open Access publications\n\nSO_table_all_oa<-table(scopus_wos_all_oa$SO)\nSO_table_all_oa_sorted <- SO_table_all_oa%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green<-table(scopus_wos_green$SO)\nSO_table_green_sorted <- SO_table_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green_final<-table(scopus_wos_green_final$SO)\nSO_table_green_final_sorted <- SO_table_green_final%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green_accepted<-table(scopus_wos_green_accepted$SO)\nSO_table_green_accepted_sorted <- SO_table_green_accepted%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_not_green<-table(scopus_wos_not_green$SO)\nSO_table_not_green_sorted <- SO_table_not_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))"
  },
  {
    "objectID": "Quatro_Bilbio.html#publications",
    "href": "Quatro_Bilbio.html#publications",
    "title": "Bibliometrix_Northumbria",
    "section": "Publications",
    "text": "Publications\nYarrr package seems to be best for vibrant and differing colours!\nAll Open Access\n\nset.seed(1404)\n\nDF_SO_table_all_oa_sorted <- as.data.frame(SO_table_all_oa_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_all_oa_sorted$Var1, freq = DF_SO_table_all_oa_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nGreen\n\nDF_SO_table_green_sorted <- as.data.frame(SO_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_green_sorted$Var1, freq = DF_SO_table_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nGreen Final\n\nDF_SO_table_green_final_sorted <- as.data.frame(SO_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = DF_SO_table_green_final_sorted$Var1, freq = DF_SO_table_green_final_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nGreen Accepted\n\nDF_SO_table_green_accepted_sorted <- as.data.frame(SO_table_green_accepted_sorted)\nwourdcloud_green_accepted_publications<- wordcloud(words = DF_SO_table_green_accepted_sorted$Var1, freq = DF_SO_table_green_accepted_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nNot Green\n\nDF_SO_table_not_green_sorted <- as.data.frame(SO_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = DF_SO_table_not_green_sorted$Var1, freq = DF_SO_table_not_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(.25,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small"
  },
  {
    "objectID": "Quatro_Bilbio.html#corresponding-authors",
    "href": "Quatro_Bilbio.html#corresponding-authors",
    "title": "Bibliometrix_Northumbria",
    "section": "Corresponding Authors",
    "text": "Corresponding Authors\nAll Open Access\n\ndf_corr_table_all_oa_sorted <- as.data.frame(corr_table_all_oa_sorted)\nwourdcloud_all_oa_publications<- wordcloud(words = df_corr_table_all_oa_sorted$Var1, freq = df_corr_table_all_oa_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen\n\ndf_corr_table_green_sorted <- as.data.frame(corr_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_sorted$Var1, freq = df_corr_table_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen Final\n\ndf_corr_table_green_final_sorted <- as.data.frame(corr_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = df_corr_table_green_final_sorted$Var1, freq = df_corr_table_green_final_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen Accepted\n\ndf_corr_table_green_accepted_sorted <- as.data.frame(corr_table_green_accepted_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_accepted_sorted$Var1, freq = df_corr_table_green_accepted_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nNot Green\n\ndf_corr_table_not_green_sorted <- as.data.frame(corr_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = df_corr_table_not_green_sorted$Var1, freq = df_corr_table_not_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50"
  },
  {
    "objectID": "Quatro_Bilbio.html#keywords",
    "href": "Quatro_Bilbio.html#keywords",
    "title": "Bibliometrix_Northumbria",
    "section": "Keywords",
    "text": "Keywords\nAll Open Access\n\nall_oa_keywords<- scopus_wos_all_oa %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nall_oa_keywords<- all_oa_keywords %>% \n  count(DE)\nall_oa_keywords<- na.omit(all_oa_keywords)\ncolnames(all_oa_keywords)[2]<- \"Freq\"\nwourdcloud_just_all_oa_keywords<- wordcloud(words = all_oa_keywords$DE, freq = all_oa_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen\n\ngreen_keywords<- scopus_wos_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_keywords<- green_keywords %>% \n  count(DE)\ngreen_keywords<- na.omit(green_keywords)\ncolnames(green_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_keywords<- wordcloud(words = green_keywords$DE, freq = green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nFinal Green\n\ngreen_final_keywords<- scopus_wos_green_final %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_final_keywords<- green_final_keywords %>% \n  count(DE)\ngreen_final_keywords<- na.omit(green_final_keywords)\ncolnames(green_final_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_final_keywords<- wordcloud(words = green_final_keywords$DE, freq = green_final_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nAccepted Green\n\ngreen_accepted_keywords<- scopus_wos_green_accepted %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_accepted_keywords<- green_accepted_keywords %>% \n  count(DE)\ngreen_accepted_keywords<- na.omit(green_accepted_keywords)\ncolnames(green_accepted_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_accepted_keywords<- wordcloud(words = green_accepted_keywords$DE, freq = green_accepted_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nNot Green\n\nnot_green_keywords<- scopus_wos_not_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nnot_green_keywords<- not_green_keywords %>% \n  count(DE)\nnot_green_keywords<- na.omit(not_green_keywords)\ncolnames(not_green_keywords)[2]<- \"Freq\"\nwourdcloud_just_not_green_keywords<- wordcloud(words = not_green_keywords$DE, freq = not_green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50"
  },
  {
    "objectID": "Quatro_Bilbio.html#citedness",
    "href": "Quatro_Bilbio.html#citedness",
    "title": "Bibliometrix_Northumbria",
    "section": "Citedness",
    "text": "Citedness\n\nsingle_author_table_all_oa_cited<- rp_single_author_all_oa %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_all_oa_cited <- subset(single_author_table_all_oa_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_all_oa_atleast_one_citation <- subset(single_author_table_all_oa_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_cited<- rp_single_author_green %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_cited <- subset(single_author_table_green_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_atleast_one_citation <- subset(single_author_table_green_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_final_cited<- rp_single_author_green_final %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_final_cited <- subset(single_author_table_green_final_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_final_atleast_one_citation <- subset(single_author_table_green_final_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_accepted_cited<- rp_single_author_green_accepted %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_accepted_cited <- subset(single_author_table_green_accepted_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_accepted_atleast_one_citation <- subset(single_author_table_green_accepted_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_not_green_cited<- rp_single_author_not_green %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_not_green_cited <- subset(single_author_table_not_green_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_not_green_atleast_one_citation <- subset(single_author_table_not_green_cited, TC >= 1 ) #Remove authors with no citations\n\n\nPublications with at least one citation\nProportion of publications that have at least one citation.\nAll Open Access\n\nsum( ( single_author_table_all_oa_cited$TC >= 1 ) / length( single_author_table_all_oa_cited$TC ) )\n\n[1] 0.5264\n\n\nGreen\n\nsum( ( single_author_table_green_cited$TC >= 1 ) / length( single_author_table_green_cited$TC ) )\n\n[1] 0.5378289\n\n\nFinal Green\n\nsum( ( single_author_table_green_final_cited$TC >= 1 ) / length( single_author_table_green_final_cited$TC ) )\n\n[1] 0.5518868\n\n\nGreen Accepted\n\nsum( ( single_author_table_green_accepted_cited$TC >= 1 ) / length( single_author_table_green_accepted_cited$TC ) )\n\n[1] 0.530303\n\n\nNot Green\n\nsum( ( single_author_table_not_green_cited$TC >= 1 ) / length( single_author_table_not_green_cited$TC ) )\n\n[1] 0.45625\n\n\n\n\nComparisons between open access status\n\nsingle_author_table_all_oa_cited_status <- cbind(single_author_table_all_oa_cited, oa_status = \"All Open Access\")\n\nsingle_author_table_green_cited_status <- cbind(single_author_table_green_cited, oa_status = \"Green\")\n\nsingle_author_table_green_final_cited_status <- cbind(single_author_table_green_final_cited, oa_status = \"Green Final\")\n\nsingle_author_table_green_accepted_cited_status <- cbind(single_author_table_green_accepted_cited, oa_status = \"Green Accepted\")\n\nsingle_author_table_not_green_cited_status <- cbind(single_author_table_not_green_cited, oa_status = \"Not\")\n\nfull_oa_for_analysis <- rbind(single_author_table_green_cited_status, single_author_table_green_final_cited_status, single_author_table_green_accepted_cited_status, single_author_table_not_green_cited_status)\n\nfull_oa_for_analysis$cited <- ifelse(full_oa_for_analysis$TC>=1 & full_oa_for_analysis$TC>=1, 1, 0)\n\nfull_oa_for_analysis <- full_oa_for_analysis %>% \n  mutate(green_or_not = case_when(str_detect(oa_status, \"Green|Green Final|Green Accepted\" ) ~ \"1\",\n                           str_detect(oa_status, \"Not\" ) ~ \"0\"))\n\nmodel_all <- glm(cited ~ green_or_not ,data=full_oa_for_analysis, family=binomial)\nsummary(model_all)\n\n\nCall:\nglm(formula = cited ~ green_or_not, family = binomial, data = full_oa_for_analysis)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.242  -1.242   1.114   1.114   1.253  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)  \n(Intercept)    -0.1754     0.1587  -1.105   0.2690  \ngreen_or_not1   0.3271     0.1688   1.937   0.0527 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1903.1  on 1375  degrees of freedom\nResidual deviance: 1899.3  on 1374  degrees of freedom\nAIC: 1903.3\n\nNumber of Fisher Scoring iterations: 3"
  },
  {
    "objectID": "Quatro_Bilbio.html#author-collaboration-for-corresponding-authors",
    "href": "Quatro_Bilbio.html#author-collaboration-for-corresponding-authors",
    "title": "Bibliometrix_Northumbria",
    "section": "Author Collaboration for Corresponding Authors",
    "text": "Author Collaboration for Corresponding Authors\nSummary statistics : Size, Density, Transitivity, Diameter (length of shortest path between nodes in a network), Degree distribution, Degree centralization, Closeness centralization, Eigenvector centralization, Betweeness centralization, Average path length.\nAll Open Access\nSummary Statistics\n\nall_oa_corr <- all_oa_corr[!duplicated(all_oa_corr$DI),]\nall_oa_corr$SR <- NULL\nall_oa_corr$SR_FULL <-NULL ##Seemed to hold problem duplicates I couldn't get rid of without removing publictaions so I just dropped the columns for all_oa.Not useful anyway.\nnet_matrix_all_oa <- biblioNetwork(all_oa_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_all_oa <- networkStat(net_matrix_all_oa)\n\nsummary(net_stat_all_oa, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2432 \n Density                               0.004 \n Transitivity                          0.88 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.11 \n \n\n\nPage Rank\n\nnet_all_oa_all<- networkStat(net_matrix_all_oa, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_all_oa_interesting <- as.data.frame(net_all_oa_all[[\"vertex\"]])\nall_oa_page_rank <- net_all_oa_interesting[with(net_all_oa_interesting,order(-vertexPageRank)),]\n\nall_oa_page_rank <- all_oa_page_rank[1:25,]\nall_oa_page_rank_top_25 <- all_oa_page_rank %>% select(c(vertexID, vertexPageRank))\n\nall_oa_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002388547\nTORUN H                     TORUN H    0.002043633\nHOWATSON G               HOWATSON G    0.001657070\nFINCH T                     FINCH T    0.001593615\nWU Q                           WU Q    0.001587371\nSCOTT J                     SCOTT J    0.001544451\nMAQBOOL R                 MAQBOOL R    0.001518126\nFU Y                           FU Y    0.001502761\nPOLLET TV                 POLLET TV    0.001447671\nMARZBAND M               MARZBAND M    0.001439754\nGUO Z                         GUO Z    0.001433217\nCORDIER R                 CORDIER R    0.001418108\nBARRY G                     BARRY G    0.001403227\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001402974\nTHURAIRAJAH N         THURAIRAJAH N    0.001379891\nGODFREY A                 GODFREY A    0.001333202\nSTUART S                   STUART S    0.001321611\nDICKENS GL               DICKENS GL    0.001297331\nSHANG Y                     SHANG Y    0.001286809\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001262781\nGAO Z                         GAO Z    0.001253900\nMCCARTY K                 MCCARTY K    0.001204470\nWANG K                       WANG K    0.001196364\nAVERY L                     AVERY L    0.001190158\nFU YQ                         FU YQ    0.001179159\n\n\nNetwork Plot\n(Need to figure out how to have large networks that aren’t just hairballs)\n\nnet_all_oa <- networkPlot(net_matrix_all_oa, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = .5)\n\n\n\n\nGreen\nSummary Statistics\n\nnet_matrix_green <- biblioNetwork(green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green <- networkStat(net_matrix_green)\nsummary(net_stat_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2398 \n Density                               0.004 \n Transitivity                          0.885 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.416 \n \n\n\nPage Rank\n\nnet_green_all<- networkStat(net_matrix_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_interesting <- as.data.frame(net_green_all[[\"vertex\"]])\ngreen_page_rank <- net_green_interesting[with(net_green_interesting,order(-vertexPageRank)),]\n\ngreen_page_rank <- green_page_rank[1:25,]\ngreen_page_rank_top_25 <- green_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002267625\nTORUN H                     TORUN H    0.001975115\nHOWATSON G               HOWATSON G    0.001680174\nWU Q                           WU Q    0.001627842\nFINCH T                     FINCH T    0.001622863\nSCOTT J                     SCOTT J    0.001579656\nMARZBAND M               MARZBAND M    0.001559428\nMAQBOOL R                 MAQBOOL R    0.001538928\nFU Y                           FU Y    0.001520925\nPOLLET TV                 POLLET TV    0.001467563\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001423749\nBARRY G                     BARRY G    0.001411267\nCORDIER R                 CORDIER R    0.001404416\nGODFREY A                 GODFREY A    0.001349880\nSTUART S                   STUART S    0.001337827\nDICKENS GL               DICKENS GL    0.001326286\nTHURAIRAJAH N         THURAIRAJAH N    0.001311004\nSHANG Y                     SHANG Y    0.001305311\nGUO Z                         GUO Z    0.001293999\nGAO Z                         GAO Z    0.001272333\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001263434\nMCCARTY K                 MCCARTY K    0.001221042\nWANG K                       WANG K    0.001218286\nAVERY L                     AVERY L    0.001207882\nFU YQ                         FU YQ    0.001207161\n\n\nNetwork Plot\n\nnet_green <- networkPlot(net_matrix_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)\n\n\n\n\nFinal Green\nSummary Statistics\n\nnet_matrix_green_final <- biblioNetwork(green_final_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_final <- networkStat(net_matrix_green_final)\n\nsummary(net_stat_green_final, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1207 \n Density                               0.01 \n Transitivity                          0.958 \n Diameter                              13 \n Degree Centralization                 0.047 \n Average path length                   4.613 \n \n\n\nPage Rank\n\nnet_green_final_all<- networkStat(net_matrix_green_final, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_final_interesting <- as.data.frame(net_green_final_all[[\"vertex\"]])\ngreen_final_page_rank <- net_green_final_interesting[with(net_green_final_interesting,order(-vertexPageRank)),]\n\ngreen_final_page_rank <- green_final_page_rank[1:25,]\ngreen_final_page_rank_top_25 <- green_final_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_final_page_rank_top_25\n\n                           vertexID vertexPageRank\nFINCH T                     FINCH T    0.002924918\nHOWATSON G               HOWATSON G    0.002655933\nCORDIER R                 CORDIER R    0.002600564\nSCOTT J                     SCOTT J    0.002494150\nDICKENS GL               DICKENS GL    0.002365268\nBARRY G                     BARRY G    0.002318322\nAVERY L                     AVERY L    0.002312757\nPOOLOGANATHAN K     POOLOGANATHAN K    0.002309373\nTORUN H                     TORUN H    0.002141325\nGODFREY A                 GODFREY A    0.002118096\nSTUART S                   STUART S    0.002015907\nFU Y                           FU Y    0.002005366\nDEFEYTER MA             DEFEYTER MA    0.001983977\nTIWARI D                   TIWARI D    0.001918697\nGONZÁLEZ S               GONZÁLEZ S    0.001823282\nWOO WL                       WOO WL    0.001768242\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001763044\nCOVENTRY L               COVENTRY L    0.001746669\nXU BB                         XU BB    0.001727298\nKIERNAN MD               KIERNAN MD    0.001693775\nGATHEESHGAR P         GATHEESHGAR P    0.001649280\nPAN C                         PAN C    0.001621367\nWANG K                       WANG K    0.001621367\nCORRADI M                 CORRADI M    0.001585191\nHETTINGA FJ             HETTINGA FJ    0.001572971\n\n\nNetwork Plot\n\nnet_green_final <- networkPlot(net_matrix_green_final, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 1)\n\n\n\n\nGreen Accepted\nSummary Statistics\n\nnet_matrix_green_accepted <- biblioNetwork(green_accepted_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_accepted <- networkStat(net_matrix_green_accepted)\n\nsummary(net_stat_green_accepted, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1452 \n Density                               0.004 \n Transitivity                          0.774 \n Diameter                              15 \n Degree Centralization                 0.03 \n Average path length                   4.49 \n \n\n\nPage Rank\n\nnet_green_accepted_all<- networkStat(net_matrix_green_accepted, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_accepted_interesting <- as.data.frame(net_green_accepted_all[[\"vertex\"]])\ngreen_accepted_page_rank <- net_green_accepted_interesting[with(net_green_accepted_interesting,order(-vertexPageRank)),]\n\ngreen_accepted_page_rank <- green_accepted_page_rank[1:25,]\ngreen_accepted_page_rank_top_25 <- green_accepted_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_accepted_page_rank_top_25\n\n                       vertexID vertexPageRank\nXU BB                     XU BB    0.003023673\nWU Q                       WU Q    0.002545427\nTORUN H                 TORUN H    0.002428556\nMAQBOOL R             MAQBOOL R    0.002307804\nPOLLET TV             POLLET TV    0.002304099\nTHURAIRAJAH N     THURAIRAJAH N    0.002273221\nGUO Z                     GUO Z    0.002252070\nSHANG Y                 SHANG Y    0.002231116\nFU YQ                     FU YQ    0.002174649\nMARZBAND M           MARZBAND M    0.002147596\nWANG Y                   WANG Y    0.001975717\nGAO Z                     GAO Z    0.001901558\nPOUND MJ               POUND MJ    0.001896643\nVU MC                     VU MC    0.001883560\nSTUART S               STUART S    0.001811813\nYANG L                   YANG L    0.001754185\nNEAVE N                 NEAVE N    0.001744772\nPOOLOGANATHAN K POOLOGANATHAN K    0.001705948\nLIM M                     LIM M    0.001693244\nADENIYI O             ADENIYI O    0.001624033\nASLAM N                 ASLAM N    0.001619280\nAZIMOV U               AZIMOV U    0.001610623\nUNSWORTH J           UNSWORTH J    0.001591190\nDEARY ME               DEARY ME    0.001588631\nYUAN J                   YUAN J    0.001584682\n\n\nNetwork Plot\n\nnet_green_accepted <- networkPlot(net_matrix_green_accepted, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)\n\n\n\n\nNot Green\nSummary Statistics\n\nnet_matrix_not_green<- biblioNetwork(not_green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_not_green <- networkStat(net_matrix_not_green)\n\nsummary(net_stat_not_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  649 \n Density                               0.009 \n Transitivity                          0.621 \n Diameter                              9 \n Degree Centralization                 0.078 \n Average path length                   3.722 \n \n\n\nPage Rank\n\nnet_not_green_all<- networkStat(net_matrix_not_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_not_green_interesting <- as.data.frame(net_not_green_all[[\"vertex\"]])\nnot_green_page_rank <- net_not_green_interesting[with(net_not_green_interesting,order(-vertexPageRank)),]\n\nnot_green_page_rank <- not_green_page_rank[1:25,]\nnot_green_page_rank_top_25 <- not_green_page_rank %>% select(c(vertexID, vertexPageRank))\n\nnot_green_page_rank_top_25\n\n                       vertexID vertexPageRank\nWU Q                       WU Q    0.006783042\nJAHANKHANI H       JAHANKHANI H    0.005922758\nXU BB                     XU BB    0.005831571\nPOOLOGANATHAN K POOLOGANATHAN K    0.005295464\nFU YQ                     FU YQ    0.005258701\nGUO Z                     GUO Z    0.005250989\nGATHEESHGAR P     GATHEESHGAR P    0.004711329\nMARZBAND M           MARZBAND M    0.004274064\nYUAN J                   YUAN J    0.004045065\nALGADI H               ALGADI H    0.003792800\nZHOU X                   ZHOU X    0.003787891\nXING L                   XING L    0.003688906\nLI H                       LI H    0.003634541\nTORUN H                 TORUN H    0.003548481\nALLEN G                 ALLEN G    0.003533428\nCORRADI M             CORRADI M    0.003357814\nLIU B                     LIU B    0.003253078\nZHANG Y                 ZHANG Y    0.003220641\nGODFREY A             GODFREY A    0.003049035\nSTUART S               STUART S    0.003049035\nGHASSEMLOOY Z     GHASSEMLOOY Z    0.002911522\nMAQBOOL R             MAQBOOL R    0.002862371\nDAS J                     DAS J    0.002809138\nSHAMS SMR             SHAMS SMR    0.002762666\nELLIOTT IC           ELLIOTT IC    0.002729203\n\n\nNetwork Plot\n\nnet_not_green <- networkPlot(net_matrix_not_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=.7,edgesize = 5)\n\n\n\n\n(Alternate Network Visualizations) Biofrabric\n\nall_oa_graph <- igraph::graph.adjacency(net_matrix_all_oa                                                                             \n                                   , mode=\"undirected\"                                                                   \n                                   , weighted=TRUE) \n\n\nclusterlouvain <- cluster_louvain(all_oa_graph)\nclusterlouvain\n\nIGRAPH clustering multi level, groups: 259, mod: 0.94\n+ groups:\n  $`1`\n   [1] \"STUART S\"        \"GODFREY A\"       \"BARRY G\"         \"MORRIS R\"        \"MASON R\"         \"WALKER R\"       \n   [7] \"BAKER K\"         \"POWELL D\"        \"DAS J\"           \"YOUNG F\"         \"MANCINI M\"       \"NAISBY J\"       \n  [13] \"PEARSON LT\"      \"VITORIO R\"       \"CELIK Y\"         \"DISMORE L\"       \"GRAHAM L\"        \"HAND A\"         \n  [19] \"LI G\"            \"MCDONALD C\"      \"MONTAGUE K\"      \"OMAN P\"          \"WALL C\"          \"ZHANG Y\"        \n  [25] \"AHMAD B\"         \"AMJAD A\"         \"ARAUJO-SOARES V\" \"ASLAN MF\"        \"BAKER A\"         \"BALAAM M\"       \n  [31] \"BEHM DG\"         \"BELMONT M\"       \"BUTTERFIELD A\"   \"BYERLEY J\"       \"CAMPBELL KR\"     \"CARVALHO L\"     \n  [37] \"CLARKSON CE\"     \"CLEAR AK\"        \"COULBY G\"        \"COVASSIN T\"      \"DEVER A\"         \"DISMORE LL\"     \n  [43] \"EDWARDS C\"       \"GHATTAS H\"       \"GRAY WK\"         \"GUAN Y\"          \"GUERREIRO T\"     \"HARDING C\"      \n  [49] \"HARGREAVES E\"    \"JACKSON D\"       \"JONES O\"         \"KANDALA NB\"      \"KERNOHAN A\"      \"KING LA\"        \n  + ... omitted several groups/vertices\n\n\nUgly hair ball :-(\n\nplot(all_oa_graph, vertex.color=rainbow(7, alpha=0.6)[clusterlouvain$membership])\n\n\n\n\n\nheight <- vcount(all_oa_graph)\nwidth <- ecount(all_oa_graph)\naspect <- height / width;\nplotWidth <- 10.0\nplotHeight <- plotWidth * (aspect * 1.2)\npdf(\"myBioFabricOutput.pdf\", width=plotWidth, height=plotHeight)\nbioFabric(all_oa_graph)\n\nWarning in graph.bfs(bfGraphPass1, startIndex, neimode = \"all\"): Argument `neimode' is deprecated; use `mode' instead\n\ndev.off() ## Possibly of interest, but not viewable in html as far as I know.\n\npng \n  2"
  },
  {
    "objectID": "Quatro_Bilbio.html#hive-plots-attempts",
    "href": "Quatro_Bilbio.html#hive-plots-attempts",
    "title": "Bibliometrix_Northumbria",
    "section": "Hive Plots (Attempts)",
    "text": "Hive Plots (Attempts)\nGreen Final is missing two columns, checked other data sets the columns are empty anyway. So removing for rbind.\n\nrp_single_author_green <- subset(rp_single_author_green, select = -c(SE, molecular_seqnumbers))\nrp_single_author_not_green<- subset(rp_single_author_not_green, select = -c(SE, meeting))\nrp_single_author_green_accepted <- subset(rp_single_author_green_accepted, select = -c(SE, molecular_seqnumbers))\n\nData preparation. Creating oa_status and then linking by oa_status for axis.\n\nfull_green_with_status <- cbind(rp_single_author_green, oa_status = \"Green\")\n\nfull_green_final_with_status <- cbind(rp_single_author_green_final, oa_status = \"Green Final\")\n\nfull_green_accepted_with_status <- cbind(rp_single_author_green_accepted, oa_status = \"Green Accepted\")\n\nfull_not_green_with_status <- cbind(rp_single_author_not_green, oa_status = \"Not\")\n\n\nfull_oa_for_hive <- rbind(full_green_with_status, full_green_final_with_status, full_green_accepted_with_status, full_not_green_with_status)   \n\n\ngraph <- graph_from_data_frame(full_oa_for_hive)\n\nWarning in graph_from_data_frame(full_oa_for_hive): In `d' `NA' elements were replaced with string \"NA\"\n\nV(graph)$AU <- degree(graph, mode = 'in')\n\nV(graph)$AU <- ifelse(V(graph)$AU < 1, 'few', \n                           ifelse(V(graph)$AU >= 10, 'many', 'medium'))\n\nggraph(graph, 'hive', axis = AU, sort.by = 'degree') + \n  geom_edge_hive(aes(colour = factor(oa_status))) +\n  geom_axis_hive(aes(colour = AU), size = 3, label = FALSE) + \n  coord_fixed()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nTesting with Highschool data for hive plot- Highschool its just a data frame with from and to showing the links between nodes along with year they went to school. Relatively simple\nTo recreate this with author collaboration should be able to take each author and demonstrate the collaboration links."
  },
  {
    "objectID": "Quatro_Biblio.html",
    "href": "Quatro_Biblio.html",
    "title": "Bibliometrix_Northumbria",
    "section": "",
    "text": "library(openalexR)\nlibrary(tidyverse)\nlibrary(yarrr)\nlibrary(wordcloud)\nlibrary(wordcloud2)\nlibrary(bibliometrix)\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(EGAnet)\nlibrary(papaja)\nlibrary(janitor)\nlibrary(gtools)\nlibrary(data.table)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(HiveR)\nlibrary(RBioFabric) #Installation: install.packages(\"remotes\")\n                    #remotes::install_github(\"wjrl/RBioFabric\")"
  },
  {
    "objectID": "Quatro_Biblio.html#scopus",
    "href": "Quatro_Biblio.html#scopus",
    "title": "Bibliometrix_Northumbria",
    "section": "Scopus",
    "text": "Scopus\n2000 max BibTex for export\n\nAll Open Access\nSearch terms for all open access, scopus:\nAFFIL(northumbria AND university) AND (OA (all)) AND (LIMIT-TO(PUBYEAR, 2023) OR LIMIT-TO(PUBYEAR,2022))\n\nscopus1000df <- convert2df(file = \"scopus2000alloa.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopusRESTdf <- convert2df(file = \"scopusall30.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopus_all_oa<- merge(scopusRESTdf, scopus1000df, all = TRUE) #Scopus has a 2000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n\nGreen Open Access\nSearch terms for all green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repository) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusGreen.bib\"\n\nscopus_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nGreen Final Open Access\nSearch terms for final green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repositoryvor) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusGREENFINALOA.bib\"\n\nscopus_green_final <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nGreen Accepted Open Access\nSearch terms for accepted green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repositoryam) AND NOT OA(repositoryvor) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusGREENACCEPTEDOA.bib\"\n\nscopus_green_accepted <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nNot Green Open Access\nSearch terms for all other types of open access (gold, hybrid gold and bronze), scopus:\nAFFIL(northumbria AND university) AND NOT OA(repository) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022) )\n\nfile <- \"scopusNOTGREEN.bib\"\n\nscopus_not_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")"
  },
  {
    "objectID": "Quatro_Biblio.html#web-of-science",
    "href": "Quatro_Biblio.html#web-of-science",
    "title": "Bibliometrix_Northumbria",
    "section": "Web of Science",
    "text": "Web of Science\n1000 max BibTex for export\n\nAll Open Access\nLink to query for all open access:\nhttps://www.webofscience.com/wos/woscc/summary/76daec0d-afe7-4d19-9b33-afbcaf4ac927-797e5bf7/relevance/1\n\nwos1000df <- convert2df(file = \"wosALLOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTdf <- convert2df(file = \"wosALLrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_all_oa<- merge(wosRESTdf, wos1000df, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n\nAll Green Open Access\nLink to query for all open access:\nhttps://www.webofscience.com/wos/woscc/summary/c535d015-7a95-4b5b-9dca-0309ca62c4f2-797fe8f3/relevance/1\n\nfile <- \"wosAllGreen.bib\"\n\nwos_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nNot Green Open Access\nLink to query for not green open access:\nhttps://www.webofscience.com/wos/woscc/summary/3a3b1916-43f6-48a3-a03e-fc9e4041374b-7980065f/relevance/1\n\nfile <- \"wosNOTGREEN.bib\"\n\nwos_not_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nGreen Final Open Access\nLink to query for final open access:\nhttps://www.webofscience.com/wos/woscc/summary/26c9a11c-54fa-4bed-80d9-7c1592eb28c7-798058d2/relevance/1\n\nfile <- \"wosFinal.bib\"\n\nwos_green_final <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nGreen Accepted Open Access\nLink to query for accepted open access:\nhttps://www.webofscience.com/wos/woscc/summary/ff65467a-69e4-480c-8e34-bd8788e4fb56-79807445/relevance/1\n\nwos1000Accepteddf <- convert2df(file = \"wosAcceptedOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTAccepteddf <- convert2df(file = \"wosAcceptedrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_green_accepted<- merge(wosRESTAccepteddf, wos1000Accepteddf, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one"
  },
  {
    "objectID": "Quatro_Biblio.html#scopus-merge-with-web-of-science",
    "href": "Quatro_Biblio.html#scopus-merge-with-web-of-science",
    "title": "Bibliometrix_Northumbria",
    "section": "Scopus merge with Web of Science",
    "text": "Scopus merge with Web of Science\nOpenAlex does not have bilbiometrix compatible data.\nAll Open Access\n\ncommon_col_all_oa_names <- intersect(names(scopus_all_oa), names(wos_all_oa)) #Find common column names\nscopus_wos_all_oa <- merge(scopus_all_oa, wos_all_oa, by=common_col_all_oa_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen\n\ncommon_col_green_names <- intersect(names(scopus_green), names(wos_green)) #Find common column names\nscopus_wos_green <- merge(scopus_green, wos_green, by=common_col_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen Final\n\ncommon_col_green_final_names <- intersect(names(scopus_green_final), names(wos_green_final)) #Find common column names\nscopus_wos_green_final <- merge(scopus_green_final, wos_green_final, by=common_col_green_final_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen Accepted\n\ncommon_col_green_accepted_names <- intersect(names(scopus_green_accepted), names(wos_green_accepted)) #Find common column names\nscopus_wos_green_accepted <- merge(scopus_green_accepted, wos_green_accepted, by=common_col_green_accepted_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nNot Green\n\ncommon_col_not_green_names <- intersect(names(scopus_not_green), names(wos_not_green)) #Find common column names\nscopus_wos_not_green <- merge(scopus_not_green, wos_not_green, by=common_col_not_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\n\nJust Corresponding authors\nCleaning to just corresponding authors\n\nall_oa_corr <- scopus_wos_all_oa %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nall_oa_single_authors<- all_oa_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_corr <- scopus_wos_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_single_authors<- green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_final_corr <- scopus_wos_green_final %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_final_single_authors<- green_final_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_accepted_corr <- scopus_wos_green_accepted %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_accepted_single_authors<- green_accepted_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\nnot_green_corr <- scopus_wos_not_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nnot_green_single_authors<- not_green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\n\nall_oa_single_authors$RP <- sub(';.*', \"\" , as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub(',',\"\", as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub('\\\\.',\"\", as.character(all_oa_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_all_oa <- subset(all_oa_single_authors, AU == RP)\n\ngreen_single_authors$RP <- sub(';.*', \"\" , as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub(',',\"\", as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green <- subset(green_single_authors, AU == RP)\n\ngreen_final_single_authors$RP <- sub(';.*', \"\" , as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub(',',\"\", as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_final_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_final <- subset(green_final_single_authors, AU == RP)\n\ngreen_accepted_single_authors$RP <- sub(';.*', \"\" , as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub(',',\"\", as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_accepted_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_accepted <- subset(green_accepted_single_authors, AU == RP)\n\nnot_green_single_authors$RP <- sub(';.*', \"\" , as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub(',',\"\", as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub('\\\\.',\"\", as.character(not_green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_not_green <- subset(not_green_single_authors, AU == RP)\n\nCheck for duplicates!\n\nduplicates_green_green<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green_accepted, by='DI')\n\nduplicates_not_green_green_final<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green, by='DI')\n\nduplicates_not_green_green_acccepted<-inner_join(scopus_wos_not_green, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nduplicates_green_final_green_acccepted<-inner_join(scopus_green_final, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nSeparating corresponding authors into separate tables.\nPrep for wordclouds\n\ncorr_table_all_oa<-table(rp_single_author_all_oa$AU)\ncorr_table_all_oa_sorted <- corr_table_all_oa%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green<-table(rp_single_author_green$AU)\ncorr_table_green_sorted <- corr_table_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green_final<-table(rp_single_author_green_final$AU)\ncorr_table_green_final_sorted <- corr_table_green_final%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_green_accepted<-table(rp_single_author_green_accepted$AU)\ncorr_table_green_accepted_sorted <- corr_table_green_accepted%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\ncorr_table_not_green<-table(rp_single_author_not_green$AU)\ncorr_table_not_green_sorted <- corr_table_not_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSeparate tables for Open Access publications\n\nSO_table_all_oa<-table(scopus_wos_all_oa$SO)\nSO_table_all_oa_sorted <- SO_table_all_oa%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green<-table(scopus_wos_green$SO)\nSO_table_green_sorted <- SO_table_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green_final<-table(scopus_wos_green_final$SO)\nSO_table_green_final_sorted <- SO_table_green_final%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_green_accepted<-table(scopus_wos_green_accepted$SO)\nSO_table_green_accepted_sorted <- SO_table_green_accepted%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))\n\nSO_table_not_green<-table(scopus_wos_not_green$SO)\nSO_table_not_green_sorted <- SO_table_not_green%>%                 \n  as.data.frame() %>% \n  arrange(desc(Freq))"
  },
  {
    "objectID": "Quatro_Biblio.html#publications",
    "href": "Quatro_Biblio.html#publications",
    "title": "Bibliometrix_Northumbria",
    "section": "Publications",
    "text": "Publications\nYarrr package seems to be best for vibrant and differing colours!\nAll Open Access\n\nset.seed(1404)\n\nDF_SO_table_all_oa_sorted <- as.data.frame(SO_table_all_oa_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_all_oa_sorted$Var1, freq = DF_SO_table_all_oa_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nGreen\n\nDF_SO_table_green_sorted <- as.data.frame(SO_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_green_sorted$Var1, freq = DF_SO_table_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nGreen Final\n\nDF_SO_table_green_final_sorted <- as.data.frame(SO_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = DF_SO_table_green_final_sorted$Var1, freq = DF_SO_table_green_final_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nGreen Accepted\n\nDF_SO_table_green_accepted_sorted <- as.data.frame(SO_table_green_accepted_sorted)\nwourdcloud_green_accepted_publications<- wordcloud(words = DF_SO_table_green_accepted_sorted$Var1, freq = DF_SO_table_green_accepted_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\nNot Green\n\nDF_SO_table_not_green_sorted <- as.data.frame(SO_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = DF_SO_table_not_green_sorted$Var1, freq = DF_SO_table_not_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(.25,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small"
  },
  {
    "objectID": "Quatro_Biblio.html#corresponding-authors",
    "href": "Quatro_Biblio.html#corresponding-authors",
    "title": "Bibliometrix_Northumbria",
    "section": "Corresponding Authors",
    "text": "Corresponding Authors\nAll Open Access\n\ndf_corr_table_all_oa_sorted <- as.data.frame(corr_table_all_oa_sorted)\nwourdcloud_all_oa_publications<- wordcloud(words = df_corr_table_all_oa_sorted$Var1, freq = df_corr_table_all_oa_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen\n\ndf_corr_table_green_sorted <- as.data.frame(corr_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_sorted$Var1, freq = df_corr_table_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen Final\n\ndf_corr_table_green_final_sorted <- as.data.frame(corr_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = df_corr_table_green_final_sorted$Var1, freq = df_corr_table_green_final_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen Accepted\n\ndf_corr_table_green_accepted_sorted <- as.data.frame(corr_table_green_accepted_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_accepted_sorted$Var1, freq = df_corr_table_green_accepted_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nNot Green\n\ndf_corr_table_not_green_sorted <- as.data.frame(corr_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = df_corr_table_not_green_sorted$Var1, freq = df_corr_table_not_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50"
  },
  {
    "objectID": "Quatro_Biblio.html#keywords",
    "href": "Quatro_Biblio.html#keywords",
    "title": "Bibliometrix_Northumbria",
    "section": "Keywords",
    "text": "Keywords\nAll Open Access\n\nall_oa_keywords<- scopus_wos_all_oa %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nall_oa_keywords<- all_oa_keywords %>% \n  count(DE)\nall_oa_keywords<- na.omit(all_oa_keywords)\ncolnames(all_oa_keywords)[2]<- \"Freq\"\nwourdcloud_just_all_oa_keywords<- wordcloud(words = all_oa_keywords$DE, freq = all_oa_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nGreen\n\ngreen_keywords<- scopus_wos_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_keywords<- green_keywords %>% \n  count(DE)\ngreen_keywords<- na.omit(green_keywords)\ncolnames(green_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_keywords<- wordcloud(words = green_keywords$DE, freq = green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nFinal Green\n\ngreen_final_keywords<- scopus_wos_green_final %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_final_keywords<- green_final_keywords %>% \n  count(DE)\ngreen_final_keywords<- na.omit(green_final_keywords)\ncolnames(green_final_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_final_keywords<- wordcloud(words = green_final_keywords$DE, freq = green_final_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nAccepted Green\n\ngreen_accepted_keywords<- scopus_wos_green_accepted %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_accepted_keywords<- green_accepted_keywords %>% \n  count(DE)\ngreen_accepted_keywords<- na.omit(green_accepted_keywords)\ncolnames(green_accepted_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_accepted_keywords<- wordcloud(words = green_accepted_keywords$DE, freq = green_accepted_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\nNot Green\n\nnot_green_keywords<- scopus_wos_not_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nnot_green_keywords<- not_green_keywords %>% \n  count(DE)\nnot_green_keywords<- na.omit(not_green_keywords)\ncolnames(not_green_keywords)[2]<- \"Freq\"\nwourdcloud_just_not_green_keywords<- wordcloud(words = not_green_keywords$DE, freq = not_green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50"
  },
  {
    "objectID": "Quatro_Biblio.html#citedness",
    "href": "Quatro_Biblio.html#citedness",
    "title": "Bibliometrix_Northumbria",
    "section": "Citedness",
    "text": "Citedness\n\nsingle_author_table_all_oa_cited<- rp_single_author_all_oa %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_all_oa_cited <- subset(single_author_table_all_oa_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_all_oa_atleast_one_citation <- subset(single_author_table_all_oa_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_cited<- rp_single_author_green %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_cited <- subset(single_author_table_green_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_atleast_one_citation <- subset(single_author_table_green_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_final_cited<- rp_single_author_green_final %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_final_cited <- subset(single_author_table_green_final_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_final_atleast_one_citation <- subset(single_author_table_green_final_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_accepted_cited<- rp_single_author_green_accepted %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_accepted_cited <- subset(single_author_table_green_accepted_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_accepted_atleast_one_citation <- subset(single_author_table_green_accepted_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_not_green_cited<- rp_single_author_not_green %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_not_green_cited <- subset(single_author_table_not_green_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_not_green_atleast_one_citation <- subset(single_author_table_not_green_cited, TC >= 1 ) #Remove authors with no citations\n\n\nPublications with at least one citation\nProportion of publications that have at least one citation.\nAll Open Access\n\nsum( ( single_author_table_all_oa_cited$TC >= 1 ) / length( single_author_table_all_oa_cited$TC ) )\n\n[1] 0.5264\n\n\nGreen\n\nsum( ( single_author_table_green_cited$TC >= 1 ) / length( single_author_table_green_cited$TC ) )\n\n[1] 0.5378289\n\n\nFinal Green\n\nsum( ( single_author_table_green_final_cited$TC >= 1 ) / length( single_author_table_green_final_cited$TC ) )\n\n[1] 0.5518868\n\n\nGreen Accepted\n\nsum( ( single_author_table_green_accepted_cited$TC >= 1 ) / length( single_author_table_green_accepted_cited$TC ) )\n\n[1] 0.530303\n\n\nNot Green\n\nsum( ( single_author_table_not_green_cited$TC >= 1 ) / length( single_author_table_not_green_cited$TC ) )\n\n[1] 0.45625\n\n\n\n\nComparisons between open access status\n\nsingle_author_table_all_oa_cited_status <- cbind(single_author_table_all_oa_cited, oa_status = \"All Open Access\")\n\nsingle_author_table_green_cited_status <- cbind(single_author_table_green_cited, oa_status = \"Green\")\n\nsingle_author_table_green_final_cited_status <- cbind(single_author_table_green_final_cited, oa_status = \"Green Final\")\n\nsingle_author_table_green_accepted_cited_status <- cbind(single_author_table_green_accepted_cited, oa_status = \"Green Accepted\")\n\nsingle_author_table_not_green_cited_status <- cbind(single_author_table_not_green_cited, oa_status = \"Not\")\n\nfull_oa_for_analysis <- rbind(single_author_table_green_cited_status, single_author_table_green_final_cited_status, single_author_table_green_accepted_cited_status, single_author_table_not_green_cited_status)\n\nfull_oa_for_analysis$cited <- ifelse(full_oa_for_analysis$TC>=1 & full_oa_for_analysis$TC>=1, 1, 0)\n\nfull_oa_for_analysis <- full_oa_for_analysis %>% \n  mutate(green_or_not = case_when(str_detect(oa_status, \"Green|Green Final|Green Accepted\" ) ~ \"1\",\n                           str_detect(oa_status, \"Not\" ) ~ \"0\"))\n\nmodel_all <- glm(cited ~ green_or_not ,data=full_oa_for_analysis, family=binomial)\nsummary(model_all)\n\n\nCall:\nglm(formula = cited ~ green_or_not, family = binomial, data = full_oa_for_analysis)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.242  -1.242   1.114   1.114   1.253  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)  \n(Intercept)    -0.1754     0.1587  -1.105   0.2690  \ngreen_or_not1   0.3271     0.1688   1.937   0.0527 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1903.1  on 1375  degrees of freedom\nResidual deviance: 1899.3  on 1374  degrees of freedom\nAIC: 1903.3\n\nNumber of Fisher Scoring iterations: 3"
  },
  {
    "objectID": "Quatro_Biblio.html#author-collaboration-for-corresponding-authors",
    "href": "Quatro_Biblio.html#author-collaboration-for-corresponding-authors",
    "title": "Bibliometrix_Northumbria",
    "section": "Author Collaboration for Corresponding Authors",
    "text": "Author Collaboration for Corresponding Authors\nSummary statistics : Size, Density, Transitivity, Diameter (length of shortest path between nodes in a network), Degree distribution, Degree centralization, Closeness centralization, Eigenvector centralization, Betweeness centralization, Average path length.\nAll Open Access\nSummary Statistics\n\nall_oa_corr <- all_oa_corr[!duplicated(all_oa_corr$DI),]\nall_oa_corr$SR <- NULL\nall_oa_corr$SR_FULL <-NULL ##Seemed to hold problem duplicates I couldn't get rid of without removing publictaions so I just dropped the columns for all_oa.Not useful anyway.\nnet_matrix_all_oa <- biblioNetwork(all_oa_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_all_oa <- networkStat(net_matrix_all_oa)\n\nsummary(net_stat_all_oa, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2432 \n Density                               0.004 \n Transitivity                          0.88 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.11 \n \n\n\nPage Rank\n\nnet_all_oa_all<- networkStat(net_matrix_all_oa, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_all_oa_interesting <- as.data.frame(net_all_oa_all[[\"vertex\"]])\nall_oa_page_rank <- net_all_oa_interesting[with(net_all_oa_interesting,order(-vertexPageRank)),]\n\nall_oa_page_rank <- all_oa_page_rank[1:25,]\nall_oa_page_rank_top_25 <- all_oa_page_rank %>% select(c(vertexID, vertexPageRank))\n\nall_oa_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002388547\nTORUN H                     TORUN H    0.002043633\nHOWATSON G               HOWATSON G    0.001657070\nFINCH T                     FINCH T    0.001593615\nWU Q                           WU Q    0.001587371\nSCOTT J                     SCOTT J    0.001544451\nMAQBOOL R                 MAQBOOL R    0.001518126\nFU Y                           FU Y    0.001502761\nPOLLET TV                 POLLET TV    0.001447671\nMARZBAND M               MARZBAND M    0.001439754\nGUO Z                         GUO Z    0.001433217\nCORDIER R                 CORDIER R    0.001418108\nBARRY G                     BARRY G    0.001403227\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001402974\nTHURAIRAJAH N         THURAIRAJAH N    0.001379891\nGODFREY A                 GODFREY A    0.001333202\nSTUART S                   STUART S    0.001321611\nDICKENS GL               DICKENS GL    0.001297331\nSHANG Y                     SHANG Y    0.001286809\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001262781\nGAO Z                         GAO Z    0.001253900\nMCCARTY K                 MCCARTY K    0.001204470\nWANG K                       WANG K    0.001196364\nAVERY L                     AVERY L    0.001190158\nFU YQ                         FU YQ    0.001179159\n\n\nNetwork Plot\n(Need to figure out how to have large networks that aren’t just hairballs)\n\nnet_all_oa <- networkPlot(net_matrix_all_oa, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = .5)\n\n\n\n\nGreen\nSummary Statistics\n\nnet_matrix_green <- biblioNetwork(green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green <- networkStat(net_matrix_green)\nsummary(net_stat_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2398 \n Density                               0.004 \n Transitivity                          0.885 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.416 \n \n\n\nPage Rank\n\nnet_green_all<- networkStat(net_matrix_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_interesting <- as.data.frame(net_green_all[[\"vertex\"]])\ngreen_page_rank <- net_green_interesting[with(net_green_interesting,order(-vertexPageRank)),]\n\ngreen_page_rank <- green_page_rank[1:25,]\ngreen_page_rank_top_25 <- green_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002267625\nTORUN H                     TORUN H    0.001975115\nHOWATSON G               HOWATSON G    0.001680174\nWU Q                           WU Q    0.001627842\nFINCH T                     FINCH T    0.001622863\nSCOTT J                     SCOTT J    0.001579656\nMARZBAND M               MARZBAND M    0.001559428\nMAQBOOL R                 MAQBOOL R    0.001538928\nFU Y                           FU Y    0.001520925\nPOLLET TV                 POLLET TV    0.001467563\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001423749\nBARRY G                     BARRY G    0.001411267\nCORDIER R                 CORDIER R    0.001404416\nGODFREY A                 GODFREY A    0.001349880\nSTUART S                   STUART S    0.001337827\nDICKENS GL               DICKENS GL    0.001326286\nTHURAIRAJAH N         THURAIRAJAH N    0.001311004\nSHANG Y                     SHANG Y    0.001305311\nGUO Z                         GUO Z    0.001293999\nGAO Z                         GAO Z    0.001272333\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001263434\nMCCARTY K                 MCCARTY K    0.001221042\nWANG K                       WANG K    0.001218286\nAVERY L                     AVERY L    0.001207882\nFU YQ                         FU YQ    0.001207161\n\n\nNetwork Plot\n\nnet_green <- networkPlot(net_matrix_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)\n\n\n\n\nFinal Green\nSummary Statistics\n\nnet_matrix_green_final <- biblioNetwork(green_final_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_final <- networkStat(net_matrix_green_final)\n\nsummary(net_stat_green_final, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1207 \n Density                               0.01 \n Transitivity                          0.958 \n Diameter                              13 \n Degree Centralization                 0.047 \n Average path length                   4.613 \n \n\n\nPage Rank\n\nnet_green_final_all<- networkStat(net_matrix_green_final, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_final_interesting <- as.data.frame(net_green_final_all[[\"vertex\"]])\ngreen_final_page_rank <- net_green_final_interesting[with(net_green_final_interesting,order(-vertexPageRank)),]\n\ngreen_final_page_rank <- green_final_page_rank[1:25,]\ngreen_final_page_rank_top_25 <- green_final_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_final_page_rank_top_25\n\n                           vertexID vertexPageRank\nFINCH T                     FINCH T    0.002924918\nHOWATSON G               HOWATSON G    0.002655933\nCORDIER R                 CORDIER R    0.002600564\nSCOTT J                     SCOTT J    0.002494150\nDICKENS GL               DICKENS GL    0.002365268\nBARRY G                     BARRY G    0.002318322\nAVERY L                     AVERY L    0.002312757\nPOOLOGANATHAN K     POOLOGANATHAN K    0.002309373\nTORUN H                     TORUN H    0.002141325\nGODFREY A                 GODFREY A    0.002118096\nSTUART S                   STUART S    0.002015907\nFU Y                           FU Y    0.002005366\nDEFEYTER MA             DEFEYTER MA    0.001983977\nTIWARI D                   TIWARI D    0.001918697\nGONZÁLEZ S               GONZÁLEZ S    0.001823282\nWOO WL                       WOO WL    0.001768242\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001763044\nCOVENTRY L               COVENTRY L    0.001746669\nXU BB                         XU BB    0.001727298\nKIERNAN MD               KIERNAN MD    0.001693775\nGATHEESHGAR P         GATHEESHGAR P    0.001649280\nPAN C                         PAN C    0.001621367\nWANG K                       WANG K    0.001621367\nCORRADI M                 CORRADI M    0.001585191\nHETTINGA FJ             HETTINGA FJ    0.001572971\n\n\nNetwork Plot\n\nnet_green_final <- networkPlot(net_matrix_green_final, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 1)\n\n\n\n\nGreen Accepted\nSummary Statistics\n\nnet_matrix_green_accepted <- biblioNetwork(green_accepted_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_accepted <- networkStat(net_matrix_green_accepted)\n\nsummary(net_stat_green_accepted, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1452 \n Density                               0.004 \n Transitivity                          0.774 \n Diameter                              15 \n Degree Centralization                 0.03 \n Average path length                   4.49 \n \n\n\nPage Rank\n\nnet_green_accepted_all<- networkStat(net_matrix_green_accepted, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_accepted_interesting <- as.data.frame(net_green_accepted_all[[\"vertex\"]])\ngreen_accepted_page_rank <- net_green_accepted_interesting[with(net_green_accepted_interesting,order(-vertexPageRank)),]\n\ngreen_accepted_page_rank <- green_accepted_page_rank[1:25,]\ngreen_accepted_page_rank_top_25 <- green_accepted_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_accepted_page_rank_top_25\n\n                       vertexID vertexPageRank\nXU BB                     XU BB    0.003023673\nWU Q                       WU Q    0.002545427\nTORUN H                 TORUN H    0.002428556\nMAQBOOL R             MAQBOOL R    0.002307804\nPOLLET TV             POLLET TV    0.002304099\nTHURAIRAJAH N     THURAIRAJAH N    0.002273221\nGUO Z                     GUO Z    0.002252070\nSHANG Y                 SHANG Y    0.002231116\nFU YQ                     FU YQ    0.002174649\nMARZBAND M           MARZBAND M    0.002147596\nWANG Y                   WANG Y    0.001975717\nGAO Z                     GAO Z    0.001901558\nPOUND MJ               POUND MJ    0.001896643\nVU MC                     VU MC    0.001883560\nSTUART S               STUART S    0.001811813\nYANG L                   YANG L    0.001754185\nNEAVE N                 NEAVE N    0.001744772\nPOOLOGANATHAN K POOLOGANATHAN K    0.001705948\nLIM M                     LIM M    0.001693244\nADENIYI O             ADENIYI O    0.001624033\nASLAM N                 ASLAM N    0.001619280\nAZIMOV U               AZIMOV U    0.001610623\nUNSWORTH J           UNSWORTH J    0.001591190\nDEARY ME               DEARY ME    0.001588631\nYUAN J                   YUAN J    0.001584682\n\n\nNetwork Plot\n\nnet_green_accepted <- networkPlot(net_matrix_green_accepted, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)\n\n\n\n\nNot Green\nSummary Statistics\n\nnet_matrix_not_green<- biblioNetwork(not_green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_not_green <- networkStat(net_matrix_not_green)\n\nsummary(net_stat_not_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  649 \n Density                               0.009 \n Transitivity                          0.621 \n Diameter                              9 \n Degree Centralization                 0.078 \n Average path length                   3.722 \n \n\n\nPage Rank\n\nnet_not_green_all<- networkStat(net_matrix_not_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_not_green_interesting <- as.data.frame(net_not_green_all[[\"vertex\"]])\nnot_green_page_rank <- net_not_green_interesting[with(net_not_green_interesting,order(-vertexPageRank)),]\n\nnot_green_page_rank <- not_green_page_rank[1:25,]\nnot_green_page_rank_top_25 <- not_green_page_rank %>% select(c(vertexID, vertexPageRank))\n\nnot_green_page_rank_top_25\n\n                       vertexID vertexPageRank\nWU Q                       WU Q    0.006783042\nJAHANKHANI H       JAHANKHANI H    0.005922758\nXU BB                     XU BB    0.005831571\nPOOLOGANATHAN K POOLOGANATHAN K    0.005295464\nFU YQ                     FU YQ    0.005258701\nGUO Z                     GUO Z    0.005250989\nGATHEESHGAR P     GATHEESHGAR P    0.004711329\nMARZBAND M           MARZBAND M    0.004274064\nYUAN J                   YUAN J    0.004045065\nALGADI H               ALGADI H    0.003792800\nZHOU X                   ZHOU X    0.003787891\nXING L                   XING L    0.003688906\nLI H                       LI H    0.003634541\nTORUN H                 TORUN H    0.003548481\nALLEN G                 ALLEN G    0.003533428\nCORRADI M             CORRADI M    0.003357814\nLIU B                     LIU B    0.003253078\nZHANG Y                 ZHANG Y    0.003220641\nGODFREY A             GODFREY A    0.003049035\nSTUART S               STUART S    0.003049035\nGHASSEMLOOY Z     GHASSEMLOOY Z    0.002911522\nMAQBOOL R             MAQBOOL R    0.002862371\nDAS J                     DAS J    0.002809138\nSHAMS SMR             SHAMS SMR    0.002762666\nELLIOTT IC           ELLIOTT IC    0.002729203\n\n\nNetwork Plot\n\nnet_not_green <- networkPlot(net_matrix_not_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=.7,edgesize = 5)\n\n\n\n\n(Alternate Network Visualizations) Biofrabric\n\nall_oa_graph <- igraph::graph.adjacency(net_matrix_all_oa                                                                             \n                                   , mode=\"undirected\"                                                                   \n                                   , weighted=TRUE) \n\n\nclusterlouvain <- cluster_louvain(all_oa_graph)\nclusterlouvain\n\nIGRAPH clustering multi level, groups: 259, mod: 0.94\n+ groups:\n  $`1`\n   [1] \"STUART S\"        \"GODFREY A\"       \"BARRY G\"         \"MORRIS R\"        \"MASON R\"         \"WALKER R\"       \n   [7] \"BAKER K\"         \"POWELL D\"        \"DAS J\"           \"YOUNG F\"         \"MANCINI M\"       \"NAISBY J\"       \n  [13] \"PEARSON LT\"      \"VITORIO R\"       \"CELIK Y\"         \"DISMORE L\"       \"GRAHAM L\"        \"HAND A\"         \n  [19] \"LI G\"            \"MCDONALD C\"      \"MONTAGUE K\"      \"OMAN P\"          \"WALL C\"          \"ZHANG Y\"        \n  [25] \"AHMAD B\"         \"AMJAD A\"         \"ARAUJO-SOARES V\" \"ASLAN MF\"        \"BAKER A\"         \"BALAAM M\"       \n  [31] \"BEHM DG\"         \"BELMONT M\"       \"BUTTERFIELD A\"   \"BYERLEY J\"       \"CAMPBELL KR\"     \"CARVALHO L\"     \n  [37] \"CLARKSON CE\"     \"CLEAR AK\"        \"COULBY G\"        \"COVASSIN T\"      \"DEVER A\"         \"DISMORE LL\"     \n  [43] \"EDWARDS C\"       \"GHATTAS H\"       \"GRAY WK\"         \"GUAN Y\"          \"GUERREIRO T\"     \"HARDING C\"      \n  [49] \"HARGREAVES E\"    \"JACKSON D\"       \"JONES O\"         \"KANDALA NB\"      \"KERNOHAN A\"      \"KING LA\"        \n  + ... omitted several groups/vertices\n\n\nUgly hair ball :-(\n\nplot(all_oa_graph, vertex.color=rainbow(7, alpha=0.6)[clusterlouvain$membership])\n\n\n\n\n\nheight <- vcount(all_oa_graph)\nwidth <- ecount(all_oa_graph)\naspect <- height / width;\nplotWidth <- 10.0\nplotHeight <- plotWidth * (aspect * 1.2)\npdf(\"myBioFabricOutput.pdf\", width=plotWidth, height=plotHeight)\nbioFabric(all_oa_graph)\n\nWarning in graph.bfs(bfGraphPass1, startIndex, neimode = \"all\"): Argument `neimode' is deprecated; use `mode' instead\n\ndev.off() ## Possibly of interest, but not viewable in html as far as I know.\n\npng \n  2"
  },
  {
    "objectID": "Quatro_Biblio.html#hive-plots-attempts",
    "href": "Quatro_Biblio.html#hive-plots-attempts",
    "title": "Bibliometrix_Northumbria",
    "section": "Hive Plots (Attempts)",
    "text": "Hive Plots (Attempts)\nGreen Final is missing two columns, checked other data sets the columns are empty anyway. So removing for rbind.\n\nrp_single_author_green <- subset(rp_single_author_green, select = -c(SE, molecular_seqnumbers))\nrp_single_author_not_green<- subset(rp_single_author_not_green, select = -c(SE, meeting))\nrp_single_author_green_accepted <- subset(rp_single_author_green_accepted, select = -c(SE, molecular_seqnumbers))\n\nData preparation. Creating oa_status and then linking by oa_status for axis.\n\nfull_green_with_status <- cbind(rp_single_author_green, oa_status = \"Green\")\n\nfull_green_final_with_status <- cbind(rp_single_author_green_final, oa_status = \"Green Final\")\n\nfull_green_accepted_with_status <- cbind(rp_single_author_green_accepted, oa_status = \"Green Accepted\")\n\nfull_not_green_with_status <- cbind(rp_single_author_not_green, oa_status = \"Not\")\n\n\nfull_oa_for_hive <- rbind(full_green_with_status, full_green_final_with_status, full_green_accepted_with_status, full_not_green_with_status)   \n\n\ngraph <- graph_from_data_frame(full_oa_for_hive)\n\nWarning in graph_from_data_frame(full_oa_for_hive): In `d' `NA' elements were replaced with string \"NA\"\n\nV(graph)$AU <- degree(graph, mode = 'in')\n\nV(graph)$AU <- ifelse(V(graph)$AU < 1, 'few', \n                           ifelse(V(graph)$AU >= 10, 'many', 'medium'))\n\nggraph(graph, 'hive', axis = AU, sort.by = 'degree') + \n  geom_edge_hive(aes(colour = factor(oa_status))) +\n  geom_axis_hive(aes(colour = AU), size = 3, label = FALSE) + \n  coord_fixed()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nTesting with Highschool data for hive plot- Highschool its just a data frame with from and to showing the links between nodes along with year they went to school. Relatively simple\nTo recreate this with author collaboration should be able to take each author and demonstrate the collaboration links."
  },
  {
    "objectID": "About.html",
    "href": "About.html",
    "title": "About",
    "section": "",
    "text": "A R based document looking at bibliography data from Scopus and Web of Science based on cross department researchers in Northumbria University, who publish open access articles.\nAll Data is publicly available and all search terms used on the bibliographic databases are available as a part of the document.\nThe publications were split into types of open access.\nGreen : Free to read at repository. Published or Accepted. (Combination of Final and Accepted)\nGreen Final : Published article that is free to read at repository.\nGreen Accepted : Accepted for publication that is free to read at repository but not yet published.\nAll Open Access : Any kind of open access.\nNot Green : A combination of Bronze, Gold and Hybrid Gold\nBronze : Published or accepted where author chose to provide permanent or temporary open access. Bronze is applied if there is a license other than a creative common license. Or no licence at all.\nGold : Published with a creative common license and in an only open access journal, available on publisher platform.\nHybrid Gold : Published with a creative common license. Published in a journal that allows for the choice of publishing open access."
  },
  {
    "objectID": "Bibliometric Analysis.html",
    "href": "Bibliometric Analysis.html",
    "title": "Bibliometric Analysis",
    "section": "",
    "text": "data"
  },
  {
    "objectID": "Bibliometric Analysis.html#citedness",
    "href": "Bibliometric Analysis.html#citedness",
    "title": "Bibliometric Analysis",
    "section": "Citedness",
    "text": "Citedness\nDetails around amount of citations for each author.\n\nsingle_author_table_all_oa_cited<- rp_single_author_all_oa %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_all_oa_cited <- subset(single_author_table_all_oa_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_all_oa_atleast_one_citation <- subset(single_author_table_all_oa_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_cited<- rp_single_author_green %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_cited <- subset(single_author_table_green_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_atleast_one_citation <- subset(single_author_table_green_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_final_cited<- rp_single_author_green_final %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_final_cited <- subset(single_author_table_green_final_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_final_atleast_one_citation <- subset(single_author_table_green_final_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_green_accepted_cited<- rp_single_author_green_accepted %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_green_accepted_cited <- subset(single_author_table_green_accepted_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_green_accepted_atleast_one_citation <- subset(single_author_table_green_accepted_cited, TC >= 1 ) #Remove authors with no citations\n\nsingle_author_table_not_green_cited<- rp_single_author_not_green %>% select(c(AU, TI, TC, PY)) #Selected for single authors, publication title, amount of citations and publication year.\nsingle_author_table_not_green_cited <- subset(single_author_table_not_green_cited, PY =='2022' )#Limit to 2022\nsingle_author_table_not_green_atleast_one_citation <- subset(single_author_table_not_green_cited, TC >= 1 ) #Remove authors with no citations"
  },
  {
    "objectID": "Network Attributes and Visualisations.html",
    "href": "Network Attributes and Visualisations.html",
    "title": "Network Attributes and Visualisations",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: jpeg\n\nLoading required package: BayesFactor\n\nLoading required package: coda\n\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n************\nWelcome to BayesFactor 0.9.12-4.4. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n\nLoading required package: circlize\n\n========================================\ncirclize version 0.4.15\nCRAN page: https://cran.r-project.org/package=circlize\nGithub page: https://github.com/jokergoo/circlize\nDocumentation: https://jokergoo.github.io/circlize_book/book/\n\nIf you use it in published research, please cite:\nGu, Z. circlize implements and enhances circular visualization\n  in R. Bioinformatics 2014.\n\nThis message can be suppressed by:\n  suppressPackageStartupMessages(library(circlize))\n========================================\n\n\nyarrr v0.1.5. Citation info at citation('yarrr'). Package guide at yarrr.guide()\n\nEmail me at Nathaniel.D.Phillips.is@gmail.com\n\n\nAttaching package: 'yarrr'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    diamonds\n\n\nLoading required package: RColorBrewer\n\n\nWarning: package 'bibliometrix' was built under R version 4.2.3\n\n\nPlease note that our software is open source and available for use, distributed under the MIT license.\nWhen it is used in a publication, we ask that authors properly cite the following reference:\n\nAria, M. & Cuccurullo, C. (2017) bibliometrix: An R-tool for comprehensive science mapping analysis, \n                        Journal of Informetrics, 11(4), pp 959-975, Elsevier.\n\nFailure to properly cite the software is considered a violation of the license.\n                        \nFor information and bug reports:\n                        - Take a look at https://www.bibliometrix.org\n                        - Send an email to info@bibliometrix.org   \n                        - Write a post on https://github.com/massimoaria/bibliometrix/issues\n                        \nHelp us to keep Bibliometrix and Biblioshiny free to download and use by contributing with a small donation to support our research team (https://bibliometrix.org/donate.html)\n\n                        \nTo start with the Biblioshiny app, please digit:\nbiblioshiny()\n\n\nAttaching package: 'igraph'\n\nThe following object is masked from 'package:circlize':\n\n    degree\n\nThe following object is masked from 'package:BayesFactor':\n\n    compare\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\nThe following object is masked from 'package:base':\n\n    union\n\n\nAttaching package: 'tidygraph'\n\nThe following object is masked from 'package:igraph':\n\n    groups\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\u001b[1;m\u001b[4;m\nEGAnet (version 1.2.3)\u001b[0m\u001b[0m \nFor help getting started, type browseVignettes(\"EGAnet\")\n \nFor bugs and errors, submit an issue to <https://github.com/hfgolino/EGAnet/issues>\nLoading required package: tinylabels\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nAttaching package: 'gtools'\n\nThe following object is masked from 'package:igraph':\n\n    permute\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n\nWarning: package 'HiveR' was built under R version 4.2.3"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#author-collaboration-for-corresponding-authors",
    "href": "Network Attributes and Visualisations.html#author-collaboration-for-corresponding-authors",
    "title": "Network Attributes and Visualisations",
    "section": "Author Collaboration for Corresponding Authors",
    "text": "Author Collaboration for Corresponding Authors\nSummary statistics : Size, Density, Transitivity, Diameter (length of shortest path between nodes in a network), Degree distribution, Degree centralization, Closeness centralization, Eigenvector centralization, Betweeness centralization, Average path length.\nAll Open Access\nSummary Statistics\n\nall_oa_corr <- all_oa_corr[!duplicated(all_oa_corr$DI),]\nall_oa_corr$SR <- NULL\nall_oa_corr$SR_FULL <-NULL ##Seemed to hold problem duplicates I couldn't get rid of without removing publictaions so I just dropped the columns for all_oa.Not useful anyway.\nnet_matrix_all_oa <- biblioNetwork(all_oa_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_all_oa <- networkStat(net_matrix_all_oa)\n\nsummary(net_stat_all_oa, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2432 \n Density                               0.004 \n Transitivity                          0.88 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.11 \n \n\n\nPage Rank\n\nnet_all_oa_all<- networkStat(net_matrix_all_oa, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_all_oa_interesting <- as.data.frame(net_all_oa_all[[\"vertex\"]])\nall_oa_page_rank <- net_all_oa_interesting[with(net_all_oa_interesting,order(-vertexPageRank)),]\n\nall_oa_page_rank <- all_oa_page_rank[1:25,]\nall_oa_page_rank_top_25 <- all_oa_page_rank %>% select(c(vertexID, vertexPageRank))\n\nall_oa_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002388547\nTORUN H                     TORUN H    0.002043633\nHOWATSON G               HOWATSON G    0.001657070\nFINCH T                     FINCH T    0.001593615\nWU Q                           WU Q    0.001587371\nSCOTT J                     SCOTT J    0.001544451\nMAQBOOL R                 MAQBOOL R    0.001518126\nFU Y                           FU Y    0.001502761\nPOLLET TV                 POLLET TV    0.001447671\nMARZBAND M               MARZBAND M    0.001439754\nGUO Z                         GUO Z    0.001433217\nCORDIER R                 CORDIER R    0.001418108\nBARRY G                     BARRY G    0.001403227\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001402974\nTHURAIRAJAH N         THURAIRAJAH N    0.001379891\nGODFREY A                 GODFREY A    0.001333202\nSTUART S                   STUART S    0.001321611\nDICKENS GL               DICKENS GL    0.001297331\nSHANG Y                     SHANG Y    0.001286809\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001262781\nGAO Z                         GAO Z    0.001253900\nMCCARTY K                 MCCARTY K    0.001204470\nWANG K                       WANG K    0.001196364\nAVERY L                     AVERY L    0.001190158\nFU YQ                         FU YQ    0.001179159\n\n\nNetwork Plot\n(Need to figure out how to have large networks that aren’t just hairballs)\n\nnet_all_oa <- networkPlot(net_matrix_all_oa, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = .5)\n\n\n\n\nGreen\nSummary Statistics\n\nnet_matrix_green <- biblioNetwork(green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green <- networkStat(net_matrix_green)\nsummary(net_stat_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2398 \n Density                               0.004 \n Transitivity                          0.885 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.416 \n \n\n\nPage Rank\n\nnet_green_all<- networkStat(net_matrix_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_interesting <- as.data.frame(net_green_all[[\"vertex\"]])\ngreen_page_rank <- net_green_interesting[with(net_green_interesting,order(-vertexPageRank)),]\n\ngreen_page_rank <- green_page_rank[1:25,]\ngreen_page_rank_top_25 <- green_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002267625\nTORUN H                     TORUN H    0.001975115\nHOWATSON G               HOWATSON G    0.001680174\nWU Q                           WU Q    0.001627842\nFINCH T                     FINCH T    0.001622863\nSCOTT J                     SCOTT J    0.001579656\nMARZBAND M               MARZBAND M    0.001559428\nMAQBOOL R                 MAQBOOL R    0.001538928\nFU Y                           FU Y    0.001520925\nPOLLET TV                 POLLET TV    0.001467563\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001423749\nBARRY G                     BARRY G    0.001411267\nCORDIER R                 CORDIER R    0.001404416\nGODFREY A                 GODFREY A    0.001349880\nSTUART S                   STUART S    0.001337827\nDICKENS GL               DICKENS GL    0.001326286\nTHURAIRAJAH N         THURAIRAJAH N    0.001311004\nSHANG Y                     SHANG Y    0.001305311\nGUO Z                         GUO Z    0.001293999\nGAO Z                         GAO Z    0.001272333\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001263434\nMCCARTY K                 MCCARTY K    0.001221042\nWANG K                       WANG K    0.001218286\nAVERY L                     AVERY L    0.001207882\nFU YQ                         FU YQ    0.001207161\n\n\nNetwork Plot\n\nnet_green <- networkPlot(net_matrix_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)\n\n\n\n\nGreen Final\nSummary Statistics\n\nnet_matrix_green_final <- biblioNetwork(green_final_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_final <- networkStat(net_matrix_green_final)\n\nsummary(net_stat_green_final, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1207 \n Density                               0.01 \n Transitivity                          0.958 \n Diameter                              13 \n Degree Centralization                 0.047 \n Average path length                   4.613 \n \n\n\nPage Rank\n\nnet_green_final_all<- networkStat(net_matrix_green_final, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_final_interesting <- as.data.frame(net_green_final_all[[\"vertex\"]])\ngreen_final_page_rank <- net_green_final_interesting[with(net_green_final_interesting,order(-vertexPageRank)),]\n\ngreen_final_page_rank <- green_final_page_rank[1:25,]\ngreen_final_page_rank_top_25 <- green_final_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_final_page_rank_top_25\n\n                           vertexID vertexPageRank\nFINCH T                     FINCH T    0.002924918\nHOWATSON G               HOWATSON G    0.002655933\nCORDIER R                 CORDIER R    0.002600564\nSCOTT J                     SCOTT J    0.002494150\nDICKENS GL               DICKENS GL    0.002365268\nBARRY G                     BARRY G    0.002318322\nAVERY L                     AVERY L    0.002312757\nPOOLOGANATHAN K     POOLOGANATHAN K    0.002309373\nTORUN H                     TORUN H    0.002141325\nGODFREY A                 GODFREY A    0.002118096\nSTUART S                   STUART S    0.002015907\nFU Y                           FU Y    0.002005366\nDEFEYTER MA             DEFEYTER MA    0.001983977\nTIWARI D                   TIWARI D    0.001918697\nGONZÁLEZ S               GONZÁLEZ S    0.001823282\nWOO WL                       WOO WL    0.001768242\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001763044\nCOVENTRY L               COVENTRY L    0.001746669\nXU BB                         XU BB    0.001727298\nKIERNAN MD               KIERNAN MD    0.001693775\nGATHEESHGAR P         GATHEESHGAR P    0.001649280\nPAN C                         PAN C    0.001621367\nWANG K                       WANG K    0.001621367\nCORRADI M                 CORRADI M    0.001585191\nHETTINGA FJ             HETTINGA FJ    0.001572971\n\n\nNetwork Plot\n\nnet_green_final <- networkPlot(net_matrix_green_final, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 1)\n\n\n\n\nGreen Accepted\nSummary Statistics\n\nnet_matrix_green_accepted <- biblioNetwork(green_accepted_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_accepted <- networkStat(net_matrix_green_accepted)\n\nsummary(net_stat_green_accepted, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1452 \n Density                               0.004 \n Transitivity                          0.774 \n Diameter                              15 \n Degree Centralization                 0.03 \n Average path length                   4.49 \n \n\n\nPage Rank\n\nnet_green_accepted_all<- networkStat(net_matrix_green_accepted, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_accepted_interesting <- as.data.frame(net_green_accepted_all[[\"vertex\"]])\ngreen_accepted_page_rank <- net_green_accepted_interesting[with(net_green_accepted_interesting,order(-vertexPageRank)),]\n\ngreen_accepted_page_rank <- green_accepted_page_rank[1:25,]\ngreen_accepted_page_rank_top_25 <- green_accepted_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_accepted_page_rank_top_25\n\n                       vertexID vertexPageRank\nXU BB                     XU BB    0.003023673\nWU Q                       WU Q    0.002545427\nTORUN H                 TORUN H    0.002428556\nMAQBOOL R             MAQBOOL R    0.002307804\nPOLLET TV             POLLET TV    0.002304099\nTHURAIRAJAH N     THURAIRAJAH N    0.002273221\nGUO Z                     GUO Z    0.002252070\nSHANG Y                 SHANG Y    0.002231116\nFU YQ                     FU YQ    0.002174649\nMARZBAND M           MARZBAND M    0.002147596\nWANG Y                   WANG Y    0.001975717\nGAO Z                     GAO Z    0.001901558\nPOUND MJ               POUND MJ    0.001896643\nVU MC                     VU MC    0.001883560\nSTUART S               STUART S    0.001811813\nYANG L                   YANG L    0.001754185\nNEAVE N                 NEAVE N    0.001744772\nPOOLOGANATHAN K POOLOGANATHAN K    0.001705948\nLIM M                     LIM M    0.001693244\nADENIYI O             ADENIYI O    0.001624033\nASLAM N                 ASLAM N    0.001619280\nAZIMOV U               AZIMOV U    0.001610623\nUNSWORTH J           UNSWORTH J    0.001591190\nDEARY ME               DEARY ME    0.001588631\nYUAN J                   YUAN J    0.001584682\n\n\nNetwork Plot\n\nnet_green_accepted <- networkPlot(net_matrix_green_accepted, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)\n\n\n\n\nNot Green\nSummary Statistics\n\nnet_matrix_not_green<- biblioNetwork(not_green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_not_green <- networkStat(net_matrix_not_green)\n\nsummary(net_stat_not_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  649 \n Density                               0.009 \n Transitivity                          0.621 \n Diameter                              9 \n Degree Centralization                 0.078 \n Average path length                   3.722 \n \n\n\nPage Rank\n\nnet_not_green_all<- networkStat(net_matrix_not_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_not_green_interesting <- as.data.frame(net_not_green_all[[\"vertex\"]])\nnot_green_page_rank <- net_not_green_interesting[with(net_not_green_interesting,order(-vertexPageRank)),]\n\nnot_green_page_rank <- not_green_page_rank[1:25,]\nnot_green_page_rank_top_25 <- not_green_page_rank %>% select(c(vertexID, vertexPageRank))\n\nnot_green_page_rank_top_25\n\n                       vertexID vertexPageRank\nWU Q                       WU Q    0.006783042\nJAHANKHANI H       JAHANKHANI H    0.005922758\nXU BB                     XU BB    0.005831571\nPOOLOGANATHAN K POOLOGANATHAN K    0.005295464\nFU YQ                     FU YQ    0.005258701\nGUO Z                     GUO Z    0.005250989\nGATHEESHGAR P     GATHEESHGAR P    0.004711329\nMARZBAND M           MARZBAND M    0.004274064\nYUAN J                   YUAN J    0.004045065\nALGADI H               ALGADI H    0.003792800\nZHOU X                   ZHOU X    0.003787891\nXING L                   XING L    0.003688906\nLI H                       LI H    0.003634541\nTORUN H                 TORUN H    0.003548481\nALLEN G                 ALLEN G    0.003533428\nCORRADI M             CORRADI M    0.003357814\nLIU B                     LIU B    0.003253078\nZHANG Y                 ZHANG Y    0.003220641\nGODFREY A             GODFREY A    0.003049035\nSTUART S               STUART S    0.003049035\nGHASSEMLOOY Z     GHASSEMLOOY Z    0.002911522\nMAQBOOL R             MAQBOOL R    0.002862371\nDAS J                     DAS J    0.002809138\nSHAMS SMR             SHAMS SMR    0.002762666\nELLIOTT IC           ELLIOTT IC    0.002729203\n\n\nNetwork Plot\n\nnet_not_green <- networkPlot(net_matrix_not_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=.7,edgesize = 5)\n\n\n\n\n\nAlternate Network Visualizations\n\nall_oa_graph <- igraph::graph.adjacency(net_matrix_all_oa                                                                             \n                                   , mode=\"undirected\"                                                                   \n                                   , weighted=TRUE) \n\n\nclusterlouvain <- cluster_louvain(all_oa_graph)\nclusterlouvain\n\nIGRAPH clustering multi level, groups: 260, mod: 0.94\n+ groups:\n  $`1`\n   [1] \"STUART S\"        \"GODFREY A\"       \"BARRY G\"         \"MORRIS R\"        \"MASON R\"         \"WALKER R\"       \n   [7] \"BAKER K\"         \"GOODALL S\"       \"POWELL D\"        \"DAS J\"           \"YOUNG F\"         \"ALI M\"          \n  [13] \"MANCINI M\"       \"NAISBY J\"        \"PEARSON LT\"      \"VITORIO R\"       \"CELIK Y\"         \"DISMORE L\"      \n  [19] \"GRAHAM L\"        \"HAND A\"          \"LI G\"            \"MCDONALD C\"      \"MONTAGUE K\"      \"OMAN P\"         \n  [25] \"WALL C\"          \"ZHANG Y\"         \"AFTAB M\"         \"AHMAD B\"         \"AMJAD A\"         \"ARAUJO-SOARES V\"\n  [31] \"ASLAN MF\"        \"BAKER A\"         \"BALAAM M\"        \"BEHM DG\"         \"BELMONT M\"       \"BOKHARI SAA\"    \n  [37] \"BUTTERFIELD A\"   \"BYERLEY J\"       \"CAMPBELL KR\"     \"CARVALHO L\"      \"CLARKSON CE\"     \"CLEAR AK\"       \n  [43] \"COULBY G\"        \"COURT P\"         \"COVASSIN T\"      \"DEVER A\"         \"DISMORE LL\"      \"EDWARDS C\"      \n  [49] \"GHATTAS H\"       \"GRAY WK\"         \"GUAN Y\"          \"GUERREIRO T\"     \"HARDING C\"       \"HARGREAVES E\"   \n  + ... omitted several groups/vertices\n\n\n\nplot(all_oa_graph, vertex.color=rainbow(7, alpha=0.6)[clusterlouvain$membership])"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#hive-plots-attempts",
    "href": "Network Attributes and Visualisations.html#hive-plots-attempts",
    "title": "Network Attributes and Visualisations",
    "section": "Hive Plots (Attempts)",
    "text": "Hive Plots (Attempts)\nGreen Final is missing two columns, checked other data sets the columns are empty anyway. So removing for rbind.\n\nrp_single_author_green <- subset(rp_single_author_green, select = -c(SE, molecular_seqnumbers))\nrp_single_author_not_green<- subset(rp_single_author_not_green, select = -c(SE, meeting))\nrp_single_author_green_accepted <- subset(rp_single_author_green_accepted, select = -c(SE, molecular_seqnumbers))\n\nData preparation. Creating oa_status and then linking by oa_status for axis.\n\nfull_green_with_status <- cbind(rp_single_author_green, oa_status = \"Green\")\n\nfull_green_final_with_status <- cbind(rp_single_author_green_final, oa_status = \"Green Final\")\n\nfull_green_accepted_with_status <- cbind(rp_single_author_green_accepted, oa_status = \"Green Accepted\")\n\nfull_not_green_with_status <- cbind(rp_single_author_not_green, oa_status = \"Not\")\n\n\nfull_oa_for_hive <- rbind(full_green_with_status, full_green_final_with_status, full_green_accepted_with_status, full_not_green_with_status)  \n\n\ngraph <- graph_from_data_frame(full_oa_for_hive)\n\nWarning in graph_from_data_frame(full_oa_for_hive): In `d' `NA' elements were replaced with string \"NA\"\n\nV(graph)$AU <- degree(graph, mode = 'in')\n\nV(graph)$AU <- ifelse(V(graph)$AU < 1, 'few', \n                           ifelse(V(graph)$AU >= 10, 'many', 'medium'))\n\nggraph(graph, 'hive', axis = AU, sort.by = 'degree') + \n  geom_edge_hive(aes(colour = factor(oa_status))) +\n  geom_axis_hive(aes(colour = AU), size = 3, label = FALSE) + \n  coord_fixed()\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\nTesting with Highschool data for hive plot- Highschool its just a data frame with from and to showing the links between nodes along with year they went to school. Relatively simple\nTo recreate this with author collaboration should be able to take each author and demonstrate the collaboration links."
  },
  {
    "objectID": "BibTex Data Import.html",
    "href": "BibTex Data Import.html",
    "title": "BibTex Data",
    "section": "",
    "text": "Packages used across documents.\n\nlibrary(tidyverse)\nlibrary(yarrr)\nlibrary(wordcloud)\nlibrary(wordcloud2)\nlibrary(bibliometrix)\nlibrary(tidyverse)\nlibrary(igraph)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(EGAnet)\nlibrary(papaja)\nlibrary(janitor)\nlibrary(gtools)\nlibrary(data.table)\nlibrary(readr)\nlibrary(ggplot2)\nlibrary(HiveR)\nlibrary(RBioFabric) #Installation: install.packages(\"remotes\")\n                    #remotes::install_github(\"wjrl/RBioFabric\")"
  },
  {
    "objectID": "BibTex Data Import.html#scopus",
    "href": "BibTex Data Import.html#scopus",
    "title": "BibTex Data",
    "section": "Scopus",
    "text": "Scopus\n2000 max BibTex for export\n\nAll Open Access\nSearch terms for all open access, scopus:\nAFFIL(northumbria AND university) AND (OA (all)) AND (LIMIT-TO(PUBYEAR, 2023) OR LIMIT-TO(PUBYEAR,2022))\n\nscopus1000df <- convert2df(file = \"scopus2000alloa.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopusRESTdf <- convert2df(file = \"scopusall30.bib\" , dbsource = \"scopus\", format = \"bibtex\")\nscopus_all_oa<- merge(scopusRESTdf, scopus1000df, all = TRUE) #Scopus has a 2000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n\nGreen Open Access\nSearch terms for all green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repository) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022))\n\nfile <- \"scopusGreen.bib\"\n\nscopus_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nGreen Final Open Access\nSearch terms for final green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repositoryvor) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022))\n\nfile <- \"scopusGREENFINALOA.bib\"\n\nscopus_green_final <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nGreen Accepted Open Access\nSearch terms for accepted green open access, scopus:\nAFFIL(northumbria AND university) AND OA(repositoryam) AND NOT OA(repositoryvor) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022))\n\nfile <- \"scopusGREENACCEPTEDOA.bib\"\n\nscopus_green_accepted <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")\n\n\n\nNot Green Open Access\nSearch terms for all other types of open access (gold, hybrid gold and bronze), scopus:\nAFFIL(northumbria AND university) AND NOT OA(repository) AND ( LIMIT-TO ( PUBYEAR,2023) OR LIMIT-TO ( PUBYEAR,2022))\n\nfile <- \"scopusNOTGREEN.bib\"\n\nscopus_not_green <- convert2df(file = file , dbsource = \"scopus\", format = \"bibtex\")"
  },
  {
    "objectID": "BibTex Data Import.html#web-of-science",
    "href": "BibTex Data Import.html#web-of-science",
    "title": "BibTex Data",
    "section": "Web of Science",
    "text": "Web of Science\n1000 max BibTex for export\n\nAll Open Access\nLink to query for all open access:\nhttps://www.webofscience.com/wos/woscc/summary/76daec0d-afe7-4d19-9b33-afbcaf4ac927-797e5bf7/relevance/1\n\nwos1000df <- convert2df(file = \"wosALLOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTdf <- convert2df(file = \"wosALLrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_all_oa<- merge(wosRESTdf, wos1000df, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one\n\n\n\nAll Green Open Access\nLink to query for all open access:\nhttps://www.webofscience.com/wos/woscc/summary/c535d015-7a95-4b5b-9dca-0309ca62c4f2-797fe8f3/relevance/1\n\nfile <- \"wosAllGreen.bib\"\n\nwos_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nNot Green Open Access\nLink to query for not green open access:\nhttps://www.webofscience.com/wos/woscc/summary/3a3b1916-43f6-48a3-a03e-fc9e4041374b-7980065f/relevance/1\n\nfile <- \"wosNOTGREEN.bib\"\n\nwos_not_green <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nGreen Final Open Access\nLink to query for final open access:\nhttps://www.webofscience.com/wos/woscc/summary/26c9a11c-54fa-4bed-80d9-7c1592eb28c7-798058d2/relevance/1\n\nfile <- \"wosFinal.bib\"\n\nwos_green_final <- convert2df(file = file , dbsource = \"wos\", format = \"bibtex\")\n\n\n\nGreen Accepted Open Access\nLink to query for accepted open access:\nhttps://www.webofscience.com/wos/woscc/summary/ff65467a-69e4-480c-8e34-bd8788e4fb56-79807445/relevance/1\n\nwos1000Accepteddf <- convert2df(file = \"wosAcceptedOA1000.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwosRESTAccepteddf <- convert2df(file = \"wosAcceptedrest.bib\" , dbsource = \"wos\", format = \"bibtex\")\nwos_green_accepted<- merge(wosRESTAccepteddf, wos1000Accepteddf, all = TRUE)#Web of science has a 1000 limit for BibTex files so All Open Access needed to be downloaded into two .bib files and then merged to one"
  },
  {
    "objectID": "Data Cleaning.html",
    "href": "Data Cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.1     ✔ tibble    3.2.0\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\nLoading required package: jpeg\n\nLoading required package: BayesFactor\n\nLoading required package: coda\n\nLoading required package: Matrix\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\n************\nWelcome to BayesFactor 0.9.12-4.4. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n\nLoading required package: circlize\n\n========================================\ncirclize version 0.4.15\nCRAN page: https://cran.r-project.org/package=circlize\nGithub page: https://github.com/jokergoo/circlize\nDocumentation: https://jokergoo.github.io/circlize_book/book/\n\nIf you use it in published research, please cite:\nGu, Z. circlize implements and enhances circular visualization\n  in R. Bioinformatics 2014.\n\nThis message can be suppressed by:\n  suppressPackageStartupMessages(library(circlize))\n========================================\n\n\nyarrr v0.1.5. Citation info at citation('yarrr'). Package guide at yarrr.guide()\n\nEmail me at Nathaniel.D.Phillips.is@gmail.com\n\n\nAttaching package: 'yarrr'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    diamonds\n\n\nLoading required package: RColorBrewer\n\n\nWarning: package 'bibliometrix' was built under R version 4.2.3\n\n\nPlease note that our software is open source and available for use, distributed under the MIT license.\nWhen it is used in a publication, we ask that authors properly cite the following reference:\n\nAria, M. & Cuccurullo, C. (2017) bibliometrix: An R-tool for comprehensive science mapping analysis, \n                        Journal of Informetrics, 11(4), pp 959-975, Elsevier.\n\nFailure to properly cite the software is considered a violation of the license.\n                        \nFor information and bug reports:\n                        - Take a look at https://www.bibliometrix.org\n                        - Send an email to info@bibliometrix.org   \n                        - Write a post on https://github.com/massimoaria/bibliometrix/issues\n                        \nHelp us to keep Bibliometrix and Biblioshiny free to download and use by contributing with a small donation to support our research team (https://bibliometrix.org/donate.html)\n\n                        \nTo start with the Biblioshiny app, please digit:\nbiblioshiny()\n\n\nAttaching package: 'igraph'\n\nThe following object is masked from 'package:circlize':\n\n    degree\n\nThe following object is masked from 'package:BayesFactor':\n\n    compare\n\nThe following objects are masked from 'package:lubridate':\n\n    %--%, union\n\nThe following objects are masked from 'package:dplyr':\n\n    as_data_frame, groups, union\n\nThe following objects are masked from 'package:purrr':\n\n    compose, simplify\n\nThe following object is masked from 'package:tidyr':\n\n    crossing\n\nThe following object is masked from 'package:tibble':\n\n    as_data_frame\n\nThe following objects are masked from 'package:stats':\n\n    decompose, spectrum\n\nThe following object is masked from 'package:base':\n\n    union\n\n\nAttaching package: 'tidygraph'\n\nThe following object is masked from 'package:igraph':\n\n    groups\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\u001b[1;m\u001b[4;m\nEGAnet (version 1.2.3)\u001b[0m\u001b[0m \nFor help getting started, type browseVignettes(\"EGAnet\")\n \nFor bugs and errors, submit an issue to <https://github.com/hfgolino/EGAnet/issues>\nLoading required package: tinylabels\n\nAttaching package: 'janitor'\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\n\nAttaching package: 'gtools'\n\nThe following object is masked from 'package:igraph':\n\n    permute\n\n\nAttaching package: 'data.table'\n\nThe following objects are masked from 'package:lubridate':\n\n    hour, isoweek, mday, minute, month, quarter, second, wday, week,\n    yday, year\n\nThe following objects are masked from 'package:dplyr':\n\n    between, first, last\n\nThe following object is masked from 'package:purrr':\n\n    transpose\n\n\nWarning: package 'HiveR' was built under R version 4.2.3\ndata"
  },
  {
    "objectID": "Data Cleaning.html#scopus-merge-with-web-of-science",
    "href": "Data Cleaning.html#scopus-merge-with-web-of-science",
    "title": "Data Cleaning",
    "section": "Scopus merge with Web of Science",
    "text": "Scopus merge with Web of Science\nMerging Scopus and Web of Science data.\nAll Open Access\n\ncommon_col_all_oa_names <- intersect(names(scopus_all_oa), names(wos_all_oa)) #Find common column names\nscopus_wos_all_oa <- merge(scopus_all_oa, wos_all_oa, by=common_col_all_oa_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen\n\ncommon_col_green_names <- intersect(names(scopus_green), names(wos_green)) #Find common column names\nscopus_wos_green <- merge(scopus_green, wos_green, by=common_col_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen Final\n\ncommon_col_green_final_names <- intersect(names(scopus_green_final), names(wos_green_final)) #Find common column names\nscopus_wos_green_final <- merge(scopus_green_final, wos_green_final, by=common_col_green_final_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nGreen Accepted\n\ncommon_col_green_accepted_names <- intersect(names(scopus_green_accepted), names(wos_green_accepted)) #Find common column names\nscopus_wos_green_accepted <- merge(scopus_green_accepted, wos_green_accepted, by=common_col_green_accepted_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\nNot Green\n\ncommon_col_not_green_names <- intersect(names(scopus_not_green), names(wos_not_green)) #Find common column names\nscopus_wos_not_green <- merge(scopus_not_green, wos_not_green, by=common_col_not_green_names, all.x=TRUE) # Merge data by common column names to check if scopus missed any publications wos has.\n\n\nJust Corresponding authors\nCleaning to just corresponding authors\n\nall_oa_corr <- scopus_wos_all_oa %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nall_oa_single_authors<- all_oa_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_corr <- scopus_wos_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_single_authors<- green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_final_corr <- scopus_wos_green_final %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_final_single_authors<- green_final_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\ngreen_accepted_corr <- scopus_wos_green_accepted %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\ngreen_accepted_single_authors<- green_accepted_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\nnot_green_corr <- scopus_wos_not_green %>% dplyr::filter(grepl(\"@northumbria\",RP, ignore.case = TRUE))\nnot_green_single_authors<- not_green_corr %>% \n    mutate(AU = strsplit(as.character(AU), \";\")) %>%  \n    unnest(AU) #Individual authors\n\n\nall_oa_single_authors$RP <- sub(';.*', \"\" , as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub(',',\"\", as.character(all_oa_single_authors$RP))\nall_oa_single_authors$RP <- gsub('\\\\.',\"\", as.character(all_oa_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_all_oa <- subset(all_oa_single_authors, AU == RP)\n\ngreen_single_authors$RP <- sub(';.*', \"\" , as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub(',',\"\", as.character(green_single_authors$RP))\ngreen_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green <- subset(green_single_authors, AU == RP)\n\ngreen_final_single_authors$RP <- sub(';.*', \"\" , as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub(',',\"\", as.character(green_final_single_authors$RP))\ngreen_final_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_final_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_final <- subset(green_final_single_authors, AU == RP)\n\ngreen_accepted_single_authors$RP <- sub(';.*', \"\" , as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub(',',\"\", as.character(green_accepted_single_authors$RP))\ngreen_accepted_single_authors$RP <- gsub('\\\\.',\"\", as.character(green_accepted_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_green_accepted <- subset(green_accepted_single_authors, AU == RP)\n\nnot_green_single_authors$RP <- sub(';.*', \"\" , as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub(',',\"\", as.character(not_green_single_authors$RP))\nnot_green_single_authors$RP <- gsub('\\\\.',\"\", as.character(not_green_single_authors$RP))\n#Removing problem characters fo filtering to just corresponding authors.\nrp_single_author_not_green <- subset(not_green_single_authors, AU == RP)\n\nCheck for duplicates!\n\nduplicates_green_green<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green_accepted, by='DI')\n\nduplicates_not_green_green_final<-inner_join(scopus_wos_not_green, scopus_wos_green_final, scopus_wos_green, by='DI')\n\nduplicates_not_green_green_acccepted<-inner_join(scopus_wos_not_green, scopus_wos_green_accepted, scopus_wos_green, by='DI')\n\nduplicates_green_final_green_acccepted<-inner_join(scopus_green_final, scopus_wos_green_accepted, scopus_wos_green, by='DI')"
  },
  {
    "objectID": "Word Clouds.html#publications",
    "href": "Word Clouds.html#publications",
    "title": "Word Clouds",
    "section": "Publications",
    "text": "Publications\nYarrr package seems to be best for vibrant and differing colours!\n\nAll Open Access\n\nset.seed(1404)\n\nDF_SO_table_all_oa_sorted <- as.data.frame(SO_table_all_oa_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_all_oa_sorted$Var1, freq = DF_SO_table_all_oa_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\n\n\nGreen\n\nDF_SO_table_green_sorted <- as.data.frame(SO_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = DF_SO_table_green_sorted$Var1, freq = DF_SO_table_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(1.2,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\n\n\nGreen Final\n\nDF_SO_table_green_final_sorted <- as.data.frame(SO_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = DF_SO_table_green_final_sorted$Var1, freq = DF_SO_table_green_final_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\n\n\nGreen Accepted\n\nDF_SO_table_green_accepted_sorted <- as.data.frame(SO_table_green_accepted_sorted)\nwourdcloud_green_accepted_publications<- wordcloud(words = DF_SO_table_green_accepted_sorted$Var1, freq = DF_SO_table_green_accepted_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(0.8,0.05), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small\n\n\n\nNot Green\n\nDF_SO_table_not_green_sorted <- as.data.frame(SO_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = DF_SO_table_not_green_sorted$Var1, freq = DF_SO_table_not_green_sorted$Freq, min.freq = 1, max.words=25, random.order=FALSE, scale=c(.25,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 25\n\n\n\n##To fit long publication names had to make the words pretty small"
  },
  {
    "objectID": "Word Clouds.html#corresponding-authors",
    "href": "Word Clouds.html#corresponding-authors",
    "title": "Word Clouds",
    "section": "Corresponding Authors",
    "text": "Corresponding Authors\n\nAll Open Access\n\ndf_corr_table_all_oa_sorted <- as.data.frame(corr_table_all_oa_sorted)\nwourdcloud_all_oa_publications<- wordcloud(words = df_corr_table_all_oa_sorted$Var1, freq = df_corr_table_all_oa_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nGreen\n\ndf_corr_table_green_sorted <- as.data.frame(corr_table_green_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_sorted$Var1, freq = df_corr_table_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nGreen Final\n\ndf_corr_table_green_final_sorted <- as.data.frame(corr_table_green_final_sorted)\nwourdcloud_green_final_publications<- wordcloud(words = df_corr_table_green_final_sorted$Var1, freq = df_corr_table_green_final_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nGreen Accepted\n\ndf_corr_table_green_accepted_sorted <- as.data.frame(corr_table_green_accepted_sorted)\nwourdcloud_green_publications<- wordcloud(words = df_corr_table_green_accepted_sorted$Var1, freq = df_corr_table_green_accepted_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nNot Green\n\ndf_corr_table_not_green_sorted <- as.data.frame(corr_table_not_green_sorted)\nwourdcloud_not_green_publications<- wordcloud(words = df_corr_table_not_green_sorted$Var1, freq = df_corr_table_not_green_sorted$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1, 1), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50"
  },
  {
    "objectID": "Word Clouds.html#keywords",
    "href": "Word Clouds.html#keywords",
    "title": "Word Clouds",
    "section": "Keywords",
    "text": "Keywords\n\nAll Open Access\n\nall_oa_keywords<- scopus_wos_all_oa %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nall_oa_keywords<- all_oa_keywords %>% \n  count(DE)\nall_oa_keywords<- na.omit(all_oa_keywords)\ncolnames(all_oa_keywords)[2]<- \"Freq\"\nwourdcloud_just_all_oa_keywords<- wordcloud(words = all_oa_keywords$DE, freq = all_oa_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nGreen\n\ngreen_keywords<- scopus_wos_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_keywords<- green_keywords %>% \n  count(DE)\ngreen_keywords<- na.omit(green_keywords)\ncolnames(green_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_keywords<- wordcloud(words = green_keywords$DE, freq = green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nGreen Final\n\ngreen_final_keywords<- scopus_wos_green_final %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_final_keywords<- green_final_keywords %>% \n  count(DE)\ngreen_final_keywords<- na.omit(green_final_keywords)\ncolnames(green_final_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_final_keywords<- wordcloud(words = green_final_keywords$DE, freq = green_final_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nGreen Accepted\n\ngreen_accepted_keywords<- scopus_wos_green_accepted %>% separate_rows(DE, sep = \"; \") %>% select(DE) \ngreen_accepted_keywords<- green_accepted_keywords %>% \n  count(DE)\ngreen_accepted_keywords<- na.omit(green_accepted_keywords)\ncolnames(green_accepted_keywords)[2]<- \"Freq\"\nwourdcloud_just_green_accepted_keywords<- wordcloud(words = green_accepted_keywords$DE, freq = green_accepted_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50\n\n\n\n\n\n\nNot Green\n\nnot_green_keywords<- scopus_wos_not_green %>% separate_rows(DE, sep = \"; \") %>% select(DE) \nnot_green_keywords<- not_green_keywords %>% \n  count(DE)\nnot_green_keywords<- na.omit(not_green_keywords)\ncolnames(not_green_keywords)[2]<- \"Freq\"\nwourdcloud_just_not_green_keywords<- wordcloud(words = not_green_keywords$DE, freq = not_green_keywords$Freq, min.freq = 1, max.words=50, random.order=FALSE, scale=c(1.5,0.25), rot.per=0.35, colors = piratepal(\"xmen\")) ##Just the TOP 50"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#hive-plots",
    "href": "Network Attributes and Visualisations.html#hive-plots",
    "title": "Network Attributes and Visualisations",
    "section": "Hive Plots",
    "text": "Hive Plots\nTaking igraphs from the bilbionetwork object.\n\nhive_green <- net_green[[\"graph\"]]\ngreen_edge <- as_edgelist(hive_green)\ngreen_edge <- cbind(green_edge, oa_status = \"Green\")\ngreen_edge <- as.data.frame(green_edge)\nnames(green_edge)[names(green_edge) == \"V1\"] <- \"From\"\nnames(green_edge)[names(green_edge) == \"V2\"] <- \"To\"\n\nhive_green_accpeted <- net_green_accepted[[\"graph\"]]\ngreen_accepted_edge <- as_edgelist(hive_green_accpeted)\ngreen_accepted_edge <- cbind(green_accepted_edge, oa_status = \"Green Accepted\")\ngreen_accepted_edge <- as.data.frame(green_accepted_edge)\nnames(green_accepted_edge)[names(green_accepted_edge) == \"V1\"] <- \"From\"\nnames(green_accepted_edge)[names(green_accepted_edge) == \"V2\"] <- \"To\"\n\nhive_green_final <- net_green_final[[\"graph\"]]\ngreen_final_edge <- as_edgelist(hive_green_final)\ngreen_final_edge <- cbind(green_final_edge, oa_status = \"Green Final\")\ngreen_final_edge <- as.data.frame(green_final_edge)\nnames(green_final_edge)[names(green_final_edge) == \"V1\"] <- \"From\"\nnames(green_final_edge)[names(green_final_edge) == \"V2\"] <- \"To\"\n\nhive_not_green <- net_not_green[[\"graph\"]]\nnot_green_edge <- as_edgelist(hive_not_green)\nnot_green_edge <- cbind(not_green_edge, oa_status = \"Not Green\")\nnot_green_edge <- as.data.frame(not_green_edge)\nnames(not_green_edge)[names(not_green_edge) == \"V1\"] <- \"From\"\nnames(not_green_edge)[names(not_green_edge) == \"V2\"] <- \"To\"\n\nfull_hive <- rbind(green_edge, green_accepted_edge, green_final_edge, not_green_edge)\n\nThe Hive plot below shows the collaborations between authors in terms of collaboration, differentiated by their open access.\nThe large main hive plot lines are where the nodes (authors) are situated based on three categories. Having few collaborations (less than 5) having medium collaborations (between 5 and 15) and having many collaborations (more than 15) The curved lines signify and edge (collaboration/link between authors).\n\ngraph <- graph_from_data_frame(full_hive)\nV(graph)$Collaboration <- degree(graph, mode = 'in')\n\n\nV(graph)$Collaboration <- factor(ifelse(V(graph)$Collaboration < 5, 'few', \n                                         ifelse(V(graph)$Collaboration >= 15, 'many', 'medium')), \n                                  levels = c('few', 'medium', 'many'))\n\n\n\n# Create the hive plot\nggraph(graph, 'hive', axis = Collaboration, sort.by = 'degree') + \n  geom_edge_hive(aes(colour = oa_status)) +\n  scale_color_manual(values = c(\"#16e01a\", \"#69d9db\", \"#9f4fe0\",\"#06000a\"), name = \"Open Access Status\") +\n   geom_axis_hive(aes(colour = Collaboration), size = 4, label = FALSE) + \n  scale_color_manual(values = c(\"#06000a\", \"#4149d9\", \"#fce803\"),\n                     labels = c('few', 'medium', 'many')) +\n  coord_fixed()\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\nFaceted Hive Plots\nHive plots separated by open access for clearer visualization.\n\nggraph(graph, 'hive', axis = Collaboration, sort.by = 'degree') + \n  geom_edge_hive(aes(colour = oa_status)) + \n  geom_axis_hive(aes(colour = Collaboration), size = 3, label = FALSE) + \n  scale_color_manual(values = c(\"#06000a\", \"#4149d9\", \"#fce803\"),\n                     labels = c('few', 'medium', 'many')) +\n  coord_fixed() +\n  facet_edges(~oa_status)"
  },
  {
    "objectID": "Bibliometric Analysis.html#plots",
    "href": "Bibliometric Analysis.html#plots",
    "title": "Bibliometric Analysis",
    "section": "Plots",
    "text": "Plots\nPlots with most productive authors, top manuscripts per citations, corresponding authors countries, single country publications, multiple country publications, most relevant sources, most relevant keywords.\nShowing only most productive authors.\n\nAll Open Access\n\nplot_result_all_oa <- plot(x = result_all_oa, k = 10, pause = F)\n\n\nplot_result_all_oa[[\"MostProdAuthors\"]]\n\n\n\n\n\n\nGreen\n\nplot_result_green<-plot(x = result_green, k = 10, pause = F)\n\n\nplot_result_green[[\"MostProdAuthors\"]]\n\n\n\n\n\n\nGreen Final\n\nplot_result_green_final<-plot(x = result_green_final, k = 10, pause = F)\n\n\nplot_result_green_final[[\"MostProdAuthors\"]]\n\n\n\n\n\n\nGreen Accepted\n\nplot_result_green_accepted<-plot(x = result_green_accepted, k = 10, pause = F)\n\n\nplot_result_green_accepted[[\"MostProdAuthors\"]]\n\n\n\n\n\n\nNot Green\n\nplot_result_not_green<-plot(x = result_not_green, k = 10, pause = F)\n\n\nplot_result_not_green[[\"MostProdAuthors\"]]"
  },
  {
    "objectID": "Bibliometric Analysis.html#publications-with-at-least-one-citation",
    "href": "Bibliometric Analysis.html#publications-with-at-least-one-citation",
    "title": "Bibliometric Analysis",
    "section": "Publications with at least one citation",
    "text": "Publications with at least one citation\nProportion of publications that have at least one citation.\n\nAll Open Access\n\nsum( ( single_author_table_all_oa_cited$TC >= 1 ) / length( single_author_table_all_oa_cited$TC ) )\n\n[1] 0.5264\n\n\n\n\nGreen\n\nsum( ( single_author_table_green_cited$TC >= 1 ) / length( single_author_table_green_cited$TC ) )\n\n[1] 0.5378289\n\n\n\n\nFinal Green\n\nsum( ( single_author_table_green_final_cited$TC >= 1 ) / length( single_author_table_green_final_cited$TC ) )\n\n[1] 0.5518868\n\n\n\n\nGreen Accepted\n\nsum( ( single_author_table_green_accepted_cited$TC >= 1 ) / length( single_author_table_green_accepted_cited$TC ) )\n\n[1] 0.530303\n\n\n\n\nNot Green\n\nsum( ( single_author_table_not_green_cited$TC >= 1 ) / length( single_author_table_not_green_cited$TC ) )\n\n[1] 0.45625"
  },
  {
    "objectID": "Bibliometric Analysis.html#comparisons-between-open-access-status",
    "href": "Bibliometric Analysis.html#comparisons-between-open-access-status",
    "title": "Bibliometric Analysis",
    "section": "Comparisons between Open Access status",
    "text": "Comparisons between Open Access status\nGeneral linear model showing the comparisons between the open access status of author’s publications and their citedness.\n\nsingle_author_table_all_oa_cited_status <- cbind(single_author_table_all_oa_cited, oa_status = \"All Open Access\")\n\nsingle_author_table_green_cited_status <- cbind(single_author_table_green_cited, oa_status = \"Green\")\n\nsingle_author_table_green_final_cited_status <- cbind(single_author_table_green_final_cited, oa_status = \"Green Final\")\n\nsingle_author_table_green_accepted_cited_status <- cbind(single_author_table_green_accepted_cited, oa_status = \"Green Accepted\")\n\nsingle_author_table_not_green_cited_status <- cbind(single_author_table_not_green_cited, oa_status = \"Not\")\n\nfull_oa_for_analysis <- rbind(single_author_table_green_cited_status, single_author_table_green_final_cited_status, single_author_table_green_accepted_cited_status, single_author_table_not_green_cited_status)\n\nfull_oa_for_analysis$cited <- ifelse(full_oa_for_analysis$TC>=1 & full_oa_for_analysis$TC>=1, 1, 0)\n\nfull_oa_for_analysis <- full_oa_for_analysis %>% \n  mutate(green_or_not = case_when(str_detect(oa_status, \"Green|Green Final|Green Accepted\" ) ~ \"1\",\n                           str_detect(oa_status, \"Not\" ) ~ \"0\"))\n\nmodel_all <- glm(cited ~ green_or_not ,data=full_oa_for_analysis, family=binomial)\nsummary(model_all)\n\n\nCall:\nglm(formula = cited ~ green_or_not, family = binomial, data = full_oa_for_analysis)\n\nDeviance Residuals: \n   Min      1Q  Median      3Q     Max  \n-1.242  -1.242   1.114   1.114   1.253  \n\nCoefficients:\n              Estimate Std. Error z value Pr(>|z|)  \n(Intercept)    -0.1754     0.1587  -1.105   0.2690  \ngreen_or_not1   0.3271     0.1688   1.937   0.0527 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1903.1  on 1375  degrees of freedom\nResidual deviance: 1899.3  on 1374  degrees of freedom\nAIC: 1903.3\n\nNumber of Fisher Scoring iterations: 3"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#all-open-access",
    "href": "Network Attributes and Visualisations.html#all-open-access",
    "title": "Network Attributes and Visualisations",
    "section": "All Open Access",
    "text": "All Open Access\n\nSummary Statistics\n\nall_oa_corr <- all_oa_corr[!duplicated(all_oa_corr$DI),]\nall_oa_corr$SR <- NULL\nall_oa_corr$SR_FULL <-NULL ##Seemed to hold problem duplicates I couldn't get rid of without removing publictaions so I just dropped the columns for all_oa.Not useful anyway.\nnet_matrix_all_oa <- biblioNetwork(all_oa_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_all_oa <- networkStat(net_matrix_all_oa)\n\nsummary(net_stat_all_oa, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2432 \n Density                               0.004 \n Transitivity                          0.88 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.11 \n \n\n\n\n\nPage Rank\n\nnet_all_oa_all<- networkStat(net_matrix_all_oa, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_all_oa_interesting <- as.data.frame(net_all_oa_all[[\"vertex\"]])\nall_oa_page_rank <- net_all_oa_interesting[with(net_all_oa_interesting,order(-vertexPageRank)),]\n\nall_oa_page_rank <- all_oa_page_rank[1:25,]\nall_oa_page_rank_top_25 <- all_oa_page_rank %>% select(c(vertexID, vertexPageRank))\n\nall_oa_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002388547\nTORUN H                     TORUN H    0.002043633\nHOWATSON G               HOWATSON G    0.001657070\nFINCH T                     FINCH T    0.001593615\nWU Q                           WU Q    0.001587371\nSCOTT J                     SCOTT J    0.001544451\nMAQBOOL R                 MAQBOOL R    0.001518126\nFU Y                           FU Y    0.001502761\nPOLLET TV                 POLLET TV    0.001447671\nMARZBAND M               MARZBAND M    0.001439754\nGUO Z                         GUO Z    0.001433217\nCORDIER R                 CORDIER R    0.001418108\nBARRY G                     BARRY G    0.001403227\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001402974\nTHURAIRAJAH N         THURAIRAJAH N    0.001379891\nGODFREY A                 GODFREY A    0.001333202\nSTUART S                   STUART S    0.001321611\nDICKENS GL               DICKENS GL    0.001297331\nSHANG Y                     SHANG Y    0.001286809\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001262781\nGAO Z                         GAO Z    0.001253900\nMCCARTY K                 MCCARTY K    0.001204470\nWANG K                       WANG K    0.001196364\nAVERY L                     AVERY L    0.001190158\nFU YQ                         FU YQ    0.001179159\n\n\n\n\nNetwork Plot\n(Need to figure out how to have large networks that aren’t just hairballs)\n\nnet_all_oa <- networkPlot(net_matrix_all_oa, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = .5)"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#green",
    "href": "Network Attributes and Visualisations.html#green",
    "title": "Network Attributes and Visualisations",
    "section": "Green",
    "text": "Green\n\nSummary Statistics\n\nnet_matrix_green <- biblioNetwork(green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green <- networkStat(net_matrix_green)\nsummary(net_stat_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  2398 \n Density                               0.004 \n Transitivity                          0.885 \n Diameter                              14 \n Degree Centralization                 0.027 \n Average path length                   6.416 \n \n\n\n\n\nPage Rank\n\nnet_green_all<- networkStat(net_matrix_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_interesting <- as.data.frame(net_green_all[[\"vertex\"]])\ngreen_page_rank <- net_green_interesting[with(net_green_interesting,order(-vertexPageRank)),]\n\ngreen_page_rank <- green_page_rank[1:25,]\ngreen_page_rank_top_25 <- green_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_page_rank_top_25\n\n                           vertexID vertexPageRank\nXU BB                         XU BB    0.002267625\nTORUN H                     TORUN H    0.001975115\nHOWATSON G               HOWATSON G    0.001680174\nWU Q                           WU Q    0.001627842\nFINCH T                     FINCH T    0.001622863\nSCOTT J                     SCOTT J    0.001579656\nMARZBAND M               MARZBAND M    0.001559428\nMAQBOOL R                 MAQBOOL R    0.001538928\nFU Y                           FU Y    0.001520925\nPOLLET TV                 POLLET TV    0.001467563\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001423749\nBARRY G                     BARRY G    0.001411267\nCORDIER R                 CORDIER R    0.001404416\nGODFREY A                 GODFREY A    0.001349880\nSTUART S                   STUART S    0.001337827\nDICKENS GL               DICKENS GL    0.001326286\nTHURAIRAJAH N         THURAIRAJAH N    0.001311004\nSHANG Y                     SHANG Y    0.001305311\nGUO Z                         GUO Z    0.001293999\nGAO Z                         GAO Z    0.001272333\nPOOLOGANATHAN K     POOLOGANATHAN K    0.001263434\nMCCARTY K                 MCCARTY K    0.001221042\nWANG K                       WANG K    0.001218286\nAVERY L                     AVERY L    0.001207882\nFU YQ                         FU YQ    0.001207161\n\n\n\n\nNetwork Plot\n\nnet_green <- networkPlot(net_matrix_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#green-final",
    "href": "Network Attributes and Visualisations.html#green-final",
    "title": "Network Attributes and Visualisations",
    "section": "Green Final",
    "text": "Green Final\n\nSummary Statistics\n\nnet_matrix_green_final <- biblioNetwork(green_final_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_final <- networkStat(net_matrix_green_final)\n\nsummary(net_stat_green_final, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1207 \n Density                               0.01 \n Transitivity                          0.958 \n Diameter                              13 \n Degree Centralization                 0.047 \n Average path length                   4.613 \n \n\n\n\n\nPage Rank\n\nnet_green_final_all<- networkStat(net_matrix_green_final, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_final_interesting <- as.data.frame(net_green_final_all[[\"vertex\"]])\ngreen_final_page_rank <- net_green_final_interesting[with(net_green_final_interesting,order(-vertexPageRank)),]\n\ngreen_final_page_rank <- green_final_page_rank[1:25,]\ngreen_final_page_rank_top_25 <- green_final_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_final_page_rank_top_25\n\n                           vertexID vertexPageRank\nFINCH T                     FINCH T    0.002924918\nHOWATSON G               HOWATSON G    0.002655933\nCORDIER R                 CORDIER R    0.002600564\nSCOTT J                     SCOTT J    0.002494150\nDICKENS GL               DICKENS GL    0.002365268\nBARRY G                     BARRY G    0.002318322\nAVERY L                     AVERY L    0.002312757\nPOOLOGANATHAN K     POOLOGANATHAN K    0.002309373\nTORUN H                     TORUN H    0.002141325\nGODFREY A                 GODFREY A    0.002118096\nSTUART S                   STUART S    0.002015907\nFU Y                           FU Y    0.002005366\nDEFEYTER MA             DEFEYTER MA    0.001983977\nTIWARI D                   TIWARI D    0.001918697\nGONZÁLEZ S               GONZÁLEZ S    0.001823282\nWOO WL                       WOO WL    0.001768242\nWILSON-MENZFELD G WILSON-MENZFELD G    0.001763044\nCOVENTRY L               COVENTRY L    0.001746669\nXU BB                         XU BB    0.001727298\nKIERNAN MD               KIERNAN MD    0.001693775\nGATHEESHGAR P         GATHEESHGAR P    0.001649280\nPAN C                         PAN C    0.001621367\nWANG K                       WANG K    0.001621367\nCORRADI M                 CORRADI M    0.001585191\nHETTINGA FJ             HETTINGA FJ    0.001572971\n\n\n\n\nNetwork Plot\n\nnet_green_final <- networkPlot(net_matrix_green_final, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 1)"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#green-accepted",
    "href": "Network Attributes and Visualisations.html#green-accepted",
    "title": "Network Attributes and Visualisations",
    "section": "Green Accepted",
    "text": "Green Accepted\n\nSummary Statistics\n\nnet_matrix_green_accepted <- biblioNetwork(green_accepted_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_green_accepted <- networkStat(net_matrix_green_accepted)\n\nsummary(net_stat_green_accepted, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  1452 \n Density                               0.004 \n Transitivity                          0.774 \n Diameter                              15 \n Degree Centralization                 0.03 \n Average path length                   4.49 \n \n\n\n\n\nPage Rank\n\nnet_green_accepted_all<- networkStat(net_matrix_green_accepted, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_green_accepted_interesting <- as.data.frame(net_green_accepted_all[[\"vertex\"]])\ngreen_accepted_page_rank <- net_green_accepted_interesting[with(net_green_accepted_interesting,order(-vertexPageRank)),]\n\ngreen_accepted_page_rank <- green_accepted_page_rank[1:25,]\ngreen_accepted_page_rank_top_25 <- green_accepted_page_rank %>% select(c(vertexID, vertexPageRank))\n\ngreen_accepted_page_rank_top_25\n\n                       vertexID vertexPageRank\nXU BB                     XU BB    0.003023673\nWU Q                       WU Q    0.002545427\nTORUN H                 TORUN H    0.002428556\nMAQBOOL R             MAQBOOL R    0.002307804\nPOLLET TV             POLLET TV    0.002304099\nTHURAIRAJAH N     THURAIRAJAH N    0.002273221\nGUO Z                     GUO Z    0.002252070\nSHANG Y                 SHANG Y    0.002231116\nFU YQ                     FU YQ    0.002174649\nMARZBAND M           MARZBAND M    0.002147596\nWANG Y                   WANG Y    0.001975717\nGAO Z                     GAO Z    0.001901558\nPOUND MJ               POUND MJ    0.001896643\nVU MC                     VU MC    0.001883560\nSTUART S               STUART S    0.001811813\nYANG L                   YANG L    0.001754185\nNEAVE N                 NEAVE N    0.001744772\nPOOLOGANATHAN K POOLOGANATHAN K    0.001705948\nLIM M                     LIM M    0.001693244\nADENIYI O             ADENIYI O    0.001624033\nASLAM N                 ASLAM N    0.001619280\nAZIMOV U               AZIMOV U    0.001610623\nUNSWORTH J           UNSWORTH J    0.001591190\nDEARY ME               DEARY ME    0.001588631\nYUAN J                   YUAN J    0.001584682\n\n\n\n\nNetwork Plot\n\nnet_green_accepted <- networkPlot(net_matrix_green_accepted, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=0.7,edgesize = 5)"
  },
  {
    "objectID": "Network Attributes and Visualisations.html#not-green",
    "href": "Network Attributes and Visualisations.html#not-green",
    "title": "Network Attributes and Visualisations",
    "section": "Not Green",
    "text": "Not Green\n\nSummary Statistics\n\nnet_matrix_not_green<- biblioNetwork(not_green_corr, analysis = \"collaboration\", network = \"authors\", sep = \";\")\nnet_stat_not_green <- networkStat(net_matrix_not_green)\n\nsummary(net_stat_not_green, k=10)\n\n\n\nMain statistics about the network\n\n Size                                  649 \n Density                               0.009 \n Transitivity                          0.621 \n Diameter                              9 \n Degree Centralization                 0.078 \n Average path length                   3.722 \n \n\n\n\n\nPage Rank\n\nnet_not_green_all<- networkStat(net_matrix_not_green, stat = \"all\", type= \"all\") #Calculates many interesting things (including pagerank.)\n\nWarning in betweenness(net, v = V(net), directed = FALSE, weights = NULL, : 'nobigint' is deprecated since igraph 1.3\nand will be removed in igraph 1.4\n\nnet_not_green_interesting <- as.data.frame(net_not_green_all[[\"vertex\"]])\nnot_green_page_rank <- net_not_green_interesting[with(net_not_green_interesting,order(-vertexPageRank)),]\n\nnot_green_page_rank <- not_green_page_rank[1:25,]\nnot_green_page_rank_top_25 <- not_green_page_rank %>% select(c(vertexID, vertexPageRank))\n\nnot_green_page_rank_top_25\n\n                       vertexID vertexPageRank\nWU Q                       WU Q    0.006783042\nJAHANKHANI H       JAHANKHANI H    0.005922758\nXU BB                     XU BB    0.005831571\nPOOLOGANATHAN K POOLOGANATHAN K    0.005295464\nFU YQ                     FU YQ    0.005258701\nGUO Z                     GUO Z    0.005250989\nGATHEESHGAR P     GATHEESHGAR P    0.004711329\nMARZBAND M           MARZBAND M    0.004274064\nYUAN J                   YUAN J    0.004045065\nALGADI H               ALGADI H    0.003792800\nZHOU X                   ZHOU X    0.003787891\nXING L                   XING L    0.003688906\nLI H                       LI H    0.003634541\nTORUN H                 TORUN H    0.003548481\nALLEN G                 ALLEN G    0.003533428\nCORRADI M             CORRADI M    0.003357814\nLIU B                     LIU B    0.003253078\nZHANG Y                 ZHANG Y    0.003220641\nGODFREY A             GODFREY A    0.003049035\nSTUART S               STUART S    0.003049035\nGHASSEMLOOY Z     GHASSEMLOOY Z    0.002911522\nMAQBOOL R             MAQBOOL R    0.002862371\nDAS J                     DAS J    0.002809138\nSHAMS SMR             SHAMS SMR    0.002762666\nELLIOTT IC           ELLIOTT IC    0.002729203\n\n\n\n\nNetwork Plot\n\nnet_not_green <- networkPlot(net_matrix_not_green, n = 150, Title = \"Collaboration Network\", type = \"fruchterman\", size=T, remove.multiple=FALSE, labelsize=.7,edgesize = 5)\n\n\n\n\n\n\nAlternate Network Visualizations\n\nall_oa_graph <- igraph::graph.adjacency(net_matrix_all_oa                                                                             \n                                   , mode=\"undirected\"                                                                   \n                                   , weighted=TRUE) \n\n\nclusterlouvain <- cluster_louvain(all_oa_graph)\nclusterlouvain\n\nIGRAPH clustering multi level, groups: 258, mod: 0.94\n+ groups:\n  $`1`\n   [1] \"STUART S\"        \"GODFREY A\"       \"BARRY G\"         \"MORRIS R\"        \"MASON R\"         \"WALKER R\"       \n   [7] \"GOODALL S\"       \"POWELL D\"        \"DAS J\"           \"YOUNG F\"         \"ALI M\"           \"DANJOUX G\"      \n  [13] \"GRAY J\"          \"MANCINI M\"       \"PEARSON LT\"      \"VITORIO R\"       \"CELIK Y\"         \"DISMORE L\"      \n  [19] \"GRAHAM L\"        \"KOPNINA H\"       \"MCDONALD C\"      \"MCMEEKIN P\"      \"MONTAGUE K\"      \"MOORE J\"        \n  [25] \"O'DOHERTY AF\"    \"OMAN P\"          \"WALL C\"          \"AFTAB M\"         \"AHMAD B\"         \"ARAUJO-SOARES V\"\n  [31] \"ASLAN MF\"        \"BAKER A\"         \"BAKER P\"         \"BALAAM M\"        \"BEHM DG\"         \"BOKHARI SAA\"    \n  [37] \"BUTTERFIELD A\"   \"BYERLEY J\"       \"CAISLEY K\"       \"CAMPBELL KR\"     \"CARR E\"          \"CARVALHO L\"     \n  [43] \"CLARK N\"         \"CLEAR AK\"        \"COULBY G\"        \"COURT P\"         \"COVASSIN T\"      \"DEVER A\"        \n  [49] \"DOHERTY P\"       \"DURRAND J\"       \"GHATTAS H\"       \"GILLIS C\"        \"GREAVES C\"       \"GUAN Y\"         \n  + ... omitted several groups/vertices\n\n\n\nplot(all_oa_graph, vertex.color=rainbow(7, alpha=0.6)[clusterlouvain$membership])"
  },
  {
    "objectID": "Bibliometric Analysis.html#descriptive-statistics",
    "href": "Bibliometric Analysis.html#descriptive-statistics",
    "title": "Bibliometric Analysis",
    "section": "Descriptive Statistics",
    "text": "Descriptive Statistics\nTables showing most productive authors, top manuscripts per citations, corresponding authors countries, single country publications, multiple country publications, most relevant sources, most relevant keywords.\n\nAll Open Access\n\nresult_all_oa <- biblioAnalysis(all_oa_corr, sep = \";\")\n\n\noptions(width=100)\nsummary_result_all_oa  <- summary(object= result_all_oa, k = 25, pause = F)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              2022 : 2023 \n Sources (Journals, Books, etc)        512 \n Documents                             770 \n Annual Growth Rate %                  -79.12 \n Document Average Age                  0.827 \n Average citations per doc             1.851 \n Average citations per year per doc    0.9448 \n References                            48957 \n \nDOCUMENT TYPES                     \n article           682 \n editorial         8 \n erratum           2 \n letter            2 \n note              4 \n review            69 \n short survey      3 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    5284 \n Author's Keywords (DE)                2864 \n \nAUTHORS\n Authors                               2432 \n Author Appearances                    3568 \n Authors of single-authored docs       67 \n \nAUTHORS COLLABORATION\n Single-authored docs                  84 \n Documents per Author                  0.317 \n Co-Authors per Doc                    4.63 \n International co-authorships %        49.22 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    2022      637\n    2023      133\n\nAnnual Percentage Growth Rate -79.12 \n\n\nMost Productive Authors\n\n      Authors        Articles     Authors        Articles Fractionalized\n1  STUART S                14 SHANG Y                               7.57\n2  SHANG Y                 13 MAQBOOL R                             4.23\n3  XU BB                   13 PECK S                                3.50\n4  MAQBOOL R               12 VU MC                                 3.37\n5  GODFREY A               11 RAGNEDDA M                            3.25\n6  POOLOGANATHAN K         11 STOTEN DW                             3.00\n7  TORUN H                 11 BURTON N                              2.67\n8  RAGNEDDA M               9 RUIU ML                               2.58\n9  WANG K                   9 GAO Z                                 2.50\n10 WILSON-MENZFELD G        9 WILSON-MENZFELD G                     2.40\n11 WU Q                     9 SEO KW                                2.33\n12 BARRY G                  8 DICKENS GL                            2.30\n13 CORDIER R                8 STUART S                              2.23\n14 CORRADI M                8 WANG K                                2.10\n15 DICKENS GL               8 ARE C                                 2.00\n16 FU Y                     8 COOK P                                2.00\n17 GAO Z                    8 KUJUNDŽIĆ J                           2.00\n18 PAN C                    8 MURPHY N                              2.00\n19 POUND MJ                 8 OSWALD RJ                             2.00\n20 VU MC                    8 SHARP E                               2.00\n21 ELDER GJ                 7 STEPHENS-GRIFFIN N                    2.00\n22 HOWATSON G               7 SUTHERLAND C                          2.00\n23 MARZBAND M               7 POLLET TV                             1.93\n24 MORRIS R                 7 POUND MJ                              1.90\n25 POLLET TV                7 ELDER GJ                              1.88\n\n\nTop manuscripts per citations\n\n                                     Paper                                     DOI  TC TCperYear   NTC\n1  PAN D, 2022, NANO-MICRO LETT                     10.1007/s40820-022-00863-z     109      54.5 49.77\n2  AHMADI SE, 2022, ENERGY                          10.1016/j.energy.2022.123223    42      21.0 19.18\n3  GUO J, 2022, ADV COMPOS HYBRID MATER             10.1007/s42114-022-00417-2      36      18.0 16.44\n4  COSTA SC, 2022, RENEWABLE SUSTAINABLE ENERGY REV 10.1016/j.rser.2021.111812      35      17.5 15.98\n5  WANG L, 2022, IEEE TRANS MOB COMPUT              10.1109/TMC.2021.3059691        35      17.5 15.98\n6  DENG W, 2022, ADV SCI                            10.1002/advs.202102189          31      15.5 14.16\n7  SZCZYGIELSKI JJ, 2022, ENERGY ECON               10.1016/j.eneco.2021.105258     31      15.5 14.16\n8  SZCZYGIELSKI JJ, 2022, INT REV FINANC ANAL       10.1016/j.irfa.2021.101837      27      13.5 12.33\n9  REN H, 2022, IEEE TRANS COMMUN                   10.1109/TCOMM.2021.3125057      26      13.0 11.87\n10 RAHIMILARKI R, 2022, RENEW ENERGY                10.1016/j.renene.2021.12.056    25      12.5 11.42\n11 SUN S, 2022, APPL ENERGY                         10.1016/j.apenergy.2021.117804  22      11.0 10.05\n12 ALRAJA MN, 2022, INF SYST FRONT                  10.1007/s10796-022-10250-z      19       9.5  8.68\n13 WANG Z, 2022, ADV FUNCT MATER                    10.1002/adfm.202201396          15       7.5  6.85\n14 PAN Y, 2022, IEEE TRANS VEH TECHNOL              10.1109/TVT.2022.3140869        14       7.0  6.39\n15 DU Y, 2022, SMALL                                10.1002/smll.202104640          13       6.5  5.94\n16 MANN PJ, 2022, AMBIO                             10.1007/s13280-021-01666-z      13       6.5  5.94\n17 OLAN F, 2022, INF SYST FRONT                     10.1007/s10796-022-10242-z      13       6.5  5.94\n18 JIANG F, 2022, IEEE INTERNET THINGS J            10.1109/JIOT.2021.3113872       12       6.0  5.48\n19 LIU L, 2022, IEEE TRANS IND INF                  10.1109/TII.2021.3080841        12       6.0  5.48\n20 ALLAN J, 2022, ANTIPODE                          10.1111/anti.12765              11       5.5  5.02\n21 DJAFAROVA E, 2022, YOUNG CONSUM                  10.1108/YC-10-2021-1405         11       5.5  5.02\n22 LU S, 2022, IEEE TRANS IND INF                   10.1109/TII.2022.3190034        11       5.5  5.02\n23 HUSSAIN S, 2022, ENERGY                          10.1016/j.energy.2021.122172    10       5.0  4.57\n24 ISHFAQ K, 2022, INT J ADV MANUF TECHNOL          10.1007/s00170-022-09207-y      10       5.0  4.57\n25 NAKHCHI ME, 2022, ENERGY                         10.1016/j.energy.2021.122988    10       5.0  4.57\n\n\nCorresponding Author's Countries\n\n                Country Articles   Freq SCP MCP MCP_Ratio\n1  UNITED KINGDOM            591 0.8861 320 271     0.459\n2  CHINA                      35 0.0525   0  35     1.000\n3  AUSTRALIA                   5 0.0075   0   5     1.000\n4  NETHERLANDS                 5 0.0075   0   5     1.000\n5  GEORGIA                     3 0.0045   3   0     0.000\n6  KOREA                       3 0.0045   0   3     1.000\n7  BELGIUM                     2 0.0030   0   2     1.000\n8  FRANCE                      2 0.0030   0   2     1.000\n9  INDIA                       2 0.0030   0   2     1.000\n10 QATAR                       2 0.0030   2   0     0.000\n11 SAUDI ARABIA                2 0.0030   0   2     1.000\n12 BRAZIL                      1 0.0015   0   1     1.000\n13 CANADA                      1 0.0015   0   1     1.000\n14 CHILE                       1 0.0015   0   1     1.000\n15 GERMANY                     1 0.0015   0   1     1.000\n16 GREECE                      1 0.0015   0   1     1.000\n17 HONG KONG                   1 0.0015   0   1     1.000\n18 IRELAND                     1 0.0015   1   0     0.000\n19 JORDAN                      1 0.0015   1   0     0.000\n20 KAZAKHSTAN                  1 0.0015   0   1     1.000\n21 MEXICO                      1 0.0015   0   1     1.000\n22 NORWAY                      1 0.0015   0   1     1.000\n23 PAKISTAN                    1 0.0015   0   1     1.000\n24 SWITZERLAND                 1 0.0015   0   1     1.000\n25 UNITED ARAB EMIRATES        1 0.0015   0   1     1.000\n\n\nSCP: Single Country Publications\n\nMCP: Multiple Country Publications\n\n\nTotal Citations per Country\n\n           Country      Total Citations Average Article Citations\n1  UNITED KINGDOM                   994                      1.66\n2  CHINA                            288                      8.23\n3  FRANCE                             9                      4.50\n4  AUSTRALIA                          7                      1.40\n5  GEORGIA                            6                      2.00\n6  KOREA                              6                      2.00\n7  INDIA                              5                      2.50\n8  BELGIUM                            4                      2.00\n9  SAUDI ARABIA                       4                      2.00\n10 CHILE                              3                      3.00\n11 GERMANY                            3                      3.00\n12 NORWAY                             3                      3.00\n13 NETHERLANDS                        2                      0.40\n14 CANADA                             1                      1.00\n15 MEXICO                             1                      1.00\n16 QATAR                              1                      0.50\n17 USA                                1                      1.00\n18 BRAZIL                             0                      0.00\n19 GREECE                             0                      0.00\n20 HONG KONG                          0                      0.00\n21 IRELAND                            0                      0.00\n22 JORDAN                             0                      0.00\n23 KAZAKHSTAN                         0                      0.00\n24 PAKISTAN                           0                      0.00\n25 SWITZERLAND                        0                      0.00\n\n\nMost Relevant Sources\n\n                                                      Sources        Articles\n1  PLOS ONE                                                                27\n2  BUILDINGS                                                               10\n3  SENSORS                                                                  9\n4  JOURNAL OF CRIMINAL LAW                                                  7\n5  BMJ OPEN                                                                 6\n6  BRITISH JOURNAL OF OCCUPATIONAL THERAPY                                  6\n7  FRONTIERS IN PSYCHOLOGY                                                  6\n8  INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH        6\n9  JOURNAL OF BUSINESS ETHICS                                               6\n10 ENVIRONMENTAL SCIENCE AND POLLUTION RESEARCH                             5\n11 MATHEMATICS                                                              5\n12 NURSE EDUCATION TODAY                                                    5\n13 NUTRIENTS                                                                5\n14 BRITISH JOURNAL OF NUTRITION                                             4\n15 CERAMICS INTERNATIONAL                                                   4\n16 CHRONIC RESPIRATORY DISEASE                                              4\n17 ENERGIES                                                                 4\n18 ENERGY                                                                   4\n19 FRONTIERS IN PUBLIC HEALTH                                               4\n20 GEOGRAPHICAL JOURNAL                                                     4\n21 INFORMATION SYSTEMS FRONTIERS                                            4\n22 INTERNATIONAL JOURNAL OF ENTREPRENEURSHIP AND INNOVATION                 4\n23 INTERNATIONAL JOURNAL OF SOCIAL RESEARCH METHODOLOGY                     4\n24 JOURNAL OF MATERIALS CHEMISTRY C                                         4\n25 LEISURE STUDIES                                                          4\n\n\nMost Relevant Keywords\n\n   Author Keywords (DE)      Articles Keywords-Plus (ID)     Articles\n1       COVID-19                   28   HUMAN                     206\n2       PUBLIC HEALTH              12   ARTICLE                   150\n3       CLIMATE CHANGE              9   HUMANS                    145\n4       QUALITATIVE RESEARCH        8   ADULT                     115\n5       DIGITAL DIVIDE              7   MALE                      115\n6       GENDER                      7   FEMALE                    113\n7       IDENTITY                    7   CONTROLLED STUDY           67\n8       OLDER PEOPLE                7   UNITED KINGDOM             61\n9       SOCIAL MEDIA                7   HUMAN EXPERIMENT           41\n10      TECHNOLOGY                  7   CHILD                      36\n11      CHILDREN                    6   AGED                       32\n12      GAIT                        6   COVID-19                   30\n13      MENTAL HEALTH               6   CLINICAL ARTICLE           29\n14      PERFORMANCE                 6   MENTAL HEALTH              29\n15      SUSTAINABILITY              6   ENGLAND                    28\n16      SYSTEMATIC REVIEW           6   MAJOR CLINICAL STUDY       28\n17      UK                          6   ADOLESCENT                 26\n18      ANXIETY                     5   QUALITATIVE RESEARCH       26\n19      CARE HOMES                  5   QUALITY OF LIFE            26\n20      DEEP LEARNING               5   EXERCISE                   23\n21      DISABILITY                  5   REVIEW                     21\n22      EXERCISE                    5   ANXIETY                    20\n23      FOOD INSECURITY             5   COGNITION                  20\n24      HIGHER EDUCATION            5   NONHUMAN                   20\n25      IMPLEMENTATION              5   SYSTEMATIC REVIEW          20\n\n\n\n\nGreen\n\nresult_green <- biblioAnalysis(green_corr, sep = \";\")\n\n\noptions(width=100)\nsummary_result_green  <- summary(object= result_green, k = 25, pause = F)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              2022 : 2023 \n Sources (Journals, Books, etc)        500 \n Documents                             738 \n Annual Growth Rate %                  -80.97 \n Document Average Age                  0.84 \n Average citations per doc             1.925 \n Average citations per year per doc    0.9804 \n References                            47429 \n \nDOCUMENT TYPES                     \n article           656 \n editorial         7 \n erratum           1 \n letter            2 \n note              4 \n review            65 \n short survey      3 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    5200 \n Author's Keywords (DE)                2813 \n \nAUTHORS\n Authors                               2398 \n Author Appearances                    3432 \n Authors of single-authored docs       66 \n \nAUTHORS COLLABORATION\n Single-authored docs                  81 \n Documents per Author                  0.308 \n Co-Authors per Doc                    4.65 \n International co-authorships %        49.73 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    2022      620\n    2023      118\n\nAnnual Percentage Growth Rate -80.97 \n\n\nMost Productive Authors\n\n      Authors        Articles     Authors        Articles Fractionalized\n1  STUART S                14 SHANG Y                               7.57\n2  SHANG Y                 13 VU MC                                 4.37\n3  XU BB                   12 MAQBOOL R                             3.57\n4  GODFREY A               11 PECK S                                3.50\n5  MAQBOOL R               10 RAGNEDDA M                            3.25\n6  TORUN H                 10 STOTEN DW                             3.00\n7  POOLOGANATHAN K          9 SUTHERLAND C                          3.00\n8  RAGNEDDA M               9 BURTON N                              2.67\n9  VU MC                    9 RUIU ML                               2.58\n10 WANG K                   9 GAO Z                                 2.50\n11 WU Q                     9 SEO KW                                2.33\n12 BARRY G                  8 DICKENS GL                            2.30\n13 DICKENS GL               8 WILSON-MENZFELD G                     2.24\n14 FU Y                     8 STUART S                              2.23\n15 GAO Z                    8 WANG K                                2.10\n16 PAN C                    8 COOK P                                2.00\n17 POUND MJ                 8 MURPHY N                              2.00\n18 WILSON-MENZFELD G        8 OSWALD RJ                             2.00\n19 CORDIER R                7 STEPHENS-GRIFFIN N                    2.00\n20 HOWATSON G               7 POLLET TV                             1.93\n21 MORRIS R                 7 POUND MJ                              1.90\n22 POLLET TV                7 GODFREY A                             1.87\n23 RUIU ML                  7 PAN C                                 1.85\n24 SCOTT J                  7 BROWN G                               1.83\n25 BURTON N                 6 GUERRERO M                            1.83\n\n\nTop manuscripts per citations\n\n                                     Paper                                     DOI  TC TCperYear   NTC\n1  PAN D, 2022, NANO-MICRO LETT                     10.1007/s40820-022-00863-z     109      54.5 48.44\n2  AHMADI SE, 2022, ENERGY                          10.1016/j.energy.2022.123223    42      21.0 18.67\n3  GUO J, 2022, ADV COMPOS HYBRID MATER             10.1007/s42114-022-00417-2      36      18.0 16.00\n4  COSTA SC, 2022, RENEWABLE SUSTAINABLE ENERGY REV 10.1016/j.rser.2021.111812      35      17.5 15.56\n5  WANG L, 2022, IEEE TRANS MOB COMPUT-a            10.1109/TMC.2021.3059691        35      17.5 15.56\n6  DENG W, 2022, ADV SCI                            10.1002/advs.202102189          31      15.5 13.78\n7  SZCZYGIELSKI JJ, 2022, ENERGY ECON               10.1016/j.eneco.2021.105258     31      15.5 13.78\n8  SZCZYGIELSKI JJ, 2022, INT REV FINANC ANAL       10.1016/j.irfa.2021.101837      27      13.5 12.00\n9  REN H, 2022, IEEE TRANS COMMUN                   10.1109/TCOMM.2021.3125057      26      13.0 11.56\n10 RAHIMILARKI R, 2022, RENEW ENERGY                10.1016/j.renene.2021.12.056    25      12.5 11.11\n11 SUN S, 2022, APPL ENERGY                         10.1016/j.apenergy.2021.117804  22      11.0  9.78\n12 ALRAJA MN, 2022, INF SYST FRONT                  10.1007/s10796-022-10250-z      19       9.5  8.44\n13 WANG Z, 2022, ADV FUNCT MATER                    10.1002/adfm.202201396          15       7.5  6.67\n14 PAN Y, 2022, IEEE TRANS VEH TECHNOL              10.1109/TVT.2022.3140869        14       7.0  6.22\n15 DU Y, 2022, SMALL                                10.1002/smll.202104640          13       6.5  5.78\n16 MANN PJ, 2022, AMBIO                             10.1007/s13280-021-01666-z      13       6.5  5.78\n17 OLAN F, 2022, INF SYST FRONT                     10.1007/s10796-022-10242-z      13       6.5  5.78\n18 JIANG F, 2022, IEEE INTERNET THINGS J            10.1109/JIOT.2021.3113872       12       6.0  5.33\n19 LIU L, 2022, IEEE TRANS IND INF                  10.1109/TII.2021.3080841        12       6.0  5.33\n20 ALLAN J, 2022, ANTIPODE                          10.1111/anti.12765              11       5.5  4.89\n21 DJAFAROVA E, 2022, YOUNG CONSUM                  10.1108/YC-10-2021-1405         11       5.5  4.89\n22 LU S, 2022, IEEE TRANS IND INF                   10.1109/TII.2022.3190034        11       5.5  4.89\n23 HUSSAIN S, 2022, ENERGY                          10.1016/j.energy.2021.122172    10       5.0  4.44\n24 ISHFAQ K, 2022, INT J ADV MANUF TECHNOL          10.1007/s00170-022-09207-y      10       5.0  4.44\n25 NAKHCHI ME, 2022, ENERGY                         10.1016/j.energy.2021.122988    10       5.0  4.44\n\n\nCorresponding Author's Countries\n\n                Country Articles    Freq SCP MCP MCP_Ratio\n1  UNITED KINGDOM            573 0.88426 304 269     0.469\n2  CHINA                      34 0.05247   0  34     1.000\n3  AUSTRALIA                   5 0.00772   0   5     1.000\n4  NETHERLANDS                 5 0.00772   0   5     1.000\n5  GEORGIA                     3 0.00463   3   0     0.000\n6  KOREA                       3 0.00463   0   3     1.000\n7  BELGIUM                     2 0.00309   0   2     1.000\n8  CHILE                       2 0.00309   0   2     1.000\n9  FRANCE                      2 0.00309   0   2     1.000\n10 INDIA                       2 0.00309   0   2     1.000\n11 QATAR                       2 0.00309   2   0     0.000\n12 BRAZIL                      1 0.00154   0   1     1.000\n13 CANADA                      1 0.00154   0   1     1.000\n14 GERMANY                     1 0.00154   0   1     1.000\n15 GREECE                      1 0.00154   0   1     1.000\n16 HONG KONG                   1 0.00154   0   1     1.000\n17 IRELAND                     1 0.00154   1   0     0.000\n18 JORDAN                      1 0.00154   1   0     0.000\n19 KAZAKHSTAN                  1 0.00154   0   1     1.000\n20 MEXICO                      1 0.00154   0   1     1.000\n21 NORWAY                      1 0.00154   0   1     1.000\n22 PAKISTAN                    1 0.00154   0   1     1.000\n23 SAUDI ARABIA                1 0.00154   0   1     1.000\n24 SWITZERLAND                 1 0.00154   0   1     1.000\n25 UNITED ARAB EMIRATES        1 0.00154   0   1     1.000\n\n\nSCP: Single Country Publications\n\nMCP: Multiple Country Publications\n\n\nTotal Citations per Country\n\n           Country      Total Citations Average Article Citations\n1  UNITED KINGDOM                   988                      1.72\n2  CHINA                            288                      8.47\n3  FRANCE                             9                      4.50\n4  AUSTRALIA                          7                      1.40\n5  CHILE                              7                      3.50\n6  GEORGIA                            6                      2.00\n7  KOREA                              6                      2.00\n8  INDIA                              5                      2.50\n9  BELGIUM                            4                      2.00\n10 SAUDI ARABIA                       4                      4.00\n11 GERMANY                            3                      3.00\n12 NORWAY                             3                      3.00\n13 NETHERLANDS                        2                      0.40\n14 CANADA                             1                      1.00\n15 MEXICO                             1                      1.00\n16 QATAR                              1                      0.50\n17 USA                                1                      1.00\n18 BRAZIL                             0                      0.00\n19 GREECE                             0                      0.00\n20 HONG KONG                          0                      0.00\n21 IRELAND                            0                      0.00\n22 JORDAN                             0                      0.00\n23 KAZAKHSTAN                         0                      0.00\n24 PAKISTAN                           0                      0.00\n25 SWITZERLAND                        0                      0.00\n\n\nMost Relevant Sources\n\n                                                      Sources        Articles\n1  PLOS ONE                                                                25\n2  BUILDINGS                                                                9\n3  SENSORS                                                                  9\n4  JOURNAL OF CRIMINAL LAW                                                  7\n5  BMJ OPEN                                                                 6\n6  FRONTIERS IN PSYCHOLOGY                                                  6\n7  INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH        6\n8  JOURNAL OF BUSINESS ETHICS                                               6\n9  BRITISH JOURNAL OF OCCUPATIONAL THERAPY                                  5\n10 NURSE EDUCATION TODAY                                                    5\n11 NUTRIENTS                                                                5\n12 BRITISH JOURNAL OF NUTRITION                                             4\n13 CERAMICS INTERNATIONAL                                                   4\n14 ENERGIES                                                                 4\n15 ENERGY                                                                   4\n16 FRONTIERS IN PUBLIC HEALTH                                               4\n17 INFORMATION SYSTEMS FRONTIERS                                            4\n18 JOURNAL OF MATERIALS CHEMISTRY C                                         4\n19 LEISURE STUDIES                                                          4\n20 MATHEMATICS                                                              4\n21 SUSTAINABILITY (SWITZERLAND)                                             4\n22 APPLIED SCIENCES (SWITZERLAND)                                           3\n23 BMC SPORTS SCIENCE MEDICINE AND REHABILITATION                           3\n24 CASE STUDIES IN CONSTRUCTION MATERIALS                                   3\n25 CHRONIC RESPIRATORY DISEASE                                              3\n\n\nMost Relevant Keywords\n\n   Author Keywords (DE)      Articles Keywords-Plus (ID)     Articles\n1       COVID-19                   28   HUMAN                     202\n2       PUBLIC HEALTH              12   ARTICLE                   148\n3       CLIMATE CHANGE              9   HUMANS                    142\n4       GENDER                      8   ADULT                     114\n5       IDENTITY                    8   MALE                      114\n6       QUALITATIVE RESEARCH        8   FEMALE                    112\n7       DIGITAL DIVIDE              7   CONTROLLED STUDY           66\n8       OLDER PEOPLE                7   UNITED KINGDOM             61\n9       SOCIAL MEDIA                7   HUMAN EXPERIMENT           40\n10      TECHNOLOGY                  7   CHILD                      36\n11      CHILDREN                    6   AGED                       31\n12      GAIT                        6   COVID-19                   30\n13      MENTAL HEALTH               6   CLINICAL ARTICLE           29\n14      PERFORMANCE                 6   ENGLAND                    28\n15      SYSTEMATIC REVIEW           6   MAJOR CLINICAL STUDY       27\n16      UK                          6   MENTAL HEALTH              27\n17      ANXIETY                     5   QUALITATIVE RESEARCH       26\n18      CARE HOMES                  5   QUALITY OF LIFE            26\n19      DEEP LEARNING               5   ADOLESCENT                 24\n20      DISABILITY                  5   EXERCISE                   23\n21      EXERCISE                    5   COGNITION                  20\n22      FOOD INSECURITY             5   REVIEW                     20\n23      HIGHER EDUCATION            5   EDUCATION                  19\n24      IMPLEMENTATION              5   MIDDLE AGED                19\n25      LITERATURE REVIEW           5   NONHUMAN                   19\n\n\n\n\nGreen Final\n\nresult_green_final <- biblioAnalysis(green_final_corr, sep = \";\")\n\n\noptions(width=100)\nsummary_result_green_final  <- summary(object= result_green_final, k = 25, pause = F)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              2022 : 2023 \n Sources (Journals, Books, etc)        176 \n Documents                             238 \n Annual Growth Rate %                  -88.79 \n Document Average Age                  0.899 \n Average citations per doc             1.878 \n Average citations per year per doc    0.9538 \n References                            15744 \n \nDOCUMENT TYPES                     \n article           206 \n editorial         3 \n note              1 \n review            27 \n short survey      1 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    2272 \n Author's Keywords (DE)                935 \n \nAUTHORS\n Authors                               1207 \n Author Appearances                    1454 \n Authors of single-authored docs       6 \n \nAUTHORS COLLABORATION\n Single-authored docs                  6 \n Documents per Author                  0.197 \n Co-Authors per Doc                    6.11 \n International co-authorships %        53.78 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    2022      214\n    2023       24\n\nAnnual Percentage Growth Rate -88.79 \n\n\nMost Productive Authors\n\n      Authors        Articles    Authors        Articles Fractionalized\n1  GODFREY A                7 BURTON N                            1.833\n2  STUART S                 7 DICKENS GL                          1.510\n3  CORDIER R                6 GODFREY A                           1.344\n4  DEFEYTER MA              5 HETTINGA FJ                         1.333\n5  DICKENS GL               5 DEFEYTER MA                         1.317\n6  FINCH T                  5 STUART S                            1.244\n7  HETTINGA FJ              5 GAO Z                               1.167\n8  HOWATSON G               5 MENTING SGP                         1.083\n9  POOLOGANATHAN K          5 CORDIER R                           1.071\n10 SCOTT J                  5 WILSON-MENZFELD G                   1.033\n11 AVERY L                  4 DAVENPORT C                         1.000\n12 BARRY G                  4 GALVIN P                            1.000\n13 BURTON N                 4 GANIE HA                            1.000\n14 CORRADI M                4 HILGEN G                            1.000\n15 COVENTRY L               4 MIRANDA D                           1.000\n16 FU Y                     4 MONTGOMERY A                        1.000\n17 GATHEESHGAR P            4 PAN C                               1.000\n18 MENTING SGP              4 SHANG Y                             1.000\n19 MORRIS R                 4 SROKA R                             1.000\n20 PAN C                    4 WANG K                              1.000\n21 TORUN H                  4 ANTOLIN P                           0.833\n22 WANG K                   4 RAGNEDDA M                          0.833\n23 WILSON-MENZFELD G        4 RUIU ML                             0.833\n24 BROWN R                  3 VU MC                               0.833\n25 ELDER GJ                 3 FINCH T                             0.819\n\n\nTop manuscripts per citations\n\n                            Paper                                     DOI TC TCperYear   NTC\n1  WANG L, 2022, IEEE TRANS MOB COMPUT     10.1109/TMC.2021.3059691       35      17.5 17.02\n2  DENG W, 2022, ADV SCI                   10.1002/advs.202102189         31      15.5 15.08\n3  REN H, 2022, IEEE TRANS COMMUN          10.1109/TCOMM.2021.3125057     26      13.0 12.65\n4  SUN S, 2022, APPL ENERGY                10.1016/j.apenergy.2021.117804 22      11.0 10.70\n5  MANN PJ, 2022, AMBIO                    10.1007/s13280-021-01666-z     13       6.5  6.32\n6  OLAN F, 2022, INF SYST FRONT            10.1007/s10796-022-10242-z     13       6.5  6.32\n7  CUNNINGHAM JA, 2022, SMALL BUS ECON     10.1007/s11187-021-00513-5      9       4.5  4.38\n8  DEVER A, 2022, SENSORS                  10.3390/s22041480               8       4.0  3.89\n9  FARSI DN, 2022, BR J NUTR               10.1017/S0007114521002750       8       4.0  3.89\n10 MIRANDA D, 2022, POLICING SOC           10.1080/10439463.2021.1879074   8       4.0  3.89\n11 TAMAYO‐VEGAS S, 2022, POLYM             10.3390/polym14091842           8       4.0  3.89\n12 ALKHALIFAH MA, 2022, J AM CHEM SOC      10.1021/jacs.1c11757            7       3.5  3.40\n13 ANTOLIN P, 2022, FRONT ASTRON SPACE SCI 10.3389/fspas.2022.820116       7       3.5  3.40\n14 FARRAND B, 2022, EUR SECUR              10.1080/09662839.2022.2102896   7       3.5  3.40\n15 NEWBOLD JW, 2022, HUM COMPUT INTERACT   10.1080/07370024.2021.1982391   7       3.5  3.40\n16 MAHONEY J, 2022, RES ETHICS             10.1177/17470161221087542       6       3.0  2.92\n17 PUNTON G, 2022, PLOS ONE                10.1371/journal.pone.0265542    6       3.0  2.92\n18 AL MAQBALI M, 2022, BIOL RES NURS       10.1177/10998004211055866       5       2.5  2.43\n19 BROWN R, 2022, DIGIT HEALTH             10.1177/20552076221084458       5       2.5  2.43\n20 FIELD RW, 2022, MEMBR                   10.3390/membranes12020187       5       2.5  2.43\n21 KARAMPELAS K, 2022, ASTROPHYS J         10.3847/1538-4357/ac3b53        5       2.5  2.43\n22 THOMPSON N, 2022, CLIM PAST             10.5194/cp-18-209-2022          5       2.5  2.43\n23 ALROWAIS R, 2022, CASE STUD THERM ENG   10.1016/j.csite.2022.102084     4       2.0  1.95\n24 ANGIUS L, 2022, EUR J APPL PHYSIOL      10.1007/s00421-021-04815-0      4       2.0  1.95\n25 ANTOLIN P, 2022, ASTROPHYS J LETT       10.3847/2041-8213/ac51dd        4       2.0  1.95\n\n\nCorresponding Author's Countries\n\n          Country Articles    Freq SCP MCP MCP_Ratio\n1  UNITED KINGDOM      193 0.88940  93 100     0.518\n2  AUSTRALIA             5 0.02304   0   5     1.000\n3  CHINA                 4 0.01843   0   4     1.000\n4  BELGIUM               2 0.00922   0   2     1.000\n5  GEORGIA               2 0.00922   2   0     0.000\n6  NETHERLANDS           2 0.00922   0   2     1.000\n7  CANADA                1 0.00461   0   1     1.000\n8  FRANCE                1 0.00461   0   1     1.000\n9  GERMANY               1 0.00461   0   1     1.000\n10 INDIA                 1 0.00461   0   1     1.000\n11 JORDAN                1 0.00461   1   0     0.000\n12 QATAR                 1 0.00461   1   0     0.000\n13 SAUDI ARABIA          1 0.00461   0   1     1.000\n14 SWITZERLAND           1 0.00461   0   1     1.000\n15 USA                   1 0.00461   0   1     1.000\n\n\nSCP: Single Country Publications\n\nMCP: Multiple Country Publications\n\n\nTotal Citations per Country\n\n     Country      Total Citations Average Article Citations\n1  UNITED KINGDOM             355                      1.84\n2  CHINA                       32                      8.00\n3  AUSTRALIA                    7                      1.40\n4  FRANCE                       7                      7.00\n5  GEORGIA                      6                      3.00\n6  BELGIUM                      4                      2.00\n7  SAUDI ARABIA                 4                      4.00\n8  GERMANY                      3                      3.00\n9  CANADA                       1                      1.00\n10 INDIA                        1                      1.00\n11 NETHERLANDS                  1                      0.50\n12 QATAR                        1                      1.00\n13 USA                          1                      1.00\n14 JORDAN                       0                      0.00\n15 SWITZERLAND                  0                      0.00\n\n\nMost Relevant Sources\n\n                                                      Sources        Articles\n1  PLOS ONE                                                                13\n2  SENSORS                                                                  7\n3  INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH        6\n4  BMJ OPEN                                                                 5\n5  NUTRIENTS                                                                5\n6  FRONTIERS IN PSYCHOLOGY                                                  4\n7  BRITISH JOURNAL OF NUTRITION                                             3\n8  BUILDINGS                                                                3\n9  CASE STUDIES IN CONSTRUCTION MATERIALS                                   3\n10 DIGITAL HEALTH                                                           3\n11 FRONTIERS IN PUBLIC HEALTH                                               3\n12 PILOT AND FEASIBILITY STUDIES                                            3\n13 POLICING AND SOCIETY                                                     3\n14 AMERICAN BEHAVIORAL SCIENTIST                                            2\n15 ASTROPHYSICAL JOURNAL                                                    2\n16 BRITISH JOURNAL OF OCCUPATIONAL THERAPY                                  2\n17 CASE STUDIES IN THERMAL ENGINEERING                                      2\n18 FRONTIERS IN ASTRONOMY AND SPACE SCIENCES                                2\n19 FRONTIERS IN MOLECULAR BIOSCIENCES                                       2\n20 FRONTIERS IN PHYSIOLOGY                                                  2\n21 JOURNAL OF BUSINESS ETHICS                                               2\n22 JOURNAL OF CRIMINAL LAW                                                  2\n23 JOURNAL OF MATERIALS CHEMISTRY C                                         2\n24 MSYSTEMS                                                                 2\n25 POLYMERS                                                                 2\n\n\nMost Relevant Keywords\n\n   Author Keywords (DE)      Articles      Keywords-Plus (ID)     Articles\n1   COVID-19                       10 HUMAN                             97\n2   PUBLIC HEALTH                   8 HUMANS                            77\n3   EXERCISE                        5 ARTICLE                           70\n4   FOOD INSECURITY                 5 ADULT                             58\n5   GAIT                            5 MALE                              58\n6   PHYSICAL ACTIVITY               4 FEMALE                            51\n7   RECOVERY                        4 CONTROLLED STUDY                  35\n8   STROKE                          4 UNITED KINGDOM                    22\n9   SYSTEMATIC REVIEW               4 CHILD                             21\n10  TECHNOLOGY                      4 ADOLESCENT                        18\n11  AUTISM SPECTRUM DISORDER        3 CLINICAL ARTICLE                  16\n12  CARE HOMES                      3 HUMAN EXPERIMENT                  16\n13  CLIMATE CHANGE                  3 COVID-19                          14\n14  COVID-19 PANDEMIC               3 EXERCISE                          14\n15  NUTRITION                       3 QUALITY OF LIFE                   13\n16  PACING                          3 COHORT ANALYSIS                   12\n17  PERFORMANCE                     3 ENGLAND                           12\n18  REHABILITATION                  3 MENTAL HEALTH                     12\n19  SLEEP                           3 AGED                              11\n20  SOCIAL MEDIA                    3 GAIT                              11\n21  ACCEPTABILITY                   2 QUALITATIVE RESEARCH              11\n22  ACOUSTOFLUIDICS                 2 DIET                              10\n23  AGBRESA STUDY                   2 RANDOMIZED CONTROLLED TRIAL       10\n24  ANTHOCYANINS                    2 REVIEW                            10\n25  ANXIETY                         2 YOUNG ADULT                       10\n\n\n\n\nGreen Accepted\n\nresult_green_accepted <- biblioAnalysis(green_accepted_corr, sep = \";\")\n\n\noptions(width=100)\nsummary_result_green_accepted  <- summary(object= result_green, k = 25, pause = F)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              2022 : 2023 \n Sources (Journals, Books, etc)        500 \n Documents                             738 \n Annual Growth Rate %                  -80.97 \n Document Average Age                  0.84 \n Average citations per doc             1.925 \n Average citations per year per doc    0.9804 \n References                            47429 \n \nDOCUMENT TYPES                     \n article           656 \n editorial         7 \n erratum           1 \n letter            2 \n note              4 \n review            65 \n short survey      3 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    5200 \n Author's Keywords (DE)                2813 \n \nAUTHORS\n Authors                               2398 \n Author Appearances                    3432 \n Authors of single-authored docs       66 \n \nAUTHORS COLLABORATION\n Single-authored docs                  81 \n Documents per Author                  0.308 \n Co-Authors per Doc                    4.65 \n International co-authorships %        49.73 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    2022      620\n    2023      118\n\nAnnual Percentage Growth Rate -80.97 \n\n\nMost Productive Authors\n\n      Authors        Articles     Authors        Articles Fractionalized\n1  STUART S                14 SHANG Y                               7.57\n2  SHANG Y                 13 VU MC                                 4.37\n3  XU BB                   12 MAQBOOL R                             3.57\n4  GODFREY A               11 PECK S                                3.50\n5  MAQBOOL R               10 RAGNEDDA M                            3.25\n6  TORUN H                 10 STOTEN DW                             3.00\n7  POOLOGANATHAN K          9 SUTHERLAND C                          3.00\n8  RAGNEDDA M               9 BURTON N                              2.67\n9  VU MC                    9 RUIU ML                               2.58\n10 WANG K                   9 GAO Z                                 2.50\n11 WU Q                     9 SEO KW                                2.33\n12 BARRY G                  8 DICKENS GL                            2.30\n13 DICKENS GL               8 WILSON-MENZFELD G                     2.24\n14 FU Y                     8 STUART S                              2.23\n15 GAO Z                    8 WANG K                                2.10\n16 PAN C                    8 COOK P                                2.00\n17 POUND MJ                 8 MURPHY N                              2.00\n18 WILSON-MENZFELD G        8 OSWALD RJ                             2.00\n19 CORDIER R                7 STEPHENS-GRIFFIN N                    2.00\n20 HOWATSON G               7 POLLET TV                             1.93\n21 MORRIS R                 7 POUND MJ                              1.90\n22 POLLET TV                7 GODFREY A                             1.87\n23 RUIU ML                  7 PAN C                                 1.85\n24 SCOTT J                  7 BROWN G                               1.83\n25 BURTON N                 6 GUERRERO M                            1.83\n\n\nTop manuscripts per citations\n\n                                     Paper                                     DOI  TC TCperYear   NTC\n1  PAN D, 2022, NANO-MICRO LETT                     10.1007/s40820-022-00863-z     109      54.5 48.44\n2  AHMADI SE, 2022, ENERGY                          10.1016/j.energy.2022.123223    42      21.0 18.67\n3  GUO J, 2022, ADV COMPOS HYBRID MATER             10.1007/s42114-022-00417-2      36      18.0 16.00\n4  COSTA SC, 2022, RENEWABLE SUSTAINABLE ENERGY REV 10.1016/j.rser.2021.111812      35      17.5 15.56\n5  WANG L, 2022, IEEE TRANS MOB COMPUT-a            10.1109/TMC.2021.3059691        35      17.5 15.56\n6  DENG W, 2022, ADV SCI                            10.1002/advs.202102189          31      15.5 13.78\n7  SZCZYGIELSKI JJ, 2022, ENERGY ECON               10.1016/j.eneco.2021.105258     31      15.5 13.78\n8  SZCZYGIELSKI JJ, 2022, INT REV FINANC ANAL       10.1016/j.irfa.2021.101837      27      13.5 12.00\n9  REN H, 2022, IEEE TRANS COMMUN                   10.1109/TCOMM.2021.3125057      26      13.0 11.56\n10 RAHIMILARKI R, 2022, RENEW ENERGY                10.1016/j.renene.2021.12.056    25      12.5 11.11\n11 SUN S, 2022, APPL ENERGY                         10.1016/j.apenergy.2021.117804  22      11.0  9.78\n12 ALRAJA MN, 2022, INF SYST FRONT                  10.1007/s10796-022-10250-z      19       9.5  8.44\n13 WANG Z, 2022, ADV FUNCT MATER                    10.1002/adfm.202201396          15       7.5  6.67\n14 PAN Y, 2022, IEEE TRANS VEH TECHNOL              10.1109/TVT.2022.3140869        14       7.0  6.22\n15 DU Y, 2022, SMALL                                10.1002/smll.202104640          13       6.5  5.78\n16 MANN PJ, 2022, AMBIO                             10.1007/s13280-021-01666-z      13       6.5  5.78\n17 OLAN F, 2022, INF SYST FRONT                     10.1007/s10796-022-10242-z      13       6.5  5.78\n18 JIANG F, 2022, IEEE INTERNET THINGS J            10.1109/JIOT.2021.3113872       12       6.0  5.33\n19 LIU L, 2022, IEEE TRANS IND INF                  10.1109/TII.2021.3080841        12       6.0  5.33\n20 ALLAN J, 2022, ANTIPODE                          10.1111/anti.12765              11       5.5  4.89\n21 DJAFAROVA E, 2022, YOUNG CONSUM                  10.1108/YC-10-2021-1405         11       5.5  4.89\n22 LU S, 2022, IEEE TRANS IND INF                   10.1109/TII.2022.3190034        11       5.5  4.89\n23 HUSSAIN S, 2022, ENERGY                          10.1016/j.energy.2021.122172    10       5.0  4.44\n24 ISHFAQ K, 2022, INT J ADV MANUF TECHNOL          10.1007/s00170-022-09207-y      10       5.0  4.44\n25 NAKHCHI ME, 2022, ENERGY                         10.1016/j.energy.2021.122988    10       5.0  4.44\n\n\nCorresponding Author's Countries\n\n                Country Articles    Freq SCP MCP MCP_Ratio\n1  UNITED KINGDOM            573 0.88426 304 269     0.469\n2  CHINA                      34 0.05247   0  34     1.000\n3  AUSTRALIA                   5 0.00772   0   5     1.000\n4  NETHERLANDS                 5 0.00772   0   5     1.000\n5  GEORGIA                     3 0.00463   3   0     0.000\n6  KOREA                       3 0.00463   0   3     1.000\n7  BELGIUM                     2 0.00309   0   2     1.000\n8  CHILE                       2 0.00309   0   2     1.000\n9  FRANCE                      2 0.00309   0   2     1.000\n10 INDIA                       2 0.00309   0   2     1.000\n11 QATAR                       2 0.00309   2   0     0.000\n12 BRAZIL                      1 0.00154   0   1     1.000\n13 CANADA                      1 0.00154   0   1     1.000\n14 GERMANY                     1 0.00154   0   1     1.000\n15 GREECE                      1 0.00154   0   1     1.000\n16 HONG KONG                   1 0.00154   0   1     1.000\n17 IRELAND                     1 0.00154   1   0     0.000\n18 JORDAN                      1 0.00154   1   0     0.000\n19 KAZAKHSTAN                  1 0.00154   0   1     1.000\n20 MEXICO                      1 0.00154   0   1     1.000\n21 NORWAY                      1 0.00154   0   1     1.000\n22 PAKISTAN                    1 0.00154   0   1     1.000\n23 SAUDI ARABIA                1 0.00154   0   1     1.000\n24 SWITZERLAND                 1 0.00154   0   1     1.000\n25 UNITED ARAB EMIRATES        1 0.00154   0   1     1.000\n\n\nSCP: Single Country Publications\n\nMCP: Multiple Country Publications\n\n\nTotal Citations per Country\n\n           Country      Total Citations Average Article Citations\n1  UNITED KINGDOM                   988                      1.72\n2  CHINA                            288                      8.47\n3  FRANCE                             9                      4.50\n4  AUSTRALIA                          7                      1.40\n5  CHILE                              7                      3.50\n6  GEORGIA                            6                      2.00\n7  KOREA                              6                      2.00\n8  INDIA                              5                      2.50\n9  BELGIUM                            4                      2.00\n10 SAUDI ARABIA                       4                      4.00\n11 GERMANY                            3                      3.00\n12 NORWAY                             3                      3.00\n13 NETHERLANDS                        2                      0.40\n14 CANADA                             1                      1.00\n15 MEXICO                             1                      1.00\n16 QATAR                              1                      0.50\n17 USA                                1                      1.00\n18 BRAZIL                             0                      0.00\n19 GREECE                             0                      0.00\n20 HONG KONG                          0                      0.00\n21 IRELAND                            0                      0.00\n22 JORDAN                             0                      0.00\n23 KAZAKHSTAN                         0                      0.00\n24 PAKISTAN                           0                      0.00\n25 SWITZERLAND                        0                      0.00\n\n\nMost Relevant Sources\n\n                                                      Sources        Articles\n1  PLOS ONE                                                                25\n2  BUILDINGS                                                                9\n3  SENSORS                                                                  9\n4  JOURNAL OF CRIMINAL LAW                                                  7\n5  BMJ OPEN                                                                 6\n6  FRONTIERS IN PSYCHOLOGY                                                  6\n7  INTERNATIONAL JOURNAL OF ENVIRONMENTAL RESEARCH AND PUBLIC HEALTH        6\n8  JOURNAL OF BUSINESS ETHICS                                               6\n9  BRITISH JOURNAL OF OCCUPATIONAL THERAPY                                  5\n10 NURSE EDUCATION TODAY                                                    5\n11 NUTRIENTS                                                                5\n12 BRITISH JOURNAL OF NUTRITION                                             4\n13 CERAMICS INTERNATIONAL                                                   4\n14 ENERGIES                                                                 4\n15 ENERGY                                                                   4\n16 FRONTIERS IN PUBLIC HEALTH                                               4\n17 INFORMATION SYSTEMS FRONTIERS                                            4\n18 JOURNAL OF MATERIALS CHEMISTRY C                                         4\n19 LEISURE STUDIES                                                          4\n20 MATHEMATICS                                                              4\n21 SUSTAINABILITY (SWITZERLAND)                                             4\n22 APPLIED SCIENCES (SWITZERLAND)                                           3\n23 BMC SPORTS SCIENCE MEDICINE AND REHABILITATION                           3\n24 CASE STUDIES IN CONSTRUCTION MATERIALS                                   3\n25 CHRONIC RESPIRATORY DISEASE                                              3\n\n\nMost Relevant Keywords\n\n   Author Keywords (DE)      Articles Keywords-Plus (ID)     Articles\n1       COVID-19                   28   HUMAN                     202\n2       PUBLIC HEALTH              12   ARTICLE                   148\n3       CLIMATE CHANGE              9   HUMANS                    142\n4       GENDER                      8   ADULT                     114\n5       IDENTITY                    8   MALE                      114\n6       QUALITATIVE RESEARCH        8   FEMALE                    112\n7       DIGITAL DIVIDE              7   CONTROLLED STUDY           66\n8       OLDER PEOPLE                7   UNITED KINGDOM             61\n9       SOCIAL MEDIA                7   HUMAN EXPERIMENT           40\n10      TECHNOLOGY                  7   CHILD                      36\n11      CHILDREN                    6   AGED                       31\n12      GAIT                        6   COVID-19                   30\n13      MENTAL HEALTH               6   CLINICAL ARTICLE           29\n14      PERFORMANCE                 6   ENGLAND                    28\n15      SYSTEMATIC REVIEW           6   MAJOR CLINICAL STUDY       27\n16      UK                          6   MENTAL HEALTH              27\n17      ANXIETY                     5   QUALITATIVE RESEARCH       26\n18      CARE HOMES                  5   QUALITY OF LIFE            26\n19      DEEP LEARNING               5   ADOLESCENT                 24\n20      DISABILITY                  5   EXERCISE                   23\n21      EXERCISE                    5   COGNITION                  20\n22      FOOD INSECURITY             5   REVIEW                     20\n23      HIGHER EDUCATION            5   EDUCATION                  19\n24      IMPLEMENTATION              5   MIDDLE AGED                19\n25      LITERATURE REVIEW           5   NONHUMAN                   19\n\n\n\n\nNot Green\n\nresult_not_green <- biblioAnalysis(not_green_corr, sep = \";\")\n\n\noptions(width=100)\nsummary_result_not_green  <- summary(object= result_not_green, k = 25, pause = F)\n\n\n\nMAIN INFORMATION ABOUT DATA\n\n Timespan                              2022 : 2023 \n Sources (Journals, Books, etc)        172 \n Documents                             218 \n Annual Growth Rate %                  -66.26 \n Document Average Age                  0.748 \n Average citations per doc             1.477 \n Average citations per year per doc    0.8165 \n References                            12546 \n \nDOCUMENT TYPES                     \n article               148 \n book chapter          32 \n conference paper      9 \n editorial             8 \n erratum               1 \n letter                2 \n note                  7 \n review                11 \n \nDOCUMENT CONTENTS\n Keywords Plus (ID)                    1514 \n Author's Keywords (DE)                874 \n \nAUTHORS\n Authors                               649 \n Author Appearances                    856 \n Authors of single-authored docs       33 \n \nAUTHORS COLLABORATION\n Single-authored docs                  42 \n Documents per Author                  0.336 \n Co-Authors per Doc                    3.93 \n International co-authorships %        48.62 \n \n\nAnnual Scientific Production\n\n Year    Articles\n    2022      163\n    2023       55\n\nAnnual Percentage Growth Rate -66.26 \n\n\nMost Productive Authors\n\n    Authors        Articles  Authors        Articles Fractionalized\n1  FU YQ                 10 WYATT T                            8.00\n2  POOLOGANATHAN K       10 JAHANKHANI H                       3.25\n3  WU Q                   9 WILLIAMS H                         2.50\n4  GATHEESHGAR P          8 KOPNINA H                          2.00\n5  JAHANKHANI H           8 SINGH N                            2.00\n6  LIU J                  8 WALKER J                           2.00\n7  WYATT T                8 FU YQ                              1.93\n8  CORRADI M              6 POOLOGANATHAN K                    1.70\n9  LU H                   6 BLACKWOOD A                        1.50\n10 MARZBAND M             6 HILL B                             1.50\n11 XU BB                  6 LU H                               1.43\n12 YUAN J                 6 SCHAARSCHMIDT M                    1.25\n13 GODFREY A              5 PECK S                             1.20\n14 GUO Z                  5 GATHEESHGAR P                      1.17\n15 LIU B                  5 MARZBAND M                         1.16\n16 STUART S               5 LIU J                              1.15\n17 ABUSORRAH A            4 LEI H                              1.12\n18 GUNALAN S              4 CORRADI M                          1.10\n19 HE XD                  4 GODFREY A                          1.08\n20 KANTHASAMY E           4 STUART S                           1.08\n21 LI H                   4 WU Q                               1.06\n22 TORUN H                4 ANGIUS L                           1.00\n23 XING L                 4 APLIN R                            1.00\n24 AHMADI SE              3 CARELESS E                         1.00\n25 ALGADI H               3 DAVIES P                           1.00\n\n\nTop manuscripts per citations\n\n                                 Paper                                      DOI TC TCperYear   NTC\n1  SADEGHI D, 2022, INT J ENERGY RES            10.1002/er.7729                 27      13.5 15.28\n2  ZHANG Y, 2023, PARTICUOLOGY                  10.1016/j.partic.2022.05.010    24      24.0 38.82\n3  SADEGHI D, 2022, ENERGY                      10.1016/j.energy.2022.123947    21      10.5 11.89\n4  GONG C, 2022, RENEW ENERGY                   10.1016/j.renene.2022.02.104    19       9.5 10.75\n5  CELIK Y, 2022, INF FUSION                    10.1016/j.inffus.2021.09.016    18       9.0 10.19\n6  SHANAEV S, 2022, FINAN RES LETT              10.1016/j.frl.2021.102302       15       7.5  8.49\n7  LU S, 2022, J ENERGY STORAGE                 10.1016/j.est.2022.104764       12       6.0  6.79\n8  MOSCARDINI AO, 2022, STUD HIGH EDUC          10.1080/03075079.2020.1807493   11       5.5  6.23\n9  AHMADI SE, 2022, J ENERGY STORAGE            10.1016/j.est.2022.105566        9       4.5  5.09\n10 NIAEI H, 2022, J CLEAN PROD                  10.1016/j.jclepro.2022.132403    9       4.5  5.09\n11 FENG H, 2022, J BUILD ENG                    10.1016/j.jobe.2022.104191       7       3.5  3.96\n12 GATHEESHGAR P, 2022, J CONSTR STEEL RES      10.1016/j.jcsr.2021.106974       7       3.5  3.96\n13 MCINTOSH A, 2022, J BUILD ENG                10.1016/j.jobe.2022.104134       7       3.5  3.96\n14 AOKI N, 2022, PUBLIC ADM                     10.1111/padm.12822               5       2.5  2.83\n15 EDMONDSON V, 2022, EUR J ENG EDUC            10.1080/03043797.2022.2036704    5       2.5  2.83\n16 NYUUR RB, 2022, BUS ETHICS ENVIRON RESPONSIB 10.1111/beer.12399               5       2.5  2.83\n17 PERERA D, 2022, J BUILD ENG                  10.1016/j.jobe.2021.103612       5       2.5  2.83\n18 RALPH L, 2022, POLICING SOC                  10.1080/10439463.2021.1956493    5       2.5  2.83\n19 TAMAYO-VEGAS S, 2022, MATER TODAY PROC       10.1016/j.matpr.2021.09.361      5       2.5  2.83\n20 ELLIS S, 2022, J FINANC STAB                 10.1016/j.jfs.2021.100960        4       2.0  2.26\n21 JONES DR, 2022, BR EDUC RES J                10.1002/berj.3757                4       2.0  2.26\n22 KANTHASAMY E, 2022, ENG STRUCT               10.1016/j.engstruct.2021.113366  4       2.0  2.26\n23 LI J, 2022, SENS ACTUATORS A PHYS            10.1016/j.sna.2022.113429        4       2.0  2.26\n24 SIFAN M, 2022, J BUILD ENG                   10.1016/j.jobe.2021.103878       4       2.0  2.26\n25 MAZUMDER MMM, 2022, J OPER RISK              10.21314/JOP.2020.249            3       1.5  1.70\n\n\nCorresponding Author's Countries\n\n          Country Articles    Freq SCP MCP MCP_Ratio\n1  UNITED KINGDOM      143 0.81250  76  67     0.469\n2  CHINA                22 0.12500   0  22     1.000\n3  NETHERLANDS           2 0.01136   1   1     0.500\n4  AUSTRALIA             1 0.00568   0   1     1.000\n5  CHILE                 1 0.00568   0   1     1.000\n6  GERMANY               1 0.00568   0   1     1.000\n7  HONG KONG             1 0.00568   0   1     1.000\n8  INDIA                 1 0.00568   1   0     0.000\n9  IRELAND               1 0.00568   1   0     0.000\n10 ITALY                 1 0.00568   0   1     1.000\n11 SAUDI ARABIA          1 0.00568   0   1     1.000\n12 SPAIN                 1 0.00568   0   1     1.000\n\n\nSCP: Single Country Publications\n\nMCP: Multiple Country Publications\n\n\nTotal Citations per Country\n\n     Country      Total Citations Average Article Citations\n1  UNITED KINGDOM             230                      1.61\n2  CHINA                       59                      2.68\n3  GERMANY                      2                      2.00\n4  HONG KONG                    1                      1.00\n5  INDIA                        1                      1.00\n6  IRELAND                      1                      1.00\n7  NETHERLANDS                  1                      0.50\n8  AUSTRALIA                    0                      0.00\n9  CHILE                        0                      0.00\n10 ITALY                        0                      0.00\n11 SAUDI ARABIA                 0                      0.00\n12 SPAIN                        0                      0.00\n\n\nMost Relevant Sources\n\n                                                                                                                         Sources       \n1  ADVANCED SCIENCES AND TECHNOLOGIES FOR SECURITY APPLICATIONS                                                                        \n2  CRITICAL CRIMINOLOGICAL PERSPECTIVES                                                                                                \n3  JOURNAL OF BUILDING ENGINEERING                                                                                                     \n4  JOURNAL OF CONSTRUCTIONAL STEEL RESEARCH                                                                                            \n5  JOURNAL FOR EIGHTEENTH-CENTURY STUDIES                                                                                              \n6  JOURNAL OF CLEANER PRODUCTION                                                                                                       \n7  NEUROMETHODS                                                                                                                        \n8  BRITISH JOURNAL OF NURSING                                                                                                          \n9  INFORMATION TECHNOLOGY AND PEOPLE                                                                                                   \n10 JOURNAL OF ENERGY STORAGE                                                                                                           \n11 JOURNAL OF FURTHER AND HIGHER EDUCATION                                                                                             \n12 JOURNAL OF OPERATIONAL RISK                                                                                                         \n13 JOURNAL OF PHYSICS D: APPLIED PHYSICS                                                                                               \n14 LECTURE NOTES IN COMPUTER SCIENCE (INCLUDING SUBSERIES LECTURE NOTES IN ARTIFICIAL INTELLIGENCE AND LECTURE NOTES IN BIOINFORMATICS)\n15 PLOS ONE                                                                                                                            \n16 POLICING AND SOCIETY                                                                                                                \n17 POLYMER                                                                                                                             \n18 PUBLIC ADMINISTRATION                                                                                                               \n19 RENEWABLE ENERGY                                                                                                                    \n20 SMART MATERIALS AND STRUCTURES                                                                                                      \n21 STUDIES IN HIGHER EDUCATION                                                                                                         \n22 VISIONS FOR SUSTAINABILITY                                                                                                          \n23 2022 13TH INTERNATIONAL SYMPOSIUM ON COMMUNICATION SYSTEMS NETWORKS AND DIGITAL SIGNAL PROCESSING CSNDSP 2022                       \n24 ACM INTERNATIONAL CONFERENCE PROCEEDING SERIES                                                                                      \n25 ADVANCED COMPOSITES AND HYBRID MATERIALS                                                                                            \n   Articles\n1        12\n2         8\n3         5\n4         4\n5         3\n6         3\n7         3\n8         2\n9         2\n10        2\n11        2\n12        2\n13        2\n14        2\n15        2\n16        2\n17        2\n18        2\n19        2\n20        2\n21        2\n22        2\n23        1\n24        1\n25        1\n\n\nMost Relevant Keywords\n\n   Author Keywords (DE)      Articles Keywords-Plus (ID)     Articles\n1     BLOCKCHAIN                    6  HUMAN                       24\n2     ACTIVISM                      4  HUMANS                      15\n3     COVID-19                      4  ARTICLE                      7\n4     HEALTH                        4  PARKINSON DISEASE            7\n5     COMPOSITE MATERIALS           3  EXERCISE                     6\n6     CYBER SECURITY                3  FINITE ELEMENT METHOD        6\n7     DEVELOPMENT                   3  LIFE CYCLE                   6\n8     ELECTRIC VEHICLE              3  AGED                         5\n9     FEMINISM                      3  FEMALE                       5\n10    MEDICINE                      3  PERFORMANCE                  5\n11    MIGRATION                     3  WEARABLE SENSORS             5\n12    POETRY                        3  ADOLESCENT                   4\n13    POLICING                      3  ADULT                        4\n14    SMART CONTRACTS               3  AGING                        4\n15    SOCIAL MEDIA                  3  CARBON DIOXIDE               4\n16    ACOUSTOFLUIDICS               2  CASE-STUDIES                 4\n17    AUTOETHNOGRAPHY               2  DECISION MAKING              4\n18    BANGLADESH                    2  DEMENTIA                     4\n19    COLD-FORMED MEMBERS           2  DESIGN EQUATION              4\n20    COLD-FORMED STEEL             2  DYNAMICS                     4\n21    COMMUNITY                     2  ELECTROMYOGRAPHY             4\n22    CYBERSECURITY                 2  FLANGES                      4\n23    DEEP LEARNING (DL)            2  MALE                         4\n24    DIFFUSION                     2  NONHUMAN                     4\n25    DIGITAL TRANSFORMATION        2  SLEEP                        4"
  }
]